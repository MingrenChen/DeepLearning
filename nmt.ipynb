{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nmt.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "TjPTaRB4mpCd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Colab FAQ\n",
        "\n",
        "For some basic overview and features offered in Colab notebooks, check out: [Overview of Colaboratory Features](https://colab.research.google.com/notebooks/basic_features_overview.ipynb)\n",
        "\n",
        "You need to use the colab GPU for this assignmentby selecting:\n",
        "\n",
        "> **Runtime**   →   **Change runtime type**   →   **Hardware Accelerator: GPU**"
      ]
    },
    {
      "metadata": {
        "id": "s9IS9B9-yUU5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Setup PyTorch\n",
        "All files are stored at /content/csc421/a3/ folder\n"
      ]
    },
    {
      "metadata": {
        "id": "Z-6MQhMOlHXD",
        "colab_type": "code",
        "outputId": "0fe7cccd-1229-455f-8fb5-97dbfd4ecab0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        }
      },
      "cell_type": "code",
      "source": [
        "######################################################################\n",
        "# Setup python environment and change the current working directory\n",
        "######################################################################\n",
        "!pip install torch torchvision\n",
        "!pip install Pillow==4.0.0\n",
        "%mkdir -p /content/csc421/a3/\n",
        "%cd /content/csc421/a3"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python2.7/dist-packages (1.0.1.post2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python2.7/dist-packages (0.2.2.post3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python2.7/dist-packages (from torchvision) (1.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python2.7/dist-packages (from torchvision) (1.14.6)\n",
            "Collecting pillow>=4.1.1 (from torchvision)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0d/f3/421598450cb9503f4565d936860763b5af413a61009d87a5ab1e34139672/Pillow-5.4.1-cp27-cp27mu-manylinux1_x86_64.whl (2.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.0MB 11.0MB/s \n",
            "\u001b[31mfastai 0.7.0 has requirement torch<0.4, but you'll have torch 1.0.1.post2 which is incompatible.\u001b[0m\n",
            "\u001b[31mimgaug 0.2.8 has requirement numpy>=1.15.0, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pillow\n",
            "  Found existing installation: Pillow 4.0.0\n",
            "    Uninstalling Pillow-4.0.0:\n",
            "      Successfully uninstalled Pillow-4.0.0\n",
            "Successfully installed pillow-5.4.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting Pillow==4.0.0\n",
            "  Using cached https://files.pythonhosted.org/packages/89/99/0e3522a9764fe371bf9f7729404b1ef7d9c4fc49cbe5f1761c6e07812345/Pillow-4.0.0-cp27-cp27mu-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python2.7/dist-packages (from Pillow==4.0.0) (0.46)\n",
            "\u001b[31mfastai 0.7.0 has requirement torch<0.4, but you'll have torch 1.0.1.post2 which is incompatible.\u001b[0m\n",
            "\u001b[31mimgaug 0.2.8 has requirement numpy>=1.15.0, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
            "\u001b[31mtorchvision 0.2.2.post3 has requirement pillow>=4.1.1, but you'll have pillow 4.0.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: Pillow\n",
            "  Found existing installation: Pillow 5.4.1\n",
            "    Uninstalling Pillow-5.4.1:\n",
            "      Successfully uninstalled Pillow-5.4.1\n",
            "Successfully installed Pillow-4.0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/content/csc421/a3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9DaTdRNuUra7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Helper code"
      ]
    },
    {
      "metadata": {
        "id": "4BIpGwANoQOg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Utility functions"
      ]
    },
    {
      "metadata": {
        "id": "D-UJHBYZkh7f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pdb\n",
        "import argparse\n",
        "import pickle as pkl\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from six.moves.urllib.request import urlretrieve\n",
        "import tarfile\n",
        "import pickle\n",
        "import sys\n",
        "\n",
        "\n",
        "def get_file(fname,\n",
        "             origin,\n",
        "             untar=False,\n",
        "             extract=False,\n",
        "             archive_format='auto',\n",
        "             cache_dir='data'):\n",
        "    datadir = os.path.join(cache_dir)\n",
        "    if not os.path.exists(datadir):\n",
        "        os.makedirs(datadir)\n",
        "\n",
        "    if untar:\n",
        "        untar_fpath = os.path.join(datadir, fname)\n",
        "        fpath = untar_fpath + '.tar.gz'\n",
        "    else:\n",
        "        fpath = os.path.join(datadir, fname)\n",
        "    \n",
        "    print(fpath)\n",
        "    if not os.path.exists(fpath):\n",
        "        print('Downloading data from', origin)\n",
        "\n",
        "        error_msg = 'URL fetch failure on {}: {} -- {}'\n",
        "        try:\n",
        "            try:\n",
        "                urlretrieve(origin, fpath)\n",
        "            except URLError as e:\n",
        "                raise Exception(error_msg.format(origin, e.errno, e.reason))\n",
        "            except HTTPError as e:\n",
        "                raise Exception(error_msg.format(origin, e.code, e.msg))\n",
        "        except (Exception, KeyboardInterrupt) as e:\n",
        "            if os.path.exists(fpath):\n",
        "                os.remove(fpath)\n",
        "            raise\n",
        "\n",
        "    if untar:\n",
        "        if not os.path.exists(untar_fpath):\n",
        "            print('Extracting file.')\n",
        "            with tarfile.open(fpath) as archive:\n",
        "                archive.extractall(datadir)\n",
        "        return untar_fpath\n",
        "\n",
        "    if extract:\n",
        "        _extract_archive(fpath, datadir, archive_format)\n",
        "\n",
        "    return fpath\n",
        "\n",
        "class AttrDict(dict):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(AttrDict, self).__init__(*args, **kwargs)\n",
        "        self.__dict__ = self\n",
        "        \n",
        "def to_var(tensor, cuda):\n",
        "    \"\"\"Wraps a Tensor in a Variable, optionally placing it on the GPU.\n",
        "\n",
        "        Arguments:\n",
        "            tensor: A Tensor object.\n",
        "            cuda: A boolean flag indicating whether to use the GPU.\n",
        "\n",
        "        Returns:\n",
        "            A Variable object, on the GPU if cuda==True.\n",
        "    \"\"\"\n",
        "    if cuda:\n",
        "        return Variable(tensor.cuda())\n",
        "    else:\n",
        "        return Variable(tensor)\n",
        "\n",
        "\n",
        "def create_dir_if_not_exists(directory):\n",
        "    \"\"\"Creates a directory if it doesn't already exist.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "\n",
        "\n",
        "def save_loss_plot(train_losses, val_losses, opts):\n",
        "    \"\"\"Saves a plot of the training and validation loss curves.\n",
        "    \"\"\"\n",
        "    plt.figure()\n",
        "    plt.plot(range(len(train_losses)), train_losses)\n",
        "    plt.plot(range(len(val_losses)), val_losses)\n",
        "    plt.title('BS={}, nhid={}'.format(opts.batch_size, opts.hidden_size), fontsize=20)\n",
        "    plt.xlabel('Epochs', fontsize=16)\n",
        "    plt.ylabel('Loss', fontsize=16)\n",
        "    plt.xticks(fontsize=14)\n",
        "    plt.yticks(fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(opts.checkpoint_path, 'loss_plot.pdf'))\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def checkpoint(encoder, decoder, idx_dict, opts):\n",
        "    \"\"\"Saves the current encoder and decoder models, along with idx_dict, which\n",
        "    contains the char_to_index and index_to_char mappings, and the start_token\n",
        "    and end_token values.\n",
        "    \"\"\"\n",
        "    with open(os.path.join(opts.checkpoint_path, 'encoder.pt'), 'wb') as f:\n",
        "        torch.save(encoder, f)\n",
        "\n",
        "    with open(os.path.join(opts.checkpoint_path, 'decoder.pt'), 'wb') as f:\n",
        "        torch.save(decoder, f)\n",
        "\n",
        "    with open(os.path.join(opts.checkpoint_path, 'idx_dict.pkl'), 'wb') as f:\n",
        "        pkl.dump(idx_dict, f)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pbvpn4MaV0I1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data loader"
      ]
    },
    {
      "metadata": {
        "id": "XVT4TNTOV3Eg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def read_lines(filename):\n",
        "    \"\"\"Read a file and split it into lines.\n",
        "    \"\"\"\n",
        "    lines = open(filename).read().strip().lower().split('\\n')\n",
        "    return lines\n",
        "\n",
        "\n",
        "def read_pairs(filename):\n",
        "    \"\"\"Reads lines that consist of two words, separated by a space.\n",
        "\n",
        "    Returns:\n",
        "        source_words: A list of the first word in each line of the file.\n",
        "        target_words: A list of the second word in each line of the file.\n",
        "    \"\"\"\n",
        "    lines = read_lines(filename)\n",
        "    source_words, target_words = [], []\n",
        "    for line in lines:\n",
        "        line = line.strip()\n",
        "        if line:\n",
        "            source, target = line.split()\n",
        "            source_words.append(source)\n",
        "            target_words.append(target)\n",
        "    return source_words, target_words\n",
        "\n",
        "\n",
        "def all_alpha_or_dash(s):\n",
        "    \"\"\"Helper function to check whether a string is alphabetic, allowing dashes '-'.\n",
        "    \"\"\"\n",
        "    return all(c.isalpha() or c == '-' for c in s)\n",
        "\n",
        "\n",
        "def filter_lines(lines):\n",
        "    \"\"\"Filters lines to consist of only alphabetic characters or dashes \"-\".\n",
        "    \"\"\"\n",
        "    return [line for line in lines if all_alpha_or_dash(line)]\n",
        "\n",
        "\n",
        "def load_data():\n",
        "    \"\"\"Loads (English, Pig-Latin) word pairs, and creates mappings from characters to indexes.\n",
        "    \"\"\"\n",
        "\n",
        "    source_lines, target_lines = read_pairs('data/pig_latin_data.txt')\n",
        "\n",
        "    # Filter lines\n",
        "    source_lines = filter_lines(source_lines)\n",
        "    target_lines = filter_lines(target_lines)\n",
        "\n",
        "    all_characters = set(''.join(source_lines)) | set(''.join(target_lines))\n",
        "\n",
        "    # Create a dictionary mapping each character to a unique index\n",
        "    char_to_index = { char: index for (index, char) in enumerate(sorted(list(all_characters))) }\n",
        "\n",
        "    # Add start and end tokens to the dictionary\n",
        "    start_token = len(char_to_index)\n",
        "    end_token = len(char_to_index) + 1\n",
        "    char_to_index['SOS'] = start_token\n",
        "    char_to_index['EOS'] = end_token\n",
        "\n",
        "    # Create the inverse mapping, from indexes to characters (used to decode the model's predictions)\n",
        "    index_to_char = { index: char for (char, index) in char_to_index.items() }\n",
        "\n",
        "    # Store the final size of the vocabulary\n",
        "    vocab_size = len(char_to_index)\n",
        "\n",
        "    line_pairs = list(set(zip(source_lines, target_lines)))  # Python 3\n",
        "\n",
        "    idx_dict = { 'char_to_index': char_to_index,\n",
        "                 'index_to_char': index_to_char,\n",
        "                 'start_token': start_token,\n",
        "                 'end_token': end_token }\n",
        "\n",
        "    return line_pairs, vocab_size, idx_dict\n",
        "\n",
        "\n",
        "def create_dict(pairs):\n",
        "    \"\"\"Creates a mapping { (source_length, target_length): [list of (source, target) pairs]\n",
        "    This is used to make batches: each batch consists of two parallel tensors, one containing\n",
        "    all source indexes and the other containing all corresponding target indexes.\n",
        "    Within a batch, all the source words are the same length, and all the target words are\n",
        "    the same length.\n",
        "    \"\"\"\n",
        "    unique_pairs = list(set(pairs))  # Find all unique (source, target) pairs\n",
        "\n",
        "    d = defaultdict(list)\n",
        "    for (s,t) in unique_pairs:\n",
        "        d[(len(s), len(t))].append((s,t))\n",
        "\n",
        "    return d\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bRWfRdmVVjUl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training and evaluation code"
      ]
    },
    {
      "metadata": {
        "id": "wa5-onJhoSeM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def string_to_index_list(s, char_to_index, end_token):\n",
        "    \"\"\"Converts a sentence into a list of indexes (for each character).\n",
        "    \"\"\"\n",
        "    return [char_to_index[char] for char in s] + [end_token]  # Adds the end token to each index list\n",
        "\n",
        "\n",
        "def translate_sentence(sentence, encoder, decoder, idx_dict, opts):\n",
        "    \"\"\"Translates a sentence from English to Pig-Latin, by splitting the sentence into\n",
        "    words (whitespace-separated), running the encoder-decoder model to translate each\n",
        "    word independently, and then stitching the words back together with spaces between them.\n",
        "    \"\"\"\n",
        "    if idx_dict is None:\n",
        "      line_pairs, vocab_size, idx_dict = load_data()\n",
        "    return ' '.join([translate(word, encoder, decoder, idx_dict, opts) for word in sentence.split()])\n",
        "\n",
        "\n",
        "def translate(input_string, encoder, decoder, idx_dict, opts):\n",
        "    \"\"\"Translates a given string from English to Pig-Latin.\n",
        "    \"\"\"\n",
        "\n",
        "    char_to_index = idx_dict['char_to_index']\n",
        "    index_to_char = idx_dict['index_to_char']\n",
        "    start_token = idx_dict['start_token']\n",
        "    end_token = idx_dict['end_token']\n",
        "\n",
        "    max_generated_chars = 20\n",
        "    gen_string = ''\n",
        "\n",
        "    indexes = string_to_index_list(input_string, char_to_index, end_token)\n",
        "    indexes = to_var(torch.LongTensor(indexes).unsqueeze(0), opts.cuda)  # Unsqueeze to make it like BS = 1\n",
        "\n",
        "    encoder_annotations, encoder_last_hidden = encoder(indexes)\n",
        "\n",
        "    decoder_hidden = encoder_last_hidden\n",
        "    decoder_input = to_var(torch.LongTensor([[start_token]]), opts.cuda)  # For BS = 1\n",
        "    decoder_inputs = decoder_input\n",
        "\n",
        "    for i in range(max_generated_chars):\n",
        "      ## slow decoding, recompute everything at each time\n",
        "      decoder_outputs, attention_weights = decoder(decoder_inputs, encoder_annotations, decoder_hidden)\n",
        "      generated_words = F.softmax(decoder_outputs, dim=2).max(2)[1]\n",
        "      ni = generated_words.cpu().numpy().reshape(-1)  # LongTensor of size 1\n",
        "      ni = ni[-1] #latest output token\n",
        "\n",
        "      decoder_inputs = torch.cat([decoder_input, generated_words], dim=1)\n",
        "      \n",
        "      if ni == end_token:\n",
        "          break\n",
        "      else:\n",
        "          gen_string = \"\".join(\n",
        "              [index_to_char[int(item)] \n",
        "               for item in generated_words.cpu().numpy().reshape(-1)])\n",
        "\n",
        "    return gen_string\n",
        "\n",
        "\n",
        "def visualize_attention(input_string, encoder, decoder, idx_dict, opts):\n",
        "    \"\"\"Generates a heatmap to show where attention is focused in each decoder step.\n",
        "    \"\"\"\n",
        "    if idx_dict is None:\n",
        "      line_pairs, vocab_size, idx_dict = load_data()\n",
        "    char_to_index = idx_dict['char_to_index']\n",
        "    index_to_char = idx_dict['index_to_char']\n",
        "    start_token = idx_dict['start_token']\n",
        "    end_token = idx_dict['end_token']\n",
        "\n",
        "    max_generated_chars = 20\n",
        "    gen_string = ''\n",
        "\n",
        "    indexes = string_to_index_list(input_string, char_to_index, end_token)\n",
        "    indexes = to_var(torch.LongTensor(indexes).unsqueeze(0), opts.cuda)  # Unsqueeze to make it like BS = 1\n",
        "\n",
        "    encoder_annotations, encoder_hidden = encoder(indexes)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "    decoder_input = to_var(torch.LongTensor([[start_token]]), opts.cuda)  # For BS = 1\n",
        "    decoder_inputs = decoder_input\n",
        "\n",
        "    produced_end_token = False\n",
        "\n",
        "    for i in range(max_generated_chars):\n",
        "      ## slow decoding, recompute everything at each time\n",
        "      decoder_outputs, attention_weights = decoder(decoder_inputs, encoder_annotations, decoder_hidden)\n",
        "      generated_words = F.softmax(decoder_outputs, dim=2).max(2)[1]\n",
        "      ni = generated_words.cpu().numpy().reshape(-1)  # LongTensor of size 1\n",
        "      ni = ni[-1] #latest output token\n",
        "      \n",
        "      decoder_inputs = torch.cat([decoder_input, generated_words], dim=1)\n",
        "      \n",
        "      if ni == end_token:\n",
        "          break\n",
        "      else:\n",
        "          gen_string = \"\".join(\n",
        "              [index_to_char[int(item)] \n",
        "               for item in generated_words.cpu().numpy().reshape(-1)])\n",
        "    \n",
        "    if isinstance(attention_weights, tuple):\n",
        "      ## transformer's attention mweights\n",
        "      attention_weights, self_attention_weights = attention_weights\n",
        "    \n",
        "    all_attention_weights = attention_weights.data.cpu().numpy()\n",
        "    \n",
        "    for i in range(len(all_attention_weights)):\n",
        "      attention_weights_matrix = all_attention_weights[i].squeeze()\n",
        "      fig = plt.figure()\n",
        "      ax = fig.add_subplot(111)\n",
        "      cax = ax.matshow(attention_weights_matrix, cmap='bone')\n",
        "      fig.colorbar(cax)\n",
        "\n",
        "      # Set up axes\n",
        "      ax.set_yticklabels([''] + list(input_string) + ['EOS'], rotation=90)\n",
        "      ax.set_xticklabels([''] + list(gen_string) + (['EOS'] if produced_end_token else []))\n",
        "\n",
        "      # Show label at every tick\n",
        "      ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "      ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "      # Add title\n",
        "      plt.xlabel('Attention weights to the source sentence in layer {}'.format(i+1))\n",
        "      plt.tight_layout()\n",
        "      plt.grid('off')\n",
        "      plt.show()\n",
        "      #plt.savefig(save)\n",
        "\n",
        "      #plt.close(fig)\n",
        "\n",
        "    return gen_string\n",
        "\n",
        "\n",
        "def compute_loss(data_dict, encoder, decoder, idx_dict, criterion, optimizer, opts):\n",
        "    \"\"\"Train/Evaluate the model on a dataset.\n",
        "\n",
        "    Arguments:\n",
        "        data_dict: The validation/test word pairs, organized by source and target lengths.\n",
        "        encoder: An encoder model to produce annotations for each step of the input sequence.\n",
        "        decoder: A decoder model (with or without attention) to generate output tokens.\n",
        "        idx_dict: Contains char-to-index and index-to-char mappings, and start & end token indexes.\n",
        "        criterion: Used to compute the CrossEntropyLoss for each decoder output.\n",
        "        optimizer: Train the weights if an optimizer is given. None if only evaluate the model. \n",
        "        opts: The command-line arguments.\n",
        "\n",
        "    Returns:\n",
        "        mean_loss: The average loss over all batches from data_dict.\n",
        "    \"\"\"\n",
        "    start_token = idx_dict['start_token']\n",
        "    end_token = idx_dict['end_token']\n",
        "    char_to_index = idx_dict['char_to_index']\n",
        "\n",
        "    losses = []\n",
        "    for key in data_dict:\n",
        "        input_strings, target_strings = zip(*data_dict[key])\n",
        "        input_tensors = [torch.LongTensor(string_to_index_list(s, char_to_index, end_token)) for s in input_strings]\n",
        "        target_tensors = [torch.LongTensor(string_to_index_list(s, char_to_index, end_token)) for s in target_strings]\n",
        "\n",
        "        num_tensors = len(input_tensors)\n",
        "        num_batches = int(np.ceil(num_tensors / float(opts.batch_size)))\n",
        "\n",
        "        for i in range(num_batches):\n",
        "\n",
        "            start = i * opts.batch_size\n",
        "            end = start + opts.batch_size\n",
        "\n",
        "            inputs = to_var(torch.stack(input_tensors[start:end]), opts.cuda)\n",
        "            targets = to_var(torch.stack(target_tensors[start:end]), opts.cuda)\n",
        "\n",
        "            # The batch size may be different in each epoch\n",
        "            BS = inputs.size(0)\n",
        "\n",
        "            encoder_annotations, encoder_hidden = encoder(inputs)\n",
        "\n",
        "            # The last hidden state of the encoder becomes the first hidden state of the decoder\n",
        "            decoder_hidden = encoder_hidden\n",
        "\n",
        "            start_vector = torch.ones(BS).long().unsqueeze(1) * start_token  # BS x 1 --> 16x1  CHECKED\n",
        "            decoder_input = to_var(start_vector, opts.cuda)  # BS x 1 --> 16x1  CHECKED\n",
        "\n",
        "            loss = 0.0\n",
        "\n",
        "            seq_len = targets.size(1)  # Gets seq_len from BS x seq_len\n",
        "\n",
        "            decoder_inputs = torch.cat([decoder_input, targets[:, 0:-1]], dim=1)  # Gets decoder inputs by shifting the targets to the right \n",
        "            \n",
        "            decoder_outputs, attention_weights = decoder(decoder_inputs, encoder_annotations, encoder_hidden)\n",
        "            decoder_outputs_flatten = decoder_outputs.view(-1, decoder_outputs.size(2))\n",
        "            targets_flatten = targets.view(-1)\n",
        "            loss = criterion(decoder_outputs_flatten, targets_flatten)\n",
        "\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            ## training if an optimizer is provided\n",
        "            if optimizer:\n",
        "              # Zero gradients\n",
        "              optimizer.zero_grad()\n",
        "              # Compute gradients\n",
        "              loss.backward()\n",
        "              # Update the parameters of the encoder and decoder\n",
        "              optimizer.step()\n",
        "              \n",
        "    mean_loss = np.mean(losses)\n",
        "    return mean_loss\n",
        "\n",
        "  \n",
        "\n",
        "def training_loop(train_dict, val_dict, idx_dict, encoder, decoder, criterion, optimizer, opts):\n",
        "    \"\"\"Runs the main training loop; evaluates the model on the val set every epoch.\n",
        "        * Prints training and val loss each epoch.\n",
        "        * Prints qualitative translation results each epoch using TEST_SENTENCE\n",
        "        * Saves an attention map for TEST_WORD_ATTN each epoch\n",
        "\n",
        "    Arguments:\n",
        "        train_dict: The training word pairs, organized by source and target lengths.\n",
        "        val_dict: The validation word pairs, organized by source and target lengths.\n",
        "        idx_dict: Contains char-to-index and index-to-char mappings, and start & end token indexes.\n",
        "        encoder: An encoder model to produce annotations for each step of the input sequence.\n",
        "        decoder: A decoder model (with or without attention) to generate output tokens.\n",
        "        criterion: Used to compute the CrossEntropyLoss for each decoder output.\n",
        "        optimizer: Implements a step rule to update the parameters of the encoder and decoder.\n",
        "        opts: The command-line arguments.\n",
        "    \"\"\"\n",
        "\n",
        "    start_token = idx_dict['start_token']\n",
        "    end_token = idx_dict['end_token']\n",
        "    char_to_index = idx_dict['char_to_index']\n",
        "\n",
        "    loss_log = open(os.path.join(opts.checkpoint_path, 'loss_log.txt'), 'w')\n",
        "\n",
        "    best_val_loss = 1e6\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    for epoch in range(opts.nepochs):\n",
        "\n",
        "        optimizer.param_groups[0]['lr'] *= opts.lr_decay\n",
        "        \n",
        "        train_loss = compute_loss(train_dict, encoder, decoder, idx_dict, criterion, optimizer, opts)\n",
        "        val_loss = compute_loss(val_dict, encoder, decoder, idx_dict, criterion, None, opts)\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            checkpoint(encoder, decoder, idx_dict, opts)\n",
        "\n",
        "        gen_string = translate_sentence(TEST_SENTENCE, encoder, decoder, idx_dict, opts)\n",
        "        print(\"Epoch: {:3d} | Train loss: {:.3f} | Val loss: {:.3f} | Gen: {:20s}\".format(epoch, train_loss, val_loss, gen_string))\n",
        "\n",
        "        loss_log.write('{} {} {}\\n'.format(epoch, train_loss, val_loss))\n",
        "        loss_log.flush()\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "\n",
        "        save_loss_plot(train_losses, val_losses, opts)\n",
        "\n",
        "\n",
        "def print_data_stats(line_pairs, vocab_size, idx_dict):\n",
        "    \"\"\"Prints example word pairs, the number of data points, and the vocabulary.\n",
        "    \"\"\"\n",
        "    print('=' * 80)\n",
        "    print('Data Stats'.center(80))\n",
        "    print('-' * 80)\n",
        "    for pair in line_pairs[:5]:\n",
        "        print(pair)\n",
        "    print('Num unique word pairs: {}'.format(len(line_pairs)))\n",
        "    print('Vocabulary: {}'.format(idx_dict['char_to_index'].keys()))\n",
        "    print('Vocab size: {}'.format(vocab_size))\n",
        "    print('=' * 80)\n",
        "\n",
        "\n",
        "def train(opts):\n",
        "    line_pairs, vocab_size, idx_dict = load_data()\n",
        "    print_data_stats(line_pairs, vocab_size, idx_dict)\n",
        "\n",
        "    # Split the line pairs into an 80% train and 20% val split\n",
        "    num_lines = len(line_pairs)\n",
        "    num_train = int(0.8 * num_lines)\n",
        "    train_pairs, val_pairs = line_pairs[:num_train], line_pairs[num_train:]\n",
        "\n",
        "    # Group the data by the lengths of the source and target words, to form batches\n",
        "    train_dict = create_dict(train_pairs)\n",
        "    val_dict = create_dict(val_pairs)\n",
        "\n",
        "    ##########################################################################\n",
        "    ### Setup: Create Encoder, Decoder, Learning Criterion, and Optimizers ###\n",
        "    ##########################################################################\n",
        "    encoder = GRUEncoder(vocab_size=vocab_size, \n",
        "                         hidden_size=opts.hidden_size, \n",
        "                         opts=opts)\n",
        "\n",
        "    if opts.decoder_type == 'rnn':\n",
        "        decoder = RNNDecoder(vocab_size=vocab_size, \n",
        "                             hidden_size=opts.hidden_size)\n",
        "    elif opts.decoder_type == 'rnn_attention':\n",
        "        decoder = RNNAttentionDecoder(vocab_size=vocab_size, \n",
        "                                      hidden_size=opts.hidden_size, \n",
        "                                      attention_type=opts.attention_type)\n",
        "    elif opts.decoder_type == 'transformer':\n",
        "        decoder = TransformerDecoder(vocab_size=vocab_size, \n",
        "                                     hidden_size=opts.hidden_size, \n",
        "                                     num_layers=opts.num_transformer_layers)\n",
        "    else:\n",
        "        raise NotImplementedError\n",
        "        \n",
        "    #### setup checkpoint path\n",
        "    model_name = 'h{}-bs{}-{}'.format(opts.hidden_size, \n",
        "                                      opts.batch_size, \n",
        "                                      opts.decoder_type)\n",
        "    opts.checkpoint_path = model_name\n",
        "    create_dir_if_not_exists(opts.checkpoint_path)\n",
        "    ####\n",
        "\n",
        "    if opts.cuda:\n",
        "        encoder.cuda()\n",
        "        decoder.cuda()\n",
        "        print(\"Moved models to GPU!\")\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=opts.learning_rate)\n",
        "\n",
        "    try:\n",
        "        training_loop(train_dict, val_dict, idx_dict, encoder, decoder, criterion, optimizer, opts)\n",
        "    except KeyboardInterrupt:\n",
        "        print('Exiting early from training.')\n",
        "        return encoder, decoder\n",
        "      \n",
        "    return encoder, decoder\n",
        "\n",
        "\n",
        "def print_opts(opts):\n",
        "    \"\"\"Prints the values of all command-line arguments.\n",
        "    \"\"\"\n",
        "    print('=' * 80)\n",
        "    print('Opts'.center(80))\n",
        "    print('-' * 80)\n",
        "    for key in opts.__dict__:\n",
        "        print('{:>30}: {:<30}'.format(key, opts.__dict__[key]).center(80))\n",
        "    print('=' * 80)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bXNsLNkOn38w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Your code for NMT models"
      ]
    },
    {
      "metadata": {
        "id": "_BAfi_8yWB3y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## GRU cell"
      ]
    },
    {
      "metadata": {
        "id": "9ztmyA5Ro67o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class MyGRUCell(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(MyGRUCell, self).__init__()\n",
        "\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.W_i = nn.Linear(self.input_size, self.hidden_size)\n",
        "        self.W_h = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "        \n",
        "\n",
        "\n",
        "    def forward(self, x, h_prev):\n",
        "        \"\"\"Forward pass of the GRU computation for one time step.\n",
        "\n",
        "        Arguments\n",
        "            x: batch_size x input_size\n",
        "            h_prev: batch_size x hidden_size\n",
        "\n",
        "        Returns:\n",
        "            h_new: batch_size x hidden_size\n",
        "        \"\"\"\n",
        "\n",
        "        z = F.sigmoid(self.W_i(x) + self.W_h(h_prev))\n",
        "        r = F.sigmoid(self.W_i(x) + self.W_h(h_prev))\n",
        "        g = F.tanh(self.W_i(x) + r * (self.W_h(h_prev)))\n",
        "        h_new = (1 - z) * g + z * h_prev\n",
        "        return h_new\n",
        "\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-JBVFLEZWNC1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### GRU encoder / decoder"
      ]
    },
    {
      "metadata": {
        "id": "xaDt7XDmWRzC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class GRUEncoder(nn.Module):\n",
        "    def __init__(self, vocab_size, hidden_size, opts):\n",
        "        super(GRUEncoder, self).__init__()\n",
        "\n",
        "        self.vocab_size = vocab_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.opts = opts\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
        "        self.gru = nn.GRUCell(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        \"\"\"Forward pass of the encoder RNN.\n",
        "\n",
        "        Arguments:\n",
        "            inputs: Input token indexes across a batch for all time steps in the sequence. (batch_size x seq_len)\n",
        "\n",
        "        Returns:\n",
        "            annotations: The hidden states computed at each step of the input sequence. (batch_size x seq_len x hidden_size)\n",
        "            hidden: The final hidden state of the encoder, for each sequence in a batch. (batch_size x hidden_size)\n",
        "        \"\"\"\n",
        "\n",
        "        batch_size, seq_len = inputs.size()\n",
        "        hidden = self.init_hidden(batch_size)\n",
        "\n",
        "        encoded = self.embedding(inputs)  # batch_size x seq_len x hidden_size\n",
        "        annotations = []\n",
        "\n",
        "        for i in range(seq_len):\n",
        "            x = encoded[:,i,:]  # Get the current time step, across the whole batch\n",
        "            hidden = self.gru(x, hidden)\n",
        "            annotations.append(hidden)\n",
        "\n",
        "        annotations = torch.stack(annotations, dim=1)\n",
        "        return annotations, hidden\n",
        "\n",
        "    def init_hidden(self, bs):\n",
        "        \"\"\"Creates a tensor of zeros to represent the initial hidden states\n",
        "        of a batch of sequences.\n",
        "\n",
        "        Arguments:\n",
        "            bs: The batch size for the initial hidden state.\n",
        "\n",
        "        Returns:\n",
        "            hidden: An initial hidden state of all zeros. (batch_size x hidden_size)\n",
        "        \"\"\"\n",
        "        return to_var(torch.zeros(bs, self.hidden_size), self.opts.cuda)\n",
        "\n",
        "\n",
        "class RNNDecoder(nn.Module):\n",
        "    def __init__(self, vocab_size, hidden_size):\n",
        "        super(RNNDecoder, self).__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
        "        self.rnn = nn.GRUCell(input_size=hidden_size, hidden_size=hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, inputs, annotations, hidden_init):\n",
        "        \"\"\"Forward pass of the non-attentional decoder RNN.\n",
        "\n",
        "        Arguments:\n",
        "            inputs: Input token indexes across a batch. (batch_size x seq_len)\n",
        "            annotations: This is not used here. It just maintains consistency with the\n",
        "                    interface used by the AttentionDecoder class.\n",
        "            hidden_init: The hidden states from the last step of encoder, across a batch. (batch_size x hidden_size)\n",
        "\n",
        "        Returns:\n",
        "            output: Un-normalized scores for each token in the vocabulary, across a batch for all the decoding time steps. (batch_size x decoder_seq_len x vocab_size)\n",
        "            None\n",
        "        \"\"\"        \n",
        "        batch_size, seq_len = inputs.size()\n",
        "        embed = self.embedding(inputs)  # batch_size x seq_len x hidden_size        \n",
        "\n",
        "        hiddens = []\n",
        "        h_prev = hidden_init\n",
        "        for i in range(seq_len):\n",
        "            x = embed[:,i,:]  # Get the current time step input tokens, across the whole batch\n",
        "            h_prev = self.rnn(x, h_prev)  # batch_size x hidden_size\n",
        "            hiddens.append(h_prev)\n",
        "\n",
        "        hiddens = torch.stack(hiddens, dim=1) # batch_size x seq_len x hidden_size\n",
        "        \n",
        "        output = self.out(hiddens)  # batch_size x seq_len x vocab_size\n",
        "        return output, None      \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tWe0RO5FWajD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Attention"
      ]
    },
    {
      "metadata": {
        "id": "9GUK5A7CWhV8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class AdditiveAttention(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(AdditiveAttention, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # A two layer fully-connected network\n",
        "        # hidden_size*2 --> hidden_size, ReLU, hidden_size --> 1\n",
        "        self.attention_network = nn.Sequential(\n",
        "                                    nn.Linear(hidden_size*2, hidden_size),\n",
        "                                    nn.ReLU(),\n",
        "                                    nn.Linear(hidden_size, 1)\n",
        "                                 )\n",
        "\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, queries, keys, values):\n",
        "        \"\"\"The forward pass of the additive attention mechanism.\n",
        "\n",
        "        Arguments:\n",
        "            queries: The current decoder hidden state. (batch_size x hidden_size)\n",
        "            keys: The encoder hidden states for each step of the input sequence. (batch_size x seq_len x hidden_size)\n",
        "            values: The encoder hidden states for each step of the input sequence. (batch_size x seq_len x hidden_size)\n",
        "\n",
        "        Returns:\n",
        "            context: weighted average of the values (batch_size x 1 x hidden_size)\n",
        "            attention_weights: Normalized attention weights for each encoder hidden state. (batch_size x seq_len x 1)\n",
        "\n",
        "            The attention_weights must be a softmax weighting over the seq_len annotations.\n",
        "        \"\"\"\n",
        "\n",
        "        # ------------\n",
        "        # FILL THIS IN\n",
        "        # ------------\n",
        "        # batch_size = ...\n",
        "        # expanded_queries = ...\n",
        "        # concat_inputs = ...\n",
        "        # unnormalized_attention = ...\n",
        "        # attention_weights = ...\n",
        "        # context = ...\n",
        "        # return context, attention_weight\n",
        "        batch_size, seq_len, hidden_size = keys.size()\n",
        "        expanded_queries = queries.unsqueeze(1).expand_as(keys)\n",
        "        concat_inputs = torch.cat((expanded_queries, keys), 2)\n",
        "        reshape = concat_inputs.view(batch_size * seq_len, 2 * hidden_size)\n",
        "        unnormalized_attention = self.attention_network(reshape).view(batch_size, seq_len, 1) \n",
        "        attention_weights = self.softmax(unnormalized_attention)\n",
        "        context = torch.bmm(attention_weights.view(batch_size, 1, seq_len), values)\n",
        "        return context, attention_weights\n",
        "      \n",
        "      \n",
        "\n",
        "class ScaledDotAttention(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(ScaledDotAttention, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.Q = nn.Linear(hidden_size, hidden_size)\n",
        "        self.K = nn.Linear(hidden_size, hidden_size)\n",
        "        self.V = nn.Linear(hidden_size, hidden_size)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "        self.scaling_factor = torch.rsqrt(torch.tensor(self.hidden_size, dtype= torch.float))\n",
        "\n",
        "    def forward(self, queries, keys, values):\n",
        "        \"\"\"The forward pass of the scaled dot attention mechanism.\n",
        "\n",
        "        Arguments:\n",
        "            queries: The current decoder hidden state, 2D or 3D tensor. (batch_size x (k) x hidden_size)\n",
        "            keys: The encoder hidden states for each step of the input sequence. (batch_size x seq_len x hidden_size)\n",
        "            values: The encoder hidden states for each step of the input sequence. (batch_size x seq_len x hidden_size)\n",
        "\n",
        "        Returns:\n",
        "            context: weighted average of the values (batch_size x k x hidden_size)\n",
        "            attention_weights: Normalized attention weights for each encoder hidden state. (batch_size x seq_len x 1)\n",
        "\n",
        "            The output must be a softmax weighting over the seq_len annotations.\n",
        "        \"\"\"\n",
        "\n",
        "        batch_size, seq_len, hidden_size = keys.size()\n",
        "        q = self.Q(queries)\n",
        "        k = self.K(keys)\n",
        "        v = self.V(values)\n",
        "        q = q.view(batch_size, 1, hidden_size) if len(q.size()) == 2 else q\n",
        "        reshape = torch.bmm(k, torch.transpose(q, 1, 2))\n",
        "        unnormalized_attention = reshape * self.scaling_factor\n",
        "        attention_weights = self.softmax(unnormalized_attention)\n",
        "        context = torch.bmm(torch.transpose(attention_weights,1,2), v)\n",
        "        return context, attention_weights\n",
        "\n",
        "      \n",
        "      \n",
        "class CausalScaledDotAttention(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(CausalScaledDotAttention, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        self.neg_inf = torch.tensor(-1e7)\n",
        "\n",
        "        self.Q = nn.Linear(hidden_size, hidden_size)\n",
        "        self.K = nn.Linear(hidden_size, hidden_size)\n",
        "        self.V = nn.Linear(hidden_size, hidden_size)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "        self.scaling_factor = torch.rsqrt(torch.tensor(self.hidden_size, dtype= torch.float))\n",
        "\n",
        "    def forward(self, queries, keys, values):\n",
        "        \"\"\"The forward pass of the scaled dot attention mechanism.\n",
        "\n",
        "        Arguments:\n",
        "            queries: The current decoder hidden state, 2D or 3D tensor. (batch_size x (k) x hidden_size)\n",
        "            keys: The encoder hidden states for each step of the input sequence. (batch_size x seq_len x hidden_size)\n",
        "            values: The encoder hidden states for each step of the input sequence. (batch_size x seq_len x hidden_size)\n",
        "\n",
        "        Returns:\n",
        "            context: weighted average of the values (batch_size x k x hidden_size)\n",
        "            attention_weights: Normalized attention weights for each encoder hidden state. (batch_size x seq_len x 1)\n",
        "\n",
        "            The output must be a softmax weighting over the seq_len annotations.\n",
        "        \"\"\"\n",
        "\n",
        "        batch_size, seq_len, hidden_size = keys.size()\n",
        "        k = self.K(keys)\n",
        "        v = self.V(values)\n",
        "        q = self.Q(queries).view(batch_size, 1, hidden_size) if len(self.Q(queries).size()) == 2 else self.Q(queries)\n",
        "   \n",
        "        k_size = q.size()[1]\n",
        "        \n",
        "        unnormalized_attention = torch.bmm(q, torch.transpose(k, 1, 2)) * self.scaling_factor\n",
        "        mask = torch.tril(torch.ones((seq_len, k_size), dtype=torch.uint8), diagonal=k_size-seq_len).cuda().unsqueeze(0).expand(batch_size, -1, -1)\n",
        "        unnormalized_attention = unnormalized_attention.masked_fill(mask, self.neg_inf)\n",
        "        attention_weights = self.softmax(unnormalized_attention)\n",
        "        context = torch.bmm(torch.transpose(attention_weights, 1, 2), v)\n",
        "        return context, attention_weights\n",
        "        \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pemjZo2XWtRt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Attention decoder"
      ]
    },
    {
      "metadata": {
        "id": "PfjF0Z-PWwPv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class RNNAttentionDecoder(nn.Module):\n",
        "    def __init__(self, vocab_size, hidden_size, attention_type='scaled_dot'):\n",
        "        super(RNNAttentionDecoder, self).__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
        "\n",
        "        self.rnn = MyGRUCell(input_size=hidden_size*2, hidden_size=hidden_size)\n",
        "        if attention_type == 'additive':\n",
        "          self.attention = AdditiveAttention(hidden_size=hidden_size)\n",
        "        elif attention_type == 'scaled_dot':\n",
        "          self.attention = ScaledDotAttention(hidden_size=hidden_size)\n",
        "        \n",
        "        self.out = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "        \n",
        "    def forward(self, inputs, annotations, hidden_init):\n",
        "        \"\"\"Forward pass of the attention-based decoder RNN.\n",
        "\n",
        "        Arguments:\n",
        "            inputs: Input token indexes across a batch for all the time step. (batch_size x decoder_seq_len)\n",
        "            annotations: The encoder hidden states for each step of the input.\n",
        "                         sequence. (batch_size x seq_len x hidden_size)\n",
        "            hidden_init: The final hidden states from the encoder, across a batch. (batch_size x hidden_size)\n",
        "\n",
        "        Returns:\n",
        "            output: Un-normalized scores for each token in the vocabulary, across a batch for all the decoding time steps. (batch_size x decoder_seq_len x vocab_size)\n",
        "            attentions: The stacked attention weights applied to the encoder annotations (batch_size x encoder_seq_len x decoder_seq_len)\n",
        "        \"\"\"\n",
        "        \n",
        "        batch_size, seq_len = inputs.size()\n",
        "        embed = self.embedding(inputs)  # batch_size x seq_len x hidden_size        \n",
        "\n",
        "        hiddens = []\n",
        "        attentions = []\n",
        "        h_prev = hidden_init\n",
        "        for i in range(seq_len):\n",
        "            embed_current = embed[:,i,:].squeeze(1)\n",
        "            context, attention_weights = self.attention.forward(h_prev, annotations, annotations)\n",
        "            embed_and_context = torch.cat((context.squeeze(1), embed_current), 1) \n",
        "            h_prev = self.rnn.forward(embed_and_context, h_prev)\n",
        "\n",
        "            hiddens.append(h_prev)\n",
        "            attentions.append(attention_weights)\n",
        "\n",
        "        hiddens = torch.stack(hiddens, dim=1) # batch_size x seq_len x hidden_size\n",
        "        attentions = torch.cat(attentions, dim=2) # batch_size x seq_len x seq_len\n",
        "        \n",
        "        output = self.out(hiddens)  # batch_size x seq_len x vocab_size\n",
        "        return output, attentions\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N8JpcwTRW5cw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Transformer decoder"
      ]
    },
    {
      "metadata": {
        "id": "V5vJPku1W7sz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class TransformerDecoder(nn.Module):\n",
        "    def __init__(self, vocab_size, hidden_size, num_layers):\n",
        "        super(TransformerDecoder, self).__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, hidden_size)        \n",
        "        self.num_layers = num_layers\n",
        "        \n",
        "        self.self_attentions = nn.ModuleList([CausalScaledDotAttention(\n",
        "                                    hidden_size=hidden_size, \n",
        "                                 ) for i in range(self.num_layers)])\n",
        "        self.encoder_attentions = nn.ModuleList([ScaledDotAttention(\n",
        "                                    hidden_size=hidden_size, \n",
        "                                 ) for i in range(self.num_layers)])\n",
        "        self.attention_mlps = nn.ModuleList([nn.Sequential(\n",
        "                                    nn.Linear(hidden_size, hidden_size),\n",
        "                                    nn.ReLU(),\n",
        "                                 ) for i in range(self.num_layers)])\n",
        "        self.out = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "        \n",
        "    def forward(self, inputs, annotations, hidden_init):\n",
        "        \"\"\"Forward pass of the attention-based decoder RNN.\n",
        "\n",
        "        Arguments:\n",
        "            inputs: Input token indexes across a batch for all the time step. (batch_size x decoder_seq_len)\n",
        "            annotations: The encoder hidden states for each step of the input.\n",
        "                         sequence. (batch_size x seq_len x hidden_size)\n",
        "            hidden_init: Not used in the transformer decoder\n",
        "        Returns:\n",
        "            output: Un-normalized scores for each token in the vocabulary, across a batch for all the decoding time steps. (batch_size x decoder_seq_len x vocab_size)\n",
        "            attentions: The stacked attention weights applied to the encoder annotations (batch_size x encoder_seq_len x decoder_seq_len)\n",
        "        \"\"\"\n",
        "        \n",
        "        batch_size, seq_len = inputs.size()\n",
        "        embed = self.embedding(inputs)  # batch_size x seq_len x hidden_size        \n",
        "\n",
        "        encoder_attention_weights_list = []\n",
        "        self_attention_weights_list = []\n",
        "        contexts = embed\n",
        "        for i in range(self.num_layers):\n",
        "          new_contexts, self_attention_weights = \\\n",
        "            self.self_attentions[i](contexts, contexts, contexts)\n",
        "          residual_contexts = contexts + new_contexts\n",
        "          new_contexts, encoder_attention_weights = \\\n",
        "            self.encoder_attentions[i](residual_contexts, annotations, annotations)\n",
        "          residual_contexts = residual_contexts + new_contexts\n",
        "          new_contexts = self.attention_mlps[i](residual_contexts)\n",
        "          contexts = residual_contexts + new_contexts + contexts\n",
        "          encoder_attention_weights_list.append(encoder_attention_weights)\n",
        "          self_attention_weights_list.append(self_attention_weights)\n",
        "          encoder_attention_weights_list.append(encoder_attention_weights)\n",
        "          self_attention_weights_list.append(self_attention_weights)\n",
        "          \n",
        "        output = self.out(contexts)\n",
        "        encoder_attention_weights = torch.stack(encoder_attention_weights_list)\n",
        "        self_attention_weights = torch.stack(self_attention_weights_list)\n",
        "        \n",
        "        return output, (encoder_attention_weights, self_attention_weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XuNFd6LNo0-o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Training\n"
      ]
    },
    {
      "metadata": {
        "id": "BkPEyIjS_pAk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kiUwiOITHTW4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Download dataset"
      ]
    },
    {
      "metadata": {
        "id": "xwcFjsEpHRbI",
        "colab_type": "code",
        "outputId": "416f9ac4-8717-44d8-c2b1-17e6fbfe8fef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "######################################################################\n",
        "# Download Translation datasets\n",
        "######################################################################\n",
        "data_fpath = get_file(fname='pig_latin_data.txt', \n",
        "                         origin='http://www.cs.toronto.edu/~jba/pig_latin_data.txt', \n",
        "                         untar=False)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data/pig_latin_data.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hmQmyJDSRFKR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## RNN decoder"
      ]
    },
    {
      "metadata": {
        "id": "0LKaRF1jwhH7",
        "colab_type": "code",
        "outputId": "27263cb6-be89-469c-adfe-b6f96685e1e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2260
        }
      },
      "cell_type": "code",
      "source": [
        "TEST_SENTENCE = 'the air conditioning is working'\n",
        "\n",
        "args = AttrDict()\n",
        "args_dict = {\n",
        "              'cuda':True, \n",
        "              'nepochs':100, \n",
        "              'checkpoint_dir':\"checkpoints\", \n",
        "              'learning_rate':0.005, \n",
        "              'lr_decay':0.99,\n",
        "              'batch_size':64, \n",
        "              'hidden_size':20, \n",
        "              'decoder_type': 'rnn', # options: rnn / rnn_attention / transformer\n",
        "              'attention_type': '',  # options: additive / scaled_dot\n",
        "}\n",
        "args.update(args_dict)\n",
        "\n",
        "print_opts(args)\n",
        "rnn_encoder, rnn_decoder = train(args)\n",
        "\n",
        "translated = translate_sentence(TEST_SENTENCE, rnn_encoder, rnn_decoder, None, args)\n",
        "print(\"source:\\t\\t{} \\ntranslated:\\t{}\".format(TEST_SENTENCE, translated))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "                                      Opts                                      \n",
            "--------------------------------------------------------------------------------\n",
            "                            hidden_size: 20                                     \n",
            "                          learning_rate: 0.005                                  \n",
            "                             batch_size: 64                                     \n",
            "                                nepochs: 100                                    \n",
            "                                   cuda: 1                                      \n",
            "                         checkpoint_dir: checkpoints                            \n",
            "                           decoder_type: rnn                                    \n",
            "                               lr_decay: 0.99                                   \n",
            "                         attention_type:                                        \n",
            "================================================================================\n",
            "================================================================================\n",
            "                                   Data Stats                                   \n",
            "--------------------------------------------------------------------------------\n",
            "('payment', 'aymentpay')\n",
            "('ordination', 'ordinationway')\n",
            "('amends', 'amendsway')\n",
            "('principally', 'incipallypray')\n",
            "('anybody', 'anybodyway')\n",
            "Num unique word pairs: 6387\n",
            "Vocabulary: ['EOS', '-', 'SOS', 'a', 'c', 'b', 'e', 'd', 'g', 'f', 'i', 'h', 'k', 'j', 'm', 'l', 'o', 'n', 'q', 'p', 's', 'r', 'u', 't', 'w', 'v', 'y', 'x', 'z']\n",
            "Vocab size: 29\n",
            "================================================================================\n",
            "Moved models to GPU!\n",
            "Epoch:   0 | Train loss: 2.416 | Val loss: 2.025 | Gen: eray ateray ereray eray ereray\n",
            "Epoch:   1 | Train loss: 1.945 | Val loss: 1.861 | Gen: ereray areray ereray ingsay ereray\n",
            "Epoch:   2 | Train loss: 1.791 | Val loss: 1.759 | Gen: esteray aredsay ongheray inghedway ongheray\n",
            "Epoch:   3 | Train loss: 1.689 | Val loss: 1.698 | Gen: estay aredway onterestay inghtay onterestay\n",
            "Epoch:   4 | Train loss: 1.617 | Val loss: 1.652 | Gen: estay aredway ontertedway inghay onteredway\n",
            "Epoch:   5 | Train loss: 1.561 | Val loss: 1.617 | Gen: estay aredway ontertedway ingray ortionday\n",
            "Epoch:   6 | Train loss: 1.514 | Val loss: 1.589 | Gen: estay arway ontertedway iseray ortinghay\n",
            "Epoch:   7 | Train loss: 1.469 | Val loss: 1.551 | Gen: estay aredway ontingstay iseray oringray\n",
            "Epoch:   8 | Train loss: 1.428 | Val loss: 1.527 | Gen: estay aredway ontingstay isesay orkedsay\n",
            "Epoch:   9 | Train loss: 1.396 | Val loss: 1.506 | Gen: estay aredway ontingstay isesay orkedway\n",
            "Epoch:  10 | Train loss: 1.369 | Val loss: 1.474 | Gen: estay areray ontingstay isesay orkedway\n",
            "Epoch:  11 | Train loss: 1.340 | Val loss: 1.461 | Gen: estay armay ontingstay isesay ordray\n",
            "Epoch:  12 | Train loss: 1.317 | Val loss: 1.444 | Gen: estay armay ontingsay ishay ordedway\n",
            "Epoch:  13 | Train loss: 1.307 | Val loss: 1.461 | Gen: estay armay ontingsay ishay orkedway\n",
            "Epoch:  14 | Train loss: 1.279 | Val loss: 1.421 | Gen: estay armay ontingsay isay ordedway\n",
            "Epoch:  15 | Train loss: 1.250 | Val loss: 1.389 | Gen: estay arimay ontingsay ishay orkedway\n",
            "Epoch:  16 | Train loss: 1.224 | Val loss: 1.388 | Gen: estay arimay ontingsay ishay orkedway\n",
            "Epoch:  17 | Train loss: 1.212 | Val loss: 1.379 | Gen: esthay arimay ontingsay ishay onkerday\n",
            "Epoch:  18 | Train loss: 1.208 | Val loss: 1.368 | Gen: estay arimedway ontingsay ishay orkedray\n",
            "Epoch:  19 | Train loss: 1.180 | Val loss: 1.348 | Gen: estay airedway oningtay-othingway isay overdyway\n",
            "Epoch:  20 | Train loss: 1.177 | Val loss: 1.354 | Gen: esthay airedway ontingsay isay overednay\n",
            "Epoch:  21 | Train loss: 1.148 | Val loss: 1.331 | Gen: estray airedway ontingsay ishay overdlay\n",
            "Epoch:  22 | Train loss: 1.135 | Val loss: 1.335 | Gen: eshay airday ontingsay isay overnedsay\n",
            "Epoch:  23 | Train loss: 1.136 | Val loss: 1.313 | Gen: estray airday oningtay-othingway isay overednay\n",
            "Epoch:  24 | Train loss: 1.119 | Val loss: 1.306 | Gen: eshay airday ontingtay-othingway isay overentway\n",
            "Epoch:  25 | Train loss: 1.098 | Val loss: 1.304 | Gen: eshay airday oningtray ishay overnedsay\n",
            "Epoch:  26 | Train loss: 1.086 | Val loss: 1.290 | Gen: eshay airday oninglay-othingway isay overendsay\n",
            "Epoch:  27 | Train loss: 1.079 | Val loss: 1.296 | Gen: eshay aireway oningtray-onday-inse isay overendsay\n",
            "Epoch:  28 | Train loss: 1.063 | Val loss: 1.271 | Gen: eshay airday oningtray issay overendsay\n",
            "Epoch:  29 | Train loss: 1.059 | Val loss: 1.286 | Gen: eshay aireway oningstray issay overingway\n",
            "Epoch:  30 | Train loss: 1.050 | Val loss: 1.268 | Gen: eshay aireway oningtray issay overdingway\n",
            "Epoch:  31 | Train loss: 1.043 | Val loss: 1.263 | Gen: eshay aireway oninglay-othay-inces issay orverybay\n",
            "Epoch:  32 | Train loss: 1.055 | Val loss: 1.287 | Gen: eshay aiedway ontionturedway issay overdingway\n",
            "Epoch:  33 | Train loss: 1.064 | Val loss: 1.299 | Gen: ethay airedway oninglay-estay-inses ishay ovingedway\n",
            "Epoch:  34 | Train loss: 1.034 | Val loss: 1.278 | Gen: eshay aiedway oninglay-othingway issay orkentway\n",
            "Epoch:  35 | Train loss: 1.021 | Val loss: 1.262 | Gen: eshay aiedway oningstray issay orkentway\n",
            "Epoch:  36 | Train loss: 1.002 | Val loss: 1.246 | Gen: eshay aiedway oningtray-obationswa issay orkentray\n",
            "Epoch:  37 | Train loss: 0.994 | Val loss: 1.243 | Gen: eshay aiedway oningstray issay orkendsay\n",
            "Epoch:  38 | Train loss: 0.978 | Val loss: 1.238 | Gen: eshay aiedway oninglay-othay-othin isway orkentray\n",
            "Epoch:  39 | Train loss: 1.004 | Val loss: 1.233 | Gen: eshay aiedway onginglay-andway issay orkendsay\n",
            "Epoch:  40 | Train loss: 0.972 | Val loss: 1.237 | Gen: eshay aiedray onginglay-andway issay orkendsay\n",
            "Epoch:  41 | Train loss: 0.960 | Val loss: 1.230 | Gen: eshay aiedway oningstray issay orkendsay\n",
            "Epoch:  42 | Train loss: 0.963 | Val loss: 1.220 | Gen: eshay aiedway onginglay-andway issay orkendsay\n",
            "Epoch:  43 | Train loss: 0.956 | Val loss: 1.223 | Gen: eshay aiedway onginglay-andway issay orkendsay\n",
            "Epoch:  44 | Train loss: 0.952 | Val loss: 1.224 | Gen: eshay aiedray onginglay-ondway issay orkendsay\n",
            "Epoch:  45 | Train loss: 0.933 | Val loss: 1.214 | Gen: eshay aiedray onginglay-andway issay orkendsay\n",
            "Epoch:  46 | Train loss: 0.946 | Val loss: 1.203 | Gen: eshay aiedway onginglay-andway issay orkendsay\n",
            "Epoch:  47 | Train loss: 0.927 | Val loss: 1.201 | Gen: eshay aireway onginglay-andway issay orkendsay\n",
            "Epoch:  48 | Train loss: 0.923 | Val loss: 1.216 | Gen: eshay aiedway onginglay-andway issay orkendsay\n",
            "Epoch:  49 | Train loss: 0.922 | Val loss: 1.208 | Gen: eshay aiedway ondingstay-orfay-oth issay orkendshay\n",
            "Epoch:  50 | Train loss: 0.903 | Val loss: 1.192 | Gen: eshay aiedway onginglay-andway issay orkendshay\n",
            "Epoch:  51 | Train loss: 0.934 | Val loss: 1.189 | Gen: eshay aiedway ongingssay issay orkendsay\n",
            "Epoch:  52 | Train loss: 0.917 | Val loss: 1.183 | Gen: eshay aiedway ondingstay-orfray isay orkendway\n",
            "Epoch:  53 | Train loss: 0.903 | Val loss: 1.177 | Gen: eshay aiedway ondingstay issay orkendway\n",
            "Epoch:  54 | Train loss: 0.888 | Val loss: 1.173 | Gen: etay aiedway ondingstay-orfay-ort issay orkendway\n",
            "Epoch:  55 | Train loss: 0.877 | Val loss: 1.176 | Gen: eshay aiwlay ondingstay-orfay-ort issay orkendway\n",
            "Epoch:  56 | Train loss: 0.876 | Val loss: 1.167 | Gen: etay aiedway ondingstay-orrationc issay orkendsay\n",
            "Epoch:  57 | Train loss: 0.872 | Val loss: 1.189 | Gen: eshay aiedway ondingstay-orfay-ort issay orkendway\n",
            "Epoch:  58 | Train loss: 0.927 | Val loss: 1.157 | Gen: eshay aiedway ondingstay isay orkendway\n",
            "Epoch:  59 | Train loss: 0.901 | Val loss: 1.160 | Gen: eshay aiedway ondingstay issay orkednay\n",
            "Epoch:  60 | Train loss: 0.863 | Val loss: 1.156 | Gen: etay aiedway ondingstay issay orkendway\n",
            "Epoch:  61 | Train loss: 0.855 | Val loss: 1.159 | Gen: etay aiedway ondingstay-orfay-igh issay orkednay\n",
            "Epoch:  62 | Train loss: 0.854 | Val loss: 1.163 | Gen: etay aiwlay ondingstay-orratedwa issay orkendway\n",
            "Epoch:  63 | Train loss: 0.883 | Val loss: 1.158 | Gen: etay aiwlay ondingstay isay orkendway\n",
            "Epoch:  64 | Train loss: 0.853 | Val loss: 1.154 | Gen: etay aiwlay ondingtay-orrationca issay orkednay\n",
            "Epoch:  65 | Train loss: 0.842 | Val loss: 1.149 | Gen: etay aiwlay ondingtay-osteray issay orkednay\n",
            "Epoch:  66 | Train loss: 0.838 | Val loss: 1.159 | Gen: etay aiweray ondingtay-orrationca isay orkednay\n",
            "Epoch:  67 | Train loss: 0.830 | Val loss: 1.153 | Gen: etay aiwlay ondingtay-orrationta issay orkednay\n",
            "Epoch:  68 | Train loss: 0.831 | Val loss: 1.151 | Gen: etay aiwlay ondingtay-orsheray issay orkednay\n",
            "Epoch:  69 | Train loss: 0.836 | Val loss: 1.146 | Gen: etay aiwlay ondingtanclyway issay orkednay\n",
            "Epoch:  70 | Train loss: 0.830 | Val loss: 1.165 | Gen: etay aiwlay ondingtay-orrationta issay orkednay\n",
            "Epoch:  71 | Train loss: 0.828 | Val loss: 1.141 | Gen: etay aiedway ondingstay-orratedwa issay orkednay\n",
            "Epoch:  72 | Train loss: 0.819 | Val loss: 1.154 | Gen: etay aiwlay ondingtanclyway issay orkednay\n",
            "Epoch:  73 | Train loss: 0.806 | Val loss: 1.148 | Gen: etay aiwlay ondingtay-orrationta isay orkednay\n",
            "Epoch:  74 | Train loss: 0.810 | Val loss: 1.150 | Gen: etay aiwlay ondingtay-orratecay issay orkednay\n",
            "Epoch:  75 | Train loss: 0.814 | Val loss: 1.154 | Gen: etay aiwlay ondingtay-eartionmay issay orkednay\n",
            "Epoch:  76 | Train loss: 0.815 | Val loss: 1.145 | Gen: etay aiedway ondingtanclyway issay orkingway\n",
            "Epoch:  77 | Train loss: 0.809 | Val loss: 1.130 | Gen: etay aiwlay ondingtay-earteray issay orkingway\n",
            "Epoch:  78 | Train loss: 0.794 | Val loss: 1.139 | Gen: etay aiwlay ondingtanclyway issay orhionmay\n",
            "Epoch:  79 | Train loss: 0.790 | Val loss: 1.134 | Gen: etay aiwlay ondingtanclyway issay orkingway\n",
            "Epoch:  80 | Train loss: 0.788 | Val loss: 1.140 | Gen: etay aiwlay ondingtay-eartingway issay orkingway\n",
            "Epoch:  81 | Train loss: 0.785 | Val loss: 1.130 | Gen: etay aiwlay ondingtanclyway issay orkingway\n",
            "Epoch:  82 | Train loss: 0.781 | Val loss: 1.135 | Gen: etay aiwlay ondintionsmay issay orkingway\n",
            "Epoch:  83 | Train loss: 0.851 | Val loss: 1.136 | Gen: etay aiedway ondingtancedray issway orhionmay\n",
            "Epoch:  84 | Train loss: 0.815 | Val loss: 1.131 | Gen: etay aiwlay ondingtancedray issay orkingday\n",
            "Epoch:  85 | Train loss: 0.781 | Val loss: 1.111 | Gen: etay aiwlay ondintionsmay issay orhionmay\n",
            "Epoch:  86 | Train loss: 0.772 | Val loss: 1.125 | Gen: etay aiwlay ondingtancedray isay orroudtay\n",
            "Epoch:  87 | Train loss: 0.765 | Val loss: 1.111 | Gen: etay aiweray ondintionsmay issay orhionmay\n",
            "Epoch:  88 | Train loss: 0.758 | Val loss: 1.107 | Gen: etay aiwlay ondingtanchedway issay orroudtay\n",
            "Epoch:  89 | Train loss: 0.754 | Val loss: 1.117 | Gen: etay aiweray ondintionsmay issay orhionmay\n",
            "Epoch:  90 | Train loss: 0.756 | Val loss: 1.101 | Gen: etay aiwlay ondingtanchedway issay orkingway\n",
            "Epoch:  91 | Train loss: 0.758 | Val loss: 1.142 | Gen: etay aiweray ondintionsmay issay orhionmay\n",
            "Epoch:  92 | Train loss: 0.755 | Val loss: 1.109 | Gen: etay aiweray ondingtancedray issay orhiouncray\n",
            "Epoch:  93 | Train loss: 0.748 | Val loss: 1.110 | Gen: etay aiweray ondintionsmay issay orhioundray\n",
            "Epoch:  94 | Train loss: 0.756 | Val loss: 1.112 | Gen: etay aiwlay ondingtancedway isay orroudtay\n",
            "Epoch:  95 | Train loss: 0.758 | Val loss: 1.111 | Gen: etay aiwlay ondintionspray issay orkingway\n",
            "Epoch:  96 | Train loss: 0.741 | Val loss: 1.096 | Gen: etay aiwlay ondintionspay issay orroudtay\n",
            "Epoch:  97 | Train loss: 0.741 | Val loss: 1.120 | Gen: etay aiwlay ondingtancedray isay orhioundray\n",
            "Epoch:  98 | Train loss: 0.740 | Val loss: 1.107 | Gen: etay aiedway ondintionspay issay orroudtay\n",
            "Epoch:  99 | Train loss: 0.830 | Val loss: 1.117 | Gen: etay aiwlay ondintedspay issay orhionmay\n",
            "source:\t\tthe air conditioning is working \n",
            "translated:\tetay aiwlay ondintedspay issay orhionmay\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "p2kPGj5DFv7a",
        "colab_type": "code",
        "outputId": "8d1ae33c-a49b-404d-c0ae-b1b5b5911114",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "TEST_SENTENCE = 'drive driving drived driver drive-way'\n",
        "translated = translate_sentence(TEST_SENTENCE, rnn_encoder, rnn_decoder, None, args)\n",
        "print(\"source:\\t\\t{} \\ntranslated:\\t{}\".format(TEST_SENTENCE, translated))"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "source:\t\tdrive driving drived driver drive-way \n",
            "translated:\tivedway ivedynay ivedray iverray iverway-yemay\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7cP7nl5NRJbu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## RNN attention decoder"
      ]
    },
    {
      "metadata": {
        "id": "rU8xnNeg_uju",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2260
        },
        "outputId": "298f7d40-4a72-42d4-855f-d245827f680e"
      },
      "cell_type": "code",
      "source": [
        "TEST_SENTENCE = 'the air conditioning is working'\n",
        "\n",
        "args = AttrDict()\n",
        "args_dict = {\n",
        "              'cuda':True, \n",
        "              'nepochs':100, \n",
        "              'checkpoint_dir':\"checkpoints\", \n",
        "              'learning_rate':0.005, \n",
        "              'lr_decay':0.99,\n",
        "              'batch_size':64, \n",
        "              'hidden_size':20, \n",
        "              'decoder_type': 'rnn_attention', # options: rnn / rnn_attention / transformer\n",
        "              'attention_type': 'additive',  # options: additive / scaled_dot\n",
        "}\n",
        "args.update(args_dict)\n",
        "\n",
        "print_opts(args)\n",
        "rnn_attn_encoder, rnn_attn_decoder = train(args)\n",
        "\n",
        "translated = translate_sentence(TEST_SENTENCE, rnn_attn_encoder, rnn_attn_decoder, None, args)\n",
        "print(\"source:\\t\\t{} \\ntranslated:\\t{}\".format(TEST_SENTENCE, translated))"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "                                      Opts                                      \n",
            "--------------------------------------------------------------------------------\n",
            "                            hidden_size: 20                                     \n",
            "                          learning_rate: 0.005                                  \n",
            "                             batch_size: 64                                     \n",
            "                                nepochs: 100                                    \n",
            "                                   cuda: 1                                      \n",
            "                         checkpoint_dir: checkpoints                            \n",
            "                           decoder_type: rnn_attention                          \n",
            "                               lr_decay: 0.99                                   \n",
            "                         attention_type: additive                               \n",
            "================================================================================\n",
            "================================================================================\n",
            "                                   Data Stats                                   \n",
            "--------------------------------------------------------------------------------\n",
            "('payment', 'aymentpay')\n",
            "('ordination', 'ordinationway')\n",
            "('amends', 'amendsway')\n",
            "('principally', 'incipallypray')\n",
            "('anybody', 'anybodyway')\n",
            "Num unique word pairs: 6387\n",
            "Vocabulary: ['EOS', '-', 'SOS', 'a', 'c', 'b', 'e', 'd', 'g', 'f', 'i', 'h', 'k', 'j', 'm', 'l', 'o', 'n', 'q', 'p', 's', 'r', 'u', 't', 'w', 'v', 'y', 'x', 'z']\n",
            "Vocab size: 29\n",
            "================================================================================\n",
            "Moved models to GPU!\n",
            "Epoch:   0 | Train loss: 2.474 | Val loss: 2.087 | Gen: eray ay onay onsay onay\n",
            "Epoch:   1 | Train loss: 1.967 | Val loss: 1.826 | Gen: onteray aray onttttttay instay ontttay\n",
            "Epoch:   2 | Train loss: 1.707 | Val loss: 1.620 | Gen: ersay arirray ontingtay isttay ontingtay\n",
            "Epoch:   3 | Train loss: 1.499 | Val loss: 1.429 | Gen: eray alllay ontingay istay otingtay\n",
            "Epoch:   4 | Train loss: 1.317 | Val loss: 1.269 | Gen: eray airray ontiongingay istay orlingway\n",
            "Epoch:   5 | Train loss: 1.138 | Val loss: 1.100 | Gen: eday airay ongigiongnay istay oritingway\n",
            "Epoch:   6 | Train loss: 1.001 | Val loss: 1.099 | Gen: etay airrray onditingingcay isshay orkingcay\n",
            "Epoch:   7 | Train loss: 0.884 | Val loss: 0.887 | Gen: ethay airray ondiiongngay istay orkingcay\n",
            "Epoch:   8 | Train loss: 0.760 | Val loss: 0.768 | Gen: ethay airay onditiongnay isshay orkingcay\n",
            "Epoch:   9 | Train loss: 0.748 | Val loss: 0.739 | Gen: ethay airay ondiginingway issay orkingcay\n",
            "Epoch:  10 | Train loss: 0.680 | Val loss: 0.752 | Gen: ethay airay onditioningngay issay orkingway\n",
            "Epoch:  11 | Train loss: 0.597 | Val loss: 0.641 | Gen: ethay-ethay airay onditiongnay issay orkingway\n",
            "Epoch:  12 | Train loss: 0.533 | Val loss: 0.589 | Gen: ethay airay onditioningway issay orkingray\n",
            "Epoch:  13 | Train loss: 0.514 | Val loss: 0.565 | Gen: etay airay onditiongngay issay orkingray\n",
            "Epoch:  14 | Train loss: 0.456 | Val loss: 0.538 | Gen: ethay airay onditiongngway issay orkingray\n",
            "Epoch:  15 | Train loss: 0.442 | Val loss: 0.477 | Gen: ethay airay onditiongngway issay orkingday\n",
            "Epoch:  16 | Train loss: 0.466 | Val loss: 0.480 | Gen: ethay airay onditiongingway istay orkingway\n",
            "Epoch:  17 | Train loss: 0.370 | Val loss: 0.564 | Gen: ethay airay onditiongngway istay orkingday\n",
            "Epoch:  18 | Train loss: 0.386 | Val loss: 0.445 | Gen: etay airray onditiongngway isay orkingday\n",
            "Epoch:  19 | Train loss: 0.303 | Val loss: 0.407 | Gen: eway airay onditioningway isay orkingday\n",
            "Epoch:  20 | Train loss: 0.294 | Val loss: 0.402 | Gen: etay airay onditiongngway isay orkingday\n",
            "Epoch:  21 | Train loss: 0.367 | Val loss: 0.408 | Gen: etay airray onditioningway isway orkingday\n",
            "Epoch:  22 | Train loss: 0.277 | Val loss: 0.380 | Gen: ethay airray onditioningway isway orkingday\n",
            "Epoch:  23 | Train loss: 0.352 | Val loss: 0.550 | Gen: ehay airay onditiongngway istay orkingway\n",
            "Epoch:  24 | Train loss: 0.533 | Val loss: 0.586 | Gen: eway airay onditioningway isay orkingday\n",
            "Epoch:  25 | Train loss: 0.375 | Val loss: 0.397 | Gen: ehay airray onditioningway isway orkingway\n",
            "Epoch:  26 | Train loss: 0.261 | Val loss: 0.340 | Gen: ebay airray onditiongnay isway orkingway\n",
            "Epoch:  27 | Train loss: 0.205 | Val loss: 0.327 | Gen: ethay airray onditioningway isay orkingway\n",
            "Epoch:  28 | Train loss: 0.197 | Val loss: 0.315 | Gen: ethay airray onditioningway isway orkingway\n",
            "Epoch:  29 | Train loss: 0.170 | Val loss: 0.278 | Gen: ethay airray onditioningway isway orkingway\n",
            "Epoch:  30 | Train loss: 0.165 | Val loss: 0.316 | Gen: ethay airray onditioningway isway orkingway\n",
            "Epoch:  31 | Train loss: 0.163 | Val loss: 0.290 | Gen: ethay airray onditioningway isway orkingway\n",
            "Epoch:  32 | Train loss: 0.150 | Val loss: 0.297 | Gen: ethay airray onditioningway isway orkingway\n",
            "Epoch:  33 | Train loss: 0.159 | Val loss: 0.235 | Gen: ethay airray onditiongcay isway orkingway\n",
            "Epoch:  34 | Train loss: 0.142 | Val loss: 0.304 | Gen: ethay airray onditioningcay isway orkingway\n",
            "Epoch:  35 | Train loss: 0.135 | Val loss: 0.248 | Gen: ethay airray onditiongcay isway orkingway\n",
            "Epoch:  36 | Train loss: 0.159 | Val loss: 0.326 | Gen: etthay airray onditioningcay isway orkingway\n",
            "Epoch:  37 | Train loss: 0.185 | Val loss: 0.291 | Gen: ethay airray onditiongcay isway orkingway\n",
            "Epoch:  38 | Train loss: 0.118 | Val loss: 0.258 | Gen: ethay airray onditiongcay isway orkingway\n",
            "Epoch:  39 | Train loss: 0.128 | Val loss: 0.266 | Gen: ethay airray onditioningcay isway orkingway\n",
            "Epoch:  40 | Train loss: 0.155 | Val loss: 0.255 | Gen: ethay airray onditiongpay isway orkingway\n",
            "Epoch:  41 | Train loss: 0.144 | Val loss: 0.265 | Gen: ethay airray onditiongclay isway orkingway\n",
            "Epoch:  42 | Train loss: 0.102 | Val loss: 0.223 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  43 | Train loss: 0.082 | Val loss: 0.215 | Gen: ethay airray onditiongcay isway orkingway\n",
            "Epoch:  44 | Train loss: 0.067 | Val loss: 0.201 | Gen: ethay airway onditiongcay isway orkingway\n",
            "Epoch:  45 | Train loss: 0.058 | Val loss: 0.181 | Gen: ethay airway onditiongcay isway orkingway\n",
            "Epoch:  46 | Train loss: 0.054 | Val loss: 0.184 | Gen: ethay airway onditiongcay isway orkingway\n",
            "Epoch:  47 | Train loss: 0.058 | Val loss: 0.184 | Gen: ethay airway onditiongcay isway orkingway\n",
            "Epoch:  48 | Train loss: 0.047 | Val loss: 0.188 | Gen: ethay airway onditiongcay isway orkingway\n",
            "Epoch:  49 | Train loss: 0.059 | Val loss: 0.229 | Gen: ethay airway onditiontcgcay isway orkingway\n",
            "Epoch:  50 | Train loss: 0.118 | Val loss: 0.217 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  51 | Train loss: 0.135 | Val loss: 0.196 | Gen: ethay airray onditionicgcay isway orkingway\n",
            "Epoch:  52 | Train loss: 0.095 | Val loss: 0.284 | Gen: ethay airray onditionicgay isway orkingway\n",
            "Epoch:  53 | Train loss: 0.089 | Val loss: 0.171 | Gen: ethay airway onditionicgcay isway orkingway\n",
            "Epoch:  54 | Train loss: 0.056 | Val loss: 0.165 | Gen: ethay airway onditiongcay isway orkingway\n",
            "Epoch:  55 | Train loss: 0.037 | Val loss: 0.150 | Gen: ethay airway onditiongcay isway orkingway\n",
            "Epoch:  56 | Train loss: 0.029 | Val loss: 0.127 | Gen: ethay airway onditiongcay isway orkingway\n",
            "Epoch:  57 | Train loss: 0.029 | Val loss: 0.136 | Gen: ethay airway onditiongcay isway orkingway\n",
            "Epoch:  58 | Train loss: 0.024 | Val loss: 0.146 | Gen: ethay airway onditiongcay isway orkingway\n",
            "Epoch:  59 | Train loss: 0.035 | Val loss: 0.162 | Gen: ethay airway onditiongcay isway orkingway\n",
            "Epoch:  60 | Train loss: 0.025 | Val loss: 0.143 | Gen: ethay airway onditionicgcay isway orkingway\n",
            "Epoch:  61 | Train loss: 0.021 | Val loss: 0.136 | Gen: ethay airway onditionicgcay isway orkingway\n",
            "Epoch:  62 | Train loss: 0.148 | Val loss: 0.360 | Gen: ethay airray onditiongmay isway orkingway\n",
            "Epoch:  63 | Train loss: 0.255 | Val loss: 0.206 | Gen: ethay airaway onditiongcay isway orkingway\n",
            "Epoch:  64 | Train loss: 0.115 | Val loss: 0.172 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  65 | Train loss: 0.099 | Val loss: 0.152 | Gen: ethay airray onditionicgcay isway orkingway\n",
            "Epoch:  66 | Train loss: 0.065 | Val loss: 0.116 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  67 | Train loss: 0.043 | Val loss: 0.109 | Gen: ethay airway onditiongcay isway orkingway\n",
            "Epoch:  68 | Train loss: 0.029 | Val loss: 0.101 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  69 | Train loss: 0.025 | Val loss: 0.120 | Gen: ethay airway onditiongcay isway orkingway\n",
            "Epoch:  70 | Train loss: 0.021 | Val loss: 0.122 | Gen: ethay airway onditiongcay isway orkingway\n",
            "Epoch:  71 | Train loss: 0.018 | Val loss: 0.123 | Gen: ethay airway onditiongcay isway orkingway\n",
            "Epoch:  72 | Train loss: 0.017 | Val loss: 0.125 | Gen: ethay airway onditiongcay isway orkingway\n",
            "Epoch:  73 | Train loss: 0.016 | Val loss: 0.123 | Gen: ethay airway onditionicgcay isway orkingway\n",
            "Epoch:  74 | Train loss: 0.014 | Val loss: 0.125 | Gen: ethay airway onditiongcay isway orkingway\n",
            "Epoch:  75 | Train loss: 0.013 | Val loss: 0.124 | Gen: ethay airway onditionicgcay isway orkingway\n",
            "Epoch:  76 | Train loss: 0.013 | Val loss: 0.122 | Gen: ethay airway onditionicgcay isway orkingway\n",
            "Epoch:  77 | Train loss: 0.012 | Val loss: 0.126 | Gen: ethay airway onditiongcay isway orkingway\n",
            "Epoch:  78 | Train loss: 0.011 | Val loss: 0.122 | Gen: ethay airway onditionicgcay isway orkingway\n",
            "Epoch:  79 | Train loss: 0.011 | Val loss: 0.121 | Gen: ethay airway onditionicgcay isway orkingway\n",
            "Epoch:  80 | Train loss: 0.010 | Val loss: 0.123 | Gen: ethay airway onditiongcay isway orkingway\n",
            "Epoch:  81 | Train loss: 0.010 | Val loss: 0.123 | Gen: ethay airway onditionicgcay isway orkingway\n",
            "Epoch:  82 | Train loss: 0.010 | Val loss: 0.123 | Gen: ethay airway onditionicgcay isway orkingway\n",
            "Epoch:  83 | Train loss: 0.011 | Val loss: 0.118 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  84 | Train loss: 0.337 | Val loss: 0.185 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  85 | Train loss: 0.070 | Val loss: 0.122 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  86 | Train loss: 0.028 | Val loss: 0.099 | Gen: ethay airway onditiongcay isway orkingway\n",
            "Epoch:  87 | Train loss: 0.018 | Val loss: 0.101 | Gen: ethay airway onditiongcay isway orkingway\n",
            "Epoch:  88 | Train loss: 0.014 | Val loss: 0.093 | Gen: ethay airway onditiongcay isway orkingway\n",
            "Epoch:  89 | Train loss: 0.012 | Val loss: 0.093 | Gen: ethay airway onditiongcay isway orkingway\n",
            "Epoch:  90 | Train loss: 0.011 | Val loss: 0.091 | Gen: ethay airway onditiongcay isway orkingway\n",
            "Epoch:  91 | Train loss: 0.010 | Val loss: 0.091 | Gen: ethay airway onditiongcay isway orkingway\n",
            "Epoch:  92 | Train loss: 0.009 | Val loss: 0.092 | Gen: ethay airway onditiongcay isway orkingway\n",
            "Epoch:  93 | Train loss: 0.008 | Val loss: 0.096 | Gen: ethay airway onditiongcay isway orkingway\n",
            "Epoch:  94 | Train loss: 0.008 | Val loss: 0.093 | Gen: ethay airway onditiongcay isway orkingway\n",
            "Epoch:  95 | Train loss: 0.007 | Val loss: 0.093 | Gen: ethay airway onditiongcay isway orkingway\n",
            "Epoch:  96 | Train loss: 0.007 | Val loss: 0.097 | Gen: ethay airway onditiongcay isway orkingway\n",
            "Epoch:  97 | Train loss: 0.006 | Val loss: 0.095 | Gen: ethay airway onditiongcay isway orkingway\n",
            "Epoch:  98 | Train loss: 0.006 | Val loss: 0.097 | Gen: ethay airway onditiongcay isway orkingway\n",
            "Epoch:  99 | Train loss: 0.006 | Val loss: 0.099 | Gen: ethay airway onditiongcay isway orkingway\n",
            "source:\t\tthe air conditioning is working \n",
            "translated:\tethay airway onditiongcay isway orkingway\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nKlyfbuPDXDR",
        "colab_type": "code",
        "outputId": "3886f4f6-3ac1-4da9-f772-328af5d7cf0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2260
        }
      },
      "cell_type": "code",
      "source": [
        "TEST_SENTENCE = 'the air conditioning is working'\n",
        "\n",
        "args = AttrDict()\n",
        "args_dict = {\n",
        "              'cuda':True, \n",
        "              'nepochs':100, \n",
        "              'checkpoint_dir':\"checkpoints\", \n",
        "              'learning_rate':0.005, \n",
        "              'lr_decay':0.99,\n",
        "              'batch_size':64, \n",
        "              'hidden_size':20, \n",
        "              'decoder_type': 'rnn_attention', # options: rnn / rnn_attention / transformer\n",
        "              'attention_type': 'scaled_dot',  # options: additive / scaled_dot\n",
        "}\n",
        "args.update(args_dict)\n",
        "\n",
        "print_opts(args)\n",
        "rnn_attn_encoder1, rnn_attn_decoder1 = train(args)\n",
        "\n",
        "translated = translate_sentence(TEST_SENTENCE, rnn_attn_encoder1, rnn_attn_decoder1, None, args)\n",
        "print(\"source:\\t\\t{} \\ntranslated:\\t{}\".format(TEST_SENTENCE, translated))"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "                                      Opts                                      \n",
            "--------------------------------------------------------------------------------\n",
            "                            hidden_size: 20                                     \n",
            "                          learning_rate: 0.005                                  \n",
            "                             batch_size: 64                                     \n",
            "                                nepochs: 100                                    \n",
            "                                   cuda: 1                                      \n",
            "                         checkpoint_dir: checkpoints                            \n",
            "                           decoder_type: rnn_attention                          \n",
            "                               lr_decay: 0.99                                   \n",
            "                         attention_type: scaled_dot                             \n",
            "================================================================================\n",
            "================================================================================\n",
            "                                   Data Stats                                   \n",
            "--------------------------------------------------------------------------------\n",
            "('payment', 'aymentpay')\n",
            "('ordination', 'ordinationway')\n",
            "('amends', 'amendsway')\n",
            "('principally', 'incipallypray')\n",
            "('anybody', 'anybodyway')\n",
            "Num unique word pairs: 6387\n",
            "Vocabulary: ['EOS', '-', 'SOS', 'a', 'c', 'b', 'e', 'd', 'g', 'f', 'i', 'h', 'k', 'j', 'm', 'l', 'o', 'n', 'q', 'p', 's', 'r', 'u', 't', 'w', 'v', 'y', 'x', 'z']\n",
            "Vocab size: 29\n",
            "================================================================================\n",
            "Moved models to GPU!\n",
            "Epoch:   0 | Train loss: 2.486 | Val loss: 2.050 | Gen: eesay ay onsesensay ay onsesay\n",
            "Epoch:   1 | Train loss: 1.935 | Val loss: 1.788 | Gen: iththay aray ostesteday isssay osstay\n",
            "Epoch:   2 | Train loss: 1.728 | Val loss: 1.630 | Gen: ethay aray ostingedtay issay onstay\n",
            "Epoch:   3 | Train loss: 1.568 | Val loss: 1.521 | Gen: ethhay atay outingingedshay isssay ontingshay\n",
            "Epoch:   4 | Train loss: 1.464 | Val loss: 1.451 | Gen: edthay atay oncingingay issay ooshay\n",
            "Epoch:   5 | Train loss: 1.378 | Val loss: 1.377 | Gen: eththay aray onsingingay issay ongingshay\n",
            "Epoch:   6 | Train loss: 1.277 | Val loss: 1.276 | Gen: edthay away ongingingsay isssay ongingsay\n",
            "Epoch:   7 | Train loss: 1.175 | Val loss: 1.189 | Gen: edthay away ongingingway isssay ongingsay\n",
            "Epoch:   8 | Train loss: 1.100 | Val loss: 1.163 | Gen: eathay airway ondinitingway issssay orgingay\n",
            "Epoch:   9 | Train loss: 1.029 | Val loss: 1.073 | Gen: edhay airay ondingingcay isssssssssssssssssss orgingay\n",
            "Epoch:  10 | Train loss: 0.945 | Val loss: 0.993 | Gen: eathay airay ondingingcay issay orkingway\n",
            "Epoch:  11 | Train loss: 0.830 | Val loss: 0.897 | Gen: eathay airway onditiongcay issssay orfingingway\n",
            "Epoch:  12 | Train loss: 0.760 | Val loss: 0.840 | Gen: eethay airway onditiongcay isssay orfingfay\n",
            "Epoch:  13 | Train loss: 0.674 | Val loss: 0.731 | Gen: eethay atway onditiongcay issssay orkingway\n",
            "Epoch:  14 | Train loss: 0.612 | Val loss: 0.693 | Gen: emhay airway onditioncay isssay orkingway\n",
            "Epoch:  15 | Train loss: 0.580 | Val loss: 0.678 | Gen: emthay airway onditiongcay isgsay orkingway\n",
            "Epoch:  16 | Train loss: 0.556 | Val loss: 0.612 | Gen: emtay airway onditiongcay issay orkingway\n",
            "Epoch:  17 | Train loss: 0.513 | Val loss: 0.647 | Gen: oethay airway onditioncay isway orkingway\n",
            "Epoch:  18 | Train loss: 0.467 | Val loss: 0.599 | Gen: emthay airway onditioncay isway orkingway\n",
            "Epoch:  19 | Train loss: 0.416 | Val loss: 0.531 | Gen: emay airway onditioncay isway orkingway\n",
            "Epoch:  20 | Train loss: 0.391 | Val loss: 0.524 | Gen: emay airway onditioncay isway orkingway\n",
            "Epoch:  21 | Train loss: 0.348 | Val loss: 0.490 | Gen: emay airay onditioncay isway orkingway\n",
            "Epoch:  22 | Train loss: 0.321 | Val loss: 0.500 | Gen: emthay airway onditiongcay isway orkingway\n",
            "Epoch:  23 | Train loss: 0.318 | Val loss: 0.446 | Gen: emay airway onditionscay isway orkingway\n",
            "Epoch:  24 | Train loss: 0.367 | Val loss: 0.464 | Gen: emay airway onditiongcay isway orkingway\n",
            "Epoch:  25 | Train loss: 0.362 | Val loss: 0.471 | Gen: emay airway onditioncay isway orkingway\n",
            "Epoch:  26 | Train loss: 0.295 | Val loss: 0.420 | Gen: emay airway onditionway isway orkingway\n",
            "Epoch:  27 | Train loss: 0.248 | Val loss: 0.400 | Gen: emhay airway onditioncay isway orkingway\n",
            "Epoch:  28 | Train loss: 0.224 | Val loss: 0.396 | Gen: emay airway onditioncay isway orkingway\n",
            "Epoch:  29 | Train loss: 0.220 | Val loss: 0.364 | Gen: emay airway onditionicay isway orkingway\n",
            "Epoch:  30 | Train loss: 0.230 | Val loss: 0.375 | Gen: emhay airway onditioncay isway orkingway\n",
            "Epoch:  31 | Train loss: 0.246 | Val loss: 0.418 | Gen: emay airway onditionway isway orkingway\n",
            "Epoch:  32 | Train loss: 0.229 | Val loss: 0.399 | Gen: ethay aivay onditionway isway orkingway\n",
            "Epoch:  33 | Train loss: 0.253 | Val loss: 0.402 | Gen: ethay aincway onditionmcay isway orkingway\n",
            "Epoch:  34 | Train loss: 0.227 | Val loss: 0.328 | Gen: emay airway onditioncay isway orkingway\n",
            "Epoch:  35 | Train loss: 0.159 | Val loss: 0.293 | Gen: emay airway onditioncay isway orkingway\n",
            "Epoch:  36 | Train loss: 0.140 | Val loss: 0.274 | Gen: emay airway onditioncay isway orkingway\n",
            "Epoch:  37 | Train loss: 0.149 | Val loss: 0.298 | Gen: emay airway onditioncay isway orkingway\n",
            "Epoch:  38 | Train loss: 0.241 | Val loss: 0.431 | Gen: emay airway onditioncay isway orkingway\n",
            "Epoch:  39 | Train loss: 0.187 | Val loss: 0.300 | Gen: ethay airway onditioncay isway orkingway\n",
            "Epoch:  40 | Train loss: 0.140 | Val loss: 0.286 | Gen: emay airway onditioningcay isway orkingway\n",
            "Epoch:  41 | Train loss: 0.115 | Val loss: 0.269 | Gen: emay airway onditioningcay isway orkingway\n",
            "Epoch:  42 | Train loss: 0.106 | Val loss: 0.264 | Gen: emay airway onditioninway isway orkingway\n",
            "Epoch:  43 | Train loss: 0.111 | Val loss: 0.262 | Gen: emay airway onditioningcay isway orkingway\n",
            "Epoch:  44 | Train loss: 0.127 | Val loss: 0.281 | Gen: emay airway onditioninway isway orkingway\n",
            "Epoch:  45 | Train loss: 0.118 | Val loss: 0.308 | Gen: eethay ainway onditioningcay isway orkingway\n",
            "Epoch:  46 | Train loss: 0.147 | Val loss: 0.372 | Gen: emay airway onditioningcay isway orkingway\n",
            "Epoch:  47 | Train loss: 0.223 | Val loss: 0.404 | Gen: emhay airway onditioningcay isway orkingway\n",
            "Epoch:  48 | Train loss: 0.226 | Val loss: 0.303 | Gen: emhay aidway onditioncay isway orkfngway\n",
            "Epoch:  49 | Train loss: 0.181 | Val loss: 0.469 | Gen: ehthay airway onditioncay isway orbay-ongway\n",
            "Epoch:  50 | Train loss: 0.180 | Val loss: 0.297 | Gen: ehthay airway onditioninway isway orkingway\n",
            "Epoch:  51 | Train loss: 0.106 | Val loss: 0.222 | Gen: ehthay airway onditioningcay isway orkingway\n",
            "Epoch:  52 | Train loss: 0.091 | Val loss: 0.218 | Gen: ehthay airway onditioningcay isway orkingway\n",
            "Epoch:  53 | Train loss: 0.079 | Val loss: 0.209 | Gen: ehthay airway onditioningcay isway orkingway\n",
            "Epoch:  54 | Train loss: 0.067 | Val loss: 0.209 | Gen: ehthay airway onditioningcay isway orkingway\n",
            "Epoch:  55 | Train loss: 0.066 | Val loss: 0.202 | Gen: ehthay airway onditioningcay isway orkingway\n",
            "Epoch:  56 | Train loss: 0.061 | Val loss: 0.198 | Gen: ehthay airway onditioningcay isway orkingway\n",
            "Epoch:  57 | Train loss: 0.096 | Val loss: 0.254 | Gen: ehthay airway onditioningcay isway orkingway\n",
            "Epoch:  58 | Train loss: 0.093 | Val loss: 0.249 | Gen: emay airway onditioningcay isway orkingway\n",
            "Epoch:  59 | Train loss: 0.091 | Val loss: 0.225 | Gen: ehthay airway onditioningcay isway orkingway\n",
            "Epoch:  60 | Train loss: 0.078 | Val loss: 0.228 | Gen: ehthay airway onditioningcay isway orkingway\n",
            "Epoch:  61 | Train loss: 0.064 | Val loss: 0.173 | Gen: ehthay airway onditioningcay isway orkingway\n",
            "Epoch:  62 | Train loss: 0.052 | Val loss: 0.187 | Gen: ehthay airway onditioningcay isway orkingway\n",
            "Epoch:  63 | Train loss: 0.048 | Val loss: 0.181 | Gen: ehthay airway onditioningcay isway orkingway\n",
            "Epoch:  64 | Train loss: 0.047 | Val loss: 0.175 | Gen: ehthay airway onditioningcay isway orkingway\n",
            "Epoch:  65 | Train loss: 0.041 | Val loss: 0.161 | Gen: ehthay airway onditioningcay isway orkingway\n",
            "Epoch:  66 | Train loss: 0.038 | Val loss: 0.167 | Gen: ehthay airway onditioningcay isway orkingway\n",
            "Epoch:  67 | Train loss: 0.043 | Val loss: 0.177 | Gen: ehthay airway onditioningcay isway orkingway\n",
            "Epoch:  68 | Train loss: 0.102 | Val loss: 0.438 | Gen: eethay airway onditiolingay isway orkingway\n",
            "Epoch:  69 | Train loss: 0.304 | Val loss: 0.479 | Gen: epthay airway onditioningcay isway orkingway\n",
            "Epoch:  70 | Train loss: 0.194 | Val loss: 0.329 | Gen: epthay airway onditioningcay isway orkingway\n",
            "Epoch:  71 | Train loss: 0.097 | Val loss: 0.262 | Gen: eethay airway onditiongcay isway orkingway\n",
            "Epoch:  72 | Train loss: 0.069 | Val loss: 0.226 | Gen: etthay airway onditioningcay isway orkingway\n",
            "Epoch:  73 | Train loss: 0.053 | Val loss: 0.194 | Gen: ehthay airway onditioningcay isway orkingway\n",
            "Epoch:  74 | Train loss: 0.049 | Val loss: 0.203 | Gen: eethay airway onditioningcay isway orkingway\n",
            "Epoch:  75 | Train loss: 0.052 | Val loss: 0.224 | Gen: eethay airway onditioningcay isway orkingway\n",
            "Epoch:  76 | Train loss: 0.046 | Val loss: 0.191 | Gen: ehthay airway onditioningcay isway orkingway\n",
            "Epoch:  77 | Train loss: 0.039 | Val loss: 0.193 | Gen: ehthay airway onditioningcay isway orkingway\n",
            "Epoch:  78 | Train loss: 0.033 | Val loss: 0.179 | Gen: ehthay airway onditioningcay isway orkingway\n",
            "Epoch:  79 | Train loss: 0.030 | Val loss: 0.194 | Gen: ehthay airway onditioningcay isway orkingway\n",
            "Epoch:  80 | Train loss: 0.029 | Val loss: 0.190 | Gen: ehthay airway onditioningcay isway orkingway\n",
            "Epoch:  81 | Train loss: 0.027 | Val loss: 0.191 | Gen: eethay airway onditioningcay isway orkingway\n",
            "Epoch:  82 | Train loss: 0.025 | Val loss: 0.193 | Gen: ehthay airway onditioningcay isway orkingway\n",
            "Epoch:  83 | Train loss: 0.025 | Val loss: 0.204 | Gen: ehthay airway onditioningcay isway orkingway\n",
            "Epoch:  84 | Train loss: 0.025 | Val loss: 0.171 | Gen: eethay airway onditioningcay isway orkingway\n",
            "Epoch:  85 | Train loss: 0.025 | Val loss: 0.175 | Gen: ehthay airway onditioningcay isway orkingway\n",
            "Epoch:  86 | Train loss: 0.029 | Val loss: 0.169 | Gen: eethay airway onditioningcay isway orkingway\n",
            "Epoch:  87 | Train loss: 0.025 | Val loss: 0.191 | Gen: eethay airway onditioningcay isway orkingway\n",
            "Epoch:  88 | Train loss: 0.041 | Val loss: 0.173 | Gen: etay airway onditioningcay isway orkingway\n",
            "Epoch:  89 | Train loss: 0.060 | Val loss: 0.199 | Gen: etay airway onditioningcay isway orkingway\n",
            "Epoch:  90 | Train loss: 0.095 | Val loss: 0.306 | Gen: etthay airway onditioningcay isway orkingway\n",
            "Epoch:  91 | Train loss: 0.207 | Val loss: 0.242 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  92 | Train loss: 0.111 | Val loss: 0.201 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  93 | Train loss: 0.057 | Val loss: 0.180 | Gen: eethay airway onditioningcay isway orkingway\n",
            "Epoch:  94 | Train loss: 0.039 | Val loss: 0.188 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  95 | Train loss: 0.032 | Val loss: 0.167 | Gen: ehthay airway onditioningcay isway orkingway\n",
            "Epoch:  96 | Train loss: 0.028 | Val loss: 0.151 | Gen: ehthay airway onditioningcay isway orkingway\n",
            "Epoch:  97 | Train loss: 0.027 | Val loss: 0.147 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  98 | Train loss: 0.024 | Val loss: 0.146 | Gen: ethay airway onditioningcay isway orkingway\n",
            "Epoch:  99 | Train loss: 0.021 | Val loss: 0.147 | Gen: ethay airway onditioningcay isway orkingway\n",
            "source:\t\tthe air conditioning is working \n",
            "translated:\tethay airway onditioningcay isway orkingway\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vE-hKCxhF3iR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "be1f424f-8722-446d-f435-ba057a8474b9"
      },
      "cell_type": "code",
      "source": [
        "TEST_SENTENCE = 'drive driving drived driver drive-way '\n",
        "translated = translate_sentence(TEST_SENTENCE, rnn_attn_encoder, rnn_attn_decoder, None, args)\n",
        "print(\"source:\\t\\t{} \\ntranslated:\\t{}\".format(TEST_SENTENCE, translated))"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "source:\t\tdrive driving drived driver drive-way  \n",
            "translated:\tesesesay ongay eressay eressesay essay\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "X8FaZZUWRpY9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Transformer"
      ]
    },
    {
      "metadata": {
        "id": "Ik5rx9qw9KCg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2260
        },
        "outputId": "0edf9a2e-a5db-4cf5-9bda-84866fccad05"
      },
      "cell_type": "code",
      "source": [
        "TEST_SENTENCE = 'the air conditioning is working'\n",
        "\n",
        "args = AttrDict()\n",
        "args_dict = {\n",
        "              'cuda':True, \n",
        "              'nepochs':100, \n",
        "              'checkpoint_dir':\"checkpoints\", \n",
        "              'learning_rate':0.005, \n",
        "              'lr_decay':0.99,\n",
        "              'batch_size':64, \n",
        "              'hidden_size':20, \n",
        "              'decoder_type': 'transformer', # options: rnn / rnn_attention / transformer\n",
        "              'num_transformer_layers': 3,\n",
        "}\n",
        "args.update(args_dict)\n",
        "\n",
        "print_opts(args)\n",
        "transformer_encoder, transformer_decoder = train(args)\n",
        "\n",
        "translated = translate_sentence(TEST_SENTENCE, transformer_encoder, transformer_decoder, None, args)\n",
        "print(\"source:\\t\\t{} \\ntranslated:\\t{}\".format(TEST_SENTENCE, translated))"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "                                      Opts                                      \n",
            "--------------------------------------------------------------------------------\n",
            "                            hidden_size: 20                                     \n",
            "                          learning_rate: 0.005                                  \n",
            "                 num_transformer_layers: 3                                      \n",
            "                             batch_size: 64                                     \n",
            "                                nepochs: 100                                    \n",
            "                                   cuda: 1                                      \n",
            "                         checkpoint_dir: checkpoints                            \n",
            "                           decoder_type: transformer                            \n",
            "                               lr_decay: 0.99                                   \n",
            "================================================================================\n",
            "================================================================================\n",
            "                                   Data Stats                                   \n",
            "--------------------------------------------------------------------------------\n",
            "('payment', 'aymentpay')\n",
            "('ordination', 'ordinationway')\n",
            "('amends', 'amendsway')\n",
            "('principally', 'incipallypray')\n",
            "('anybody', 'anybodyway')\n",
            "Num unique word pairs: 6387\n",
            "Vocabulary: ['EOS', '-', 'SOS', 'a', 'c', 'b', 'e', 'd', 'g', 'f', 'i', 'h', 'k', 'j', 'm', 'l', 'o', 'n', 'q', 'p', 's', 'r', 'u', 't', 'w', 'v', 'y', 'x', 'z']\n",
            "Vocab size: 29\n",
            "================================================================================\n",
            "Moved models to GPU!\n",
            "Epoch:   0 | Train loss: 3.166 | Val loss: 1.896 | Gen: eseray eaisay ingingingingingingin isicay ingingay\n",
            "Epoch:   1 | Train loss: 1.772 | Val loss: 1.558 | Gen: edtyy aiiciaay ingingay isisisisisisisisisis oray-orcestiny\n",
            "Epoch:   2 | Train loss: 1.382 | Val loss: 1.258 | Gen: ehay airiray oningcay iscay oreray\n",
            "Epoch:   3 | Train loss: 1.119 | Val loss: 1.045 | Gen: ehay airay oninccyyiinniionnny isisisisisisisisisis orsgay\n",
            "Epoch:   4 | Train loss: 0.926 | Val loss: 0.835 | Gen: ehehay airbay oningcayEOSionionionig isisisay orbwwy\n",
            "Epoch:   5 | Train loss: 0.714 | Val loss: 0.740 | Gen: ehehay airay onininingcay isisway orkerkingdway\n",
            "Epoch:   6 | Train loss: 0.592 | Val loss: 0.611 | Gen: ethedhy airway onditiningcay isfay orkingbay\n",
            "Epoch:   7 | Train loss: 0.488 | Val loss: 0.551 | Gen: ethedhy airway onditingcay isway orkingbay\n",
            "Epoch:   8 | Train loss: 0.433 | Val loss: 0.514 | Gen: ethewaay airy onditingcay isway orkingway\n",
            "Epoch:   9 | Train loss: 0.386 | Val loss: 0.481 | Gen: ehay airayyy ondingcay isway orkingway\n",
            "Epoch:  10 | Train loss: 0.386 | Val loss: 0.457 | Gen: ethadayy airwy onninngccy isway orkingdway\n",
            "Epoch:  11 | Train loss: 0.355 | Val loss: 0.422 | Gen: ethay airgyy ondiongcay isway ogkingway\n",
            "Epoch:  12 | Train loss: 0.340 | Val loss: 0.388 | Gen: ethahay airwy ondiiiiccy isway orkingway\n",
            "Epoch:  13 | Train loss: 0.252 | Val loss: 0.306 | Gen: ethay airwy onditingay isway orkingway\n",
            "Epoch:  14 | Train loss: 0.209 | Val loss: 0.281 | Gen: ethay airway onditinggy isway orkingway\n",
            "Epoch:  15 | Train loss: 0.179 | Val loss: 0.247 | Gen: ethay airwayy onditingcayyy isway orkingway\n",
            "Epoch:  16 | Train loss: 0.180 | Val loss: 0.326 | Gen: ethay airway ondiongcayy isway orkingway\n",
            "Epoch:  17 | Train loss: 0.211 | Val loss: 0.328 | Gen: ethay airay onditingcanEOSaaaaaaaa isway orkingway\n",
            "Epoch:  18 | Train loss: 0.213 | Val loss: 0.295 | Gen: ethay airwayy onditingcayyy issway orkingway\n",
            "Epoch:  19 | Train loss: 0.145 | Val loss: 0.230 | Gen: ethay airsy onditiningcayyy isway orkingway\n",
            "Epoch:  20 | Train loss: 0.168 | Val loss: 0.339 | Gen: ethay airry ondisnaggiy isway orkingway\n",
            "Epoch:  21 | Train loss: 0.308 | Val loss: 0.447 | Gen: ekahy array oniiooonyy isway orkingbay\n",
            "Epoch:  22 | Train loss: 0.320 | Val loss: 0.390 | Gen: ethay airwayy onditiiiiiiiy isway orkingway\n",
            "Epoch:  23 | Train loss: 0.222 | Val loss: 0.276 | Gen: ethayEOSty airay onditingcaayyyy isway orkinkiagEOSgy\n",
            "Epoch:  24 | Train loss: 0.165 | Val loss: 0.255 | Gen: ethay airay onditingiiy isway orkingway\n",
            "Epoch:  25 | Train loss: 0.126 | Val loss: 0.253 | Gen: ethathay airry onditingcay isway orkingway\n",
            "Epoch:  26 | Train loss: 0.118 | Val loss: 0.220 | Gen: ethay aiway onditinngay isway orkingway\n",
            "Epoch:  27 | Train loss: 0.102 | Val loss: 0.208 | Gen: ethhayEOSty airwaEOSay onditingcay isway orkingway\n",
            "Epoch:  28 | Train loss: 0.082 | Val loss: 0.198 | Gen: etthay aiway onditingcay iswwy orkingway\n",
            "Epoch:  29 | Train loss: 0.073 | Val loss: 0.181 | Gen: ethay airwy onditingcay isway orkingway\n",
            "Epoch:  30 | Train loss: 0.066 | Val loss: 0.183 | Gen: etteehay airway ondititingcy isway orkingway\n",
            "Epoch:  31 | Train loss: 0.050 | Val loss: 0.140 | Gen: ethhay aiway onditionigcy isway orkingway\n",
            "Epoch:  32 | Train loss: 0.050 | Val loss: 0.170 | Gen: ettaahay irway onditiningcayy isflisway orkingway\n",
            "Epoch:  33 | Train loss: 0.047 | Val loss: 0.179 | Gen: ethaayEOSty aiway ondititingcay iswayy orkingway\n",
            "Epoch:  34 | Train loss: 0.088 | Val loss: 0.236 | Gen: ethay airay onditingcay isway orkingway\n",
            "Epoch:  35 | Train loss: 0.170 | Val loss: 0.392 | Gen: ethay airway onditincay iswwy orkingway\n",
            "Epoch:  36 | Train loss: 0.278 | Val loss: 0.298 | Gen: ethhthay irway onditiningcay issway orkingwhhhhy\n",
            "Epoch:  37 | Train loss: 0.152 | Val loss: 0.183 | Gen: ethay irway inditionngggy iswway orkingway\n",
            "Epoch:  38 | Train loss: 0.069 | Val loss: 0.146 | Gen: ethay iaway onditiningcy issway orkinhway\n",
            "Epoch:  39 | Train loss: 0.072 | Val loss: 0.131 | Gen: etteahhy airay onditioninnncy issway orkingway\n",
            "Epoch:  40 | Train loss: 0.119 | Val loss: 0.258 | Gen: etthay airway ondiiiowanyy isswiswy orkinggwy\n",
            "Epoch:  41 | Train loss: 0.130 | Val loss: 0.200 | Gen: ethethay iaway otdiinigagyvy isway orkingway\n",
            "Epoch:  42 | Train loss: 0.075 | Val loss: 0.135 | Gen: ethay airrway onditeiicnccyyyiy iswway orkinggey\n",
            "Epoch:  43 | Train loss: 0.080 | Val loss: 0.170 | Gen: ethhthay aiway onditiiinicyyy iswwy orkingway\n",
            "Epoch:  44 | Train loss: 0.058 | Val loss: 0.128 | Gen: ethayEOSty airay onditinnincny isway orkinggaay\n",
            "Epoch:  45 | Train loss: 0.078 | Val loss: 0.257 | Gen: ethathay iiway onditiiiicccy isway orkingway\n",
            "Epoch:  46 | Train loss: 0.110 | Val loss: 0.217 | Gen: ethaahEOSy airway onditinngcayyyy ilwwy orkioiwiiwyy\n",
            "Epoch:  47 | Train loss: 0.068 | Val loss: 0.153 | Gen: ethay aaray ondiinoigccay iswway orkingwawy\n",
            "Epoch:  48 | Train loss: 0.036 | Val loss: 0.113 | Gen: etthathy airay onditioningayy isway orkingway\n",
            "Epoch:  49 | Train loss: 0.027 | Val loss: 0.125 | Gen: ethhy airwy onditioningunaaay isway orkingwayy\n",
            "Epoch:  50 | Train loss: 0.035 | Val loss: 0.172 | Gen: ethay airway ondititnnnnnccy isway orkingwayEOSuhay\n",
            "Epoch:  51 | Train loss: 0.040 | Val loss: 0.156 | Gen: ethay airay ondititiniuhyy iswwy orkingwayy\n",
            "Epoch:  52 | Train loss: 0.019 | Val loss: 0.148 | Gen: ethay airpy ondiiioiiagy iswwy orkingway\n",
            "Epoch:  53 | Train loss: 0.027 | Val loss: 0.166 | Gen: ethay aiway onditininingcaygyy isway jrrrry\n",
            "Epoch:  54 | Train loss: 0.029 | Val loss: 0.129 | Gen: ethay airpy onditiiiniayyyy iswway orkinrwy\n",
            "Epoch:  55 | Train loss: 0.025 | Val loss: 0.107 | Gen: etthy airwayy onditiongcay iswway orkiigway\n",
            "Epoch:  56 | Train loss: 0.028 | Val loss: 0.126 | Gen: ethay airwy onditiiiiiiayyy iswway orkinngway\n",
            "Epoch:  57 | Train loss: 0.038 | Val loss: 0.169 | Gen: ethhy airpy ondttinnignyy iswwy orkinnghy\n",
            "Epoch:  58 | Train loss: 0.047 | Val loss: 0.186 | Gen: ethhy aiway ondititincayyyy iswwy orkingwaayay\n",
            "Epoch:  59 | Train loss: 0.035 | Val loss: 0.130 | Gen: ethhy airay ondttinncay iswwy orkinnway\n",
            "Epoch:  60 | Train loss: 0.024 | Val loss: 0.123 | Gen: ethay aiway onsioinniggcccy iswwy orkiinwayy\n",
            "Epoch:  61 | Train loss: 0.035 | Val loss: 0.136 | Gen: ethay airny indioninncay iswayy orgignwy\n",
            "Epoch:  62 | Train loss: 0.313 | Val loss: 0.346 | Gen: ethay airwy cnyytiniy iswayyy orkinwaay\n",
            "Epoch:  63 | Train loss: 0.308 | Val loss: 0.270 | Gen: evcthay airway onditingcay isway orrirggayy\n",
            "Epoch:  64 | Train loss: 0.122 | Val loss: 0.153 | Gen: ethay airway oniitinnncay iswayEOSEOSaay orkingway\n",
            "Epoch:  65 | Train loss: 0.045 | Val loss: 0.126 | Gen: ethay airay ondttiniggaaayy isway orkingwaywy\n",
            "Epoch:  66 | Train loss: 0.029 | Val loss: 0.116 | Gen: ethay airway ondiiiioncy isway orkinnway\n",
            "Epoch:  67 | Train loss: 0.020 | Val loss: 0.111 | Gen: ethay airay ondiiiioncy isway orkingwwy\n",
            "Epoch:  68 | Train loss: 0.015 | Val loss: 0.106 | Gen: ethay airay cnditonnnnhy isway orkingwwy\n",
            "Epoch:  69 | Train loss: 0.011 | Val loss: 0.124 | Gen: ethay airay onditiiigayyy isway orkinggayy\n",
            "Epoch:  70 | Train loss: 0.010 | Val loss: 0.096 | Gen: ethay airay onditiniggayygy iswaay orkinnway\n",
            "Epoch:  71 | Train loss: 0.008 | Val loss: 0.122 | Gen: ethay airay onditiniggoayyy isway orkinnway\n",
            "Epoch:  72 | Train loss: 0.009 | Val loss: 0.095 | Gen: ethay airay ondiiioiocnyy iswaay orkinnway\n",
            "Epoch:  73 | Train loss: 0.006 | Val loss: 0.112 | Gen: ethay airay onditiniggoayyy iswaay orkinnway\n",
            "Epoch:  74 | Train loss: 0.005 | Val loss: 0.102 | Gen: ethay airay onditiniggoyy iswaay orkinnwayy\n",
            "Epoch:  75 | Train loss: 0.004 | Val loss: 0.107 | Gen: ethay airay onditininccny isway orkingwwaywy\n",
            "Epoch:  76 | Train loss: 0.006 | Val loss: 0.105 | Gen: ethay airay onditiniggayyyy iswaay orkinggaaEOSy\n",
            "Epoch:  77 | Train loss: 0.005 | Val loss: 0.122 | Gen: ethay airay onditiniggoyy iswaay orkingwwaywy\n",
            "Epoch:  78 | Train loss: 0.005 | Val loss: 0.116 | Gen: ethay airay onditiiiigcyy iswwy orkingwwy\n",
            "Epoch:  79 | Train loss: 0.025 | Val loss: 0.174 | Gen: ethay airway onditiningcayy iswwy orkingway\n",
            "Epoch:  80 | Train loss: 0.039 | Val loss: 0.141 | Gen: ethay airway onditiningcay iswwy orkingwy\n",
            "Epoch:  81 | Train loss: 0.039 | Val loss: 0.138 | Gen: ethhy airay onditiningcy iswayyy orkingiay\n",
            "Epoch:  82 | Train loss: 0.015 | Val loss: 0.099 | Gen: ethay airway onditiningcy iswwy orkiigy\n",
            "Epoch:  83 | Train loss: 0.006 | Val loss: 0.102 | Gen: ethhy airay onditiningay iswayyy orkiigy\n",
            "Epoch:  84 | Train loss: 0.003 | Val loss: 0.095 | Gen: ethay airay onditiningcy iswwy orkiigy\n",
            "Epoch:  85 | Train loss: 0.003 | Val loss: 0.111 | Gen: ethay airay onditiningcayEOSy iswayyy orkiigy\n",
            "Epoch:  86 | Train loss: 0.026 | Val loss: 0.155 | Gen: ethay airay onditiningcay iswayyy orkingway\n",
            "Epoch:  87 | Train loss: 0.067 | Val loss: 0.157 | Gen: ehhay iaway onditiningcay iswayyy orkinnwyy\n",
            "Epoch:  88 | Train loss: 0.044 | Val loss: 0.151 | Gen: ethay airway onditinicay iswwy orkingway\n",
            "Epoch:  89 | Train loss: 0.023 | Val loss: 0.148 | Gen: ethay airway onditiningcayyy iswwy orkingway\n",
            "Epoch:  90 | Train loss: 0.079 | Val loss: 0.205 | Gen: ethathay airway onditingcay iswwy orkkngway\n",
            "Epoch:  91 | Train loss: 0.062 | Val loss: 0.152 | Gen: etthay airway onditinicay issway orkingway\n",
            "Epoch:  92 | Train loss: 0.028 | Val loss: 0.076 | Gen: ethay airay onditiniggcaay isway orkinnwayy\n",
            "Epoch:  93 | Train loss: 0.027 | Val loss: 0.107 | Gen: ethhay airway onditininccayy isway orkingway\n",
            "Epoch:  94 | Train loss: 0.013 | Val loss: 0.088 | Gen: etthay airwaay onditiningcayy iswaysy orkingway\n",
            "Epoch:  95 | Train loss: 0.008 | Val loss: 0.094 | Gen: ethhy airwaay inditioninncy iswwy orkkngway\n",
            "Epoch:  96 | Train loss: 0.004 | Val loss: 0.091 | Gen: etthay airay onditiiiocaayay iswwy orkkngway\n",
            "Epoch:  97 | Train loss: 0.003 | Val loss: 0.091 | Gen: etthay airay inditinnigoyyyy iswwy orkwnnway\n",
            "Epoch:  98 | Train loss: 0.002 | Val loss: 0.096 | Gen: etthay airay onditioingcay iswwy orkwnnway\n",
            "Epoch:  99 | Train loss: 0.002 | Val loss: 0.095 | Gen: etthay airay inditionigoyyyy iswwy orkwnnway\n",
            "source:\t\tthe air conditioning is working \n",
            "translated:\tetthay airay inditionigoyyyy iswwy orkwnnway\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ULCMHm5ZF7vx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "1c056632-a96e-4a99-8be7-130942a4a308"
      },
      "cell_type": "code",
      "source": [
        "TEST_SENTENCE = 'asdfasdfasdfasdfasdf'\n",
        "translated = translate_sentence(TEST_SENTENCE, transformer_encoder, transformer_decoder, None, args)\n",
        "print(\"source:\\t\\t{} \\ntranslated:\\t{}\".format(TEST_SENTENCE, translated))"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "source:\t\tasdfasdfasdfasdfasdf \n",
            "translated:\tasdfasdfasdfasdfasda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qbfZCByITOI6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Attention visualization"
      ]
    },
    {
      "metadata": {
        "id": "itCGMv3FdXsn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "TEST_WORD_ATTN = 'pacccomputer'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xBv4QQuBiU-V",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Visualize RNN attention map"
      ]
    },
    {
      "metadata": {
        "id": "aXvqoQYONMTA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "56549d76-a853-4bb2-90bf-e8f856e95a93"
      },
      "cell_type": "code",
      "source": [
        "visualize_attention(TEST_WORD_ATTN, rnn_attn_encoder, rnn_attn_decoder, None, args)"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgoAAAGHCAYAAADRB3rOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'acccomputerpray'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "metadata": {
        "id": "xuOvxfA1NMz3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Visualize transformer attention maps from all the transformer layers"
      ]
    },
    {
      "metadata": {
        "id": "HSSB4wd8-M7g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2380
        },
        "outputId": "04200d19-d285-4f67-f2ef-a753eefbe959"
      },
      "cell_type": "code",
      "source": [
        "visualize_attention(TEST_WORD_ATTN, transformer_encoder, transformer_decoder, None, args, )"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgcAAAGHCAYAAAAk+fF+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi40LCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcv7US4rQAAIABJREFUeJzt3XtYVXXe9/HPFsQTToGB5mHKKDVP\nOVhqYZqOJveUt8pokIXd6tWMjubkIWQo3Y55vtW7MZumnC7rNjPUsKyc8DCVNaH4aCFZaVmiJgpb\nQ0VzFPg9f/S4H1Zy2EqLxaL3q2tfF2sf1vrutTfx8fv7rbU8xhgjAACA/6eO0wUAAICahXAAAAAs\nCAcAAMCCcAAAACwIBwAAwIJwAAAALAgHAADAgnAAAAAsXBEOCgsL9fvf/16JiYkaNmyYdu/e7XRJ\nkqTY2FgVFxerqKhIv/rVr5SdnS1JGj16tL799ltHa6up++yitLQ0Pfrooxo+fLiOHTvmdDmSfqjp\n8ccf19ixYxUbG6s1a9Y4XZIkPssrUVN/N2vyZzls2DAdPHhQknT06FHFxcU5XBGc5IpwkJ+fr2HD\nhmnFihWaNGmSli1b5nRJkqQOHTroyy+/1GeffaaOHTvqk08+UUlJiXw+n1q0aOFobTV1n5WWm5ur\nlStXqmnTpk6X4rdv3z4tXbpUzzzzjF5++WWny5HEZ3klaurvZk3+LAcNGqQNGzZIkrZs2aJ77rnH\n4YrgpGCnCwjENddco7/+9a964YUXdP78eTVs2NDpkiRJ3bp10yeffKJz584pMTFRGzdu1G233ab2\n7ds7XVqN3WelderUSR6Px+kyLLp06aKgoCA1a9ZMp0+fdrocSXyWV6Km/m7W5M/ynnvu0ejRozVm\nzBi99957mjVrltMlwUGu6By89NJLatq0qVatWqUZM2Y4XY5ft27dlJWVpaysLN1xxx0qLCzUzp07\n1b17d6dLq7H7rLS6des6XcIlgoNrXl7ms7x8NfV3syZ/lmFhYWrWrJl2796tkpKSGtMFgjNcEQ6+\n++47/fKXv5Qkbd68WRcuXHC4oh+0bt1aubm5On36tEJDQ3XNNddoy5Yt6tGjh9Ol1dh9hsvHZ3n5\naurvZk3/LAcNGqSZM2cqNjbW6VLgMFeEg0GDBmn58uUaNWqUOnfurPz8fL322mtOlyVJatKkiZo3\nby5JuuWWW/Ttt9+qWbNmDldVs/cZLg+f5ZWpib+bNf2z7NOnjw4ePKgBAwY4XQoc5uGSzQAASdq2\nbZvWrVun+fPnO10KHFbzBlgBANVuyZIl+vDDD/X00087XQpqADoHAADAwhVzDgAAQPUhHAAAAAvC\nAQAAsCAcAAAAC8IBAACwIBwAAAAL289z8NjMZ+zexBVZ6B3vdAnlCg4OcbqEMtWpU3OzZFFRzToN\n7UVduvza6RLKlZu73+kSylRcXOR0CeUKCqqZp4YJu7pmXgchL/+g0yWUKz//kNMl1Gg19//2AADA\nETUzBgMAUEv8FOcarO5LohMOAACwUclPEA6CCAcAANQebrxKAXMOAACABZ0DAABsZOS+zgHhAAAA\nG5W4LxswrAAAAKzoHAAAYCM3TkgkHAAAYKOf4lDG6kY4AADARm7sHDDnAAAAWNA5AADARm7sHBAO\nAACwEXMOAACAhRs7B1c852DdunU/ZR0AAKCGCKhzkJ2drWXLlqmgoECSdOHCBfl8Pg0ZMsTW4gAA\ncDs3nj45oM7BrFmzNHz4cJ09e1ZJSUnq1q2bUlJS7K4NAADXKzFVv1W3gDoH9evXV48ePRQSEqKO\nHTuqY8eOGj16tPr06WN3fQAAuJob5xwEFA4aNGigLVu2qGXLllq8eLFatWql3Nxcu2sDAAAOCGhY\nYeHChYqKitL06dMVEhKivXv3av78+XbXBgCA65UYU+VbdQuocxAaGqrQ0FBJ0vjx420tCACA2qTW\nDisAAIAr48ZwwLUVAACABZ0DAABsxOmTAQCAhRuHFQgHAADYyI1nSCQcAADgcnPmzFFWVpY8Ho9S\nUlLUuXNnSdKxY8c0ZcoU//MOHTqkyZMna+DAgRWuj3AAAICN7D79cWZmpnJycpSamqr9+/crJSVF\nqampkqSmTZtqxYoVkqSioiIlJiaqb9++la6TcAAAgI3snnOQkZGhfv36SZKioqJ08uRJFRYW+s9P\ndNG6des0YMAANWrUqNJ1cigjAAAu5vP5FBYW5l8ODw9Xfn7+Jc9bs2aNhg4dGtA66RwAAGCj6j5a\noaztffzxx7rhhhsu6SaUh3AAAICN7D7PQWRkpHw+n385Ly9PERERlue89957uv322wNeJ8MKAADY\nyBhT5VtFYmJilJ6eLknas2ePIiMjL+kQZGdnq127dgHXTOcAAAAXi46OVocOHZSQkCCPxyOv16u0\ntDQ1btxY/fv3lyTl5+erSZMmAa+TcAAAgI2q4/TJpc9lIOmSLsGbb755WesjHAAAYCNOn1yGl5Yu\nsHsTV6Qmf1hLVq93uoQyHfrikNMllGvRjAlOl1Cm3Nz9TpdQrrZtuztdQpm2bk11uoRyBQXVzH9P\nNWzQ2OkSyuTxMK1Ncufpk/nkAACARc2MwQAA1BJ2nz7ZDoQDAABsVJOHsctDOAAAwEZuDAfMOQAA\nABZ0DgAAsFF1nOfgp0Y4AADARm4cViAcAABgIzeGA+YcAAAACzoHAADYiDkHAADAwo2nTyYcAABg\nIzeeIZE5BwAAwILOAQAANnLj0QqEAwAAbOTGcHDFwwrr1q37KesAAKBWKjGmyrfqFlDnIDs7W8uW\nLVNBQYEk6cKFC/L5fBoyZIitxQEAgOoXUOdg1qxZGj58uM6ePaukpCR169ZNKSkpdtcGAIDrGWOq\nfKtuAXUO6tevrx49eigkJEQdO3ZUx44dNXr0aPXp08fu+gAAcDU3zjkIKBw0aNBAW7ZsUcuWLbV4\n8WK1atVKubm5dtcGAAAcENCwwsKFCxUVFaXp06crJCREe/fu1fz58+2uDQAA16u1ExJDQ0MVGhoq\nSRo/frytBQEAUJtw+mQAAGDB6ZMBAIDr0TkAAMBGtfZoBQAAcGUIBwAAwMKJow2qijkHAADAgs4B\nAAA2YlgBAABYEA4AAIAFcw4AAIDr0TkAAMBGnD4ZAABYuHBUgXAAAICdqmPOwZw5c5SVlSWPx6OU\nlBR17tzZ/1hubq4mTZqkCxcuqH379po5c2al62POAQAALpaZmamcnBylpqZq9uzZmj17tuXxefPm\nadSoUVq7dq2CgoJ05MiRStdJOAAAwEbGmCrfKpKRkaF+/fpJkqKionTy5EkVFhZKkkpKSrRz5071\n7dtXkuT1etW8efNKayYcAABgoxJjqnyriM/nU1hYmH85PDxc+fn5kqQTJ06oUaNGmjt3ru6//34t\nWrQooJptn3Nw/Pi3dm/iitzVO8HpEsr1SdY/nS6hTP/52zFOl1CumnqSkWPHDjhdQrmaN7/R6RLK\nVFJS7HQJ5aqptZ06fcLpEsp08mSe0yXUCNX9/6fS2zPG6NixYxoxYoRatGih3/3ud3rvvfd01113\nVbgOOgcAALhYZGSkfD6ffzkvL08RERGSpLCwMDVv3ly//OUvFRQUpNtvv11ffvllpeskHAAAYCO7\n5xzExMQoPT1dkrRnzx5FRkYqNDRUkhQcHKxWrVrpwIED/sdbt25dac0cyggAgI3sPpQxOjpaHTp0\nUEJCgjwej7xer9LS0tS4cWP1799fKSkpSk5OljFGbdq08U9OrAjhAAAAG1XHGRKnTJliWW7Xrp3/\n5+uuu06rVq26rPUxrAAAACzoHAAAYKMaejBVhQgHAADYiEs2AwAA16NzAACAjWrqSdoqQjgAAMBG\nbhxWIBwAAGAjN3YOmHMAAAAs6BwAAGAjN3YOCAcAANiJcAAAAEozJe4LBwHNOcjL45rcAAD8XAQU\nDiZNmmR3HQAA1ErGVP1W3QIaVoiIiFBCQoI6deqkunXr+u9PSkqyrTAAAGqDWjshsVevXnbXAQBA\nrVRrw8GQIUPsrgMAANQQHK0AAICNam3nAAAAXBk3HspIOAAAwEZu7BxwbQUAAGBB5wAAABu5sXNA\nOAAAwE6EAwAAUJoLswFzDgAAgBWdAwAAbMShjAAAwMKNExIZVgAAABZ0DgAAsJEbOweEAwAAbEQ4\nAAAAFm4MB8w5AAAAFnQOAACwE4cyAgCA0tw4rGB7OKhfv5Hdm7giWz9Y43QJ5apXr6HTJZTp3Y01\nd599k3fM6RLK1Ktrb6dLKNeBA9lOl1Cm3r3inS6hXO9vTXW6hDKdOVPgdAllCg4OcbqEGsGF2YA5\nBwAAwIphBQAAbMSwAgAAsKiOcDBnzhxlZWXJ4/EoJSVFnTt39j/Wt29fNWvWTEFBQZKkhQsXqmnT\nphWuj3AAAICN7L7wUmZmpnJycpSamqr9+/crJSVFqanW+THLli1To0aBzwFkzgEAAC6WkZGhfv36\nSZKioqJ08uRJFRYWVmmdhAMAAGxkjKnyrSI+n09hYWH+5fDwcOXn51ue4/V6df/992vhwoUBDXMw\nrAAAgI2qe0Lij7c3YcIE3Xnnnbrqqqs0btw4paenKzY2tsJ10DkAAMBGdncOIiMj5fP5/Mt5eXmK\niIjwLw8ePFhNmjRRcHCwevXqpX379lVaM+EAAAAXi4mJUXp6uiRpz549ioyMVGhoqCTp9OnTGj16\ntM6fPy9J2rFjh2666aZK18mwAgAAdrJ5WCE6OlodOnRQQkKCPB6PvF6v0tLS1LhxY/Xv31+9evVS\nfHy86tWrp/bt21c6pCARDgAAsJUpsX8bU6ZMsSy3a9fO//NDDz2khx566LLWRzgAAMBGbjxDInMO\nAACABZ0DAABs5MbOAeEAAAAbEQ4AAIBFrQsHffv2lcfjKfMxj8ejzZs321IUAABwToXh4K233pIx\nRs8995zatWun7t27q6SkRNu2bVNOTk511QgAgGvZfVVGO1R4tELDhg3VqFEj7dq1S7/5zW/UpEkT\nRUREaODAgdq5c2d11QgAgHsZU/VbNQtozkFISIjmzZunX/3qV6pTp46ys7NVXFxsd20AAMABAYWD\nJUuWaP369crMzJQxRq1bt9Yzzzxjd20AALherZuQeFFoaKiGDx9udy0AANQ6LswGHMoIAICd3Ng5\n4PTJAADAgs4BAAA2cuOhjIQDAABs5MZhBcIBAAA2cmM4YM4BAACwoHMAAICN3Ng5IBwAAGAjwgEA\nALBy4dEKzDkAAAAWdA4AALCRC0cVCAcAANiJOQcAAMDCjeGAOQcAAMCCzgEAADbi2goAAMDCjcMK\ntoeD8LBmdm/iihw+u8/pEsr1n4P/4HQJZXpj3VKnSyjX3TG/cbqEMv0mboTTJZTr5b/Pc7qEMu3d\nt8PpEsoVGhrmdAllKi4ucrqEMrVs2dbpEmoEN4YD5hwAAAALhhUAALCTCzsHhAMAAGzEsAIAAHA9\nOgcAANjIlDhdweUjHAAAYCM3DisQDgAAsJEbwwFzDgAAgAXhAAAAGxljqnyrzJw5cxQfH6+EhATt\n3r27zOcsWrRIiYmJAdXMsAIAADaye1ghMzNTOTk5Sk1N1f79+5WSkqLU1FTLc7766ivt2LFDdevW\nDWiddA4AALCRKTFVvlUkIyND/fr1kyRFRUXp5MmTKiwstDxn3rx5mjhxYsA1Ew4AAHAxn8+nsLD/\nf92P8PBw5efn+5fT0tLUrVs3tWjRIuB1Eg4AALBRdcw5+PH2LiooKFBaWppGjhx5WetgzgEAAHay\nec5BZGSkfD6ffzkvL08RERGSpG3btunEiRN64IEHdP78eR08eFBz5sxRSkpKheukcwAAgI2Mqfqt\nIjExMUpPT5ck7dmzR5GRkQoNDZUkxcbGasOGDVq9erWWLl2qDh06VBoMpAA6B3FxcYqNjdWAAQN0\n3XXXBbAbAABAdYmOjlaHDh2UkJAgj8cjr9ertLQ0NW7cWP3797+idVYaDpYuXaotW7bI6/Xq9OnT\n+vWvf60BAwYoKirqijYIAMDPSXWcIXHKlCmW5Xbt2l3ynJYtW2rFihUBra/SYYXmzZsrMTFRL774\nop555hnl5ORo0KBBAZYLAMDPm92HMtqh0s7B0aNH9c9//lPvvvuu8vLy1Lt3b61atao6agMAwPXc\neG2FSsPBH/7wB/Xv319Tp07VjTfeWB01AQAAB1UaDtLS0qqjDgAAaqVa2TkAAABXjnAAAACsXBgO\nOAkSAACwoHMAAICNnDgUsaoIBwAA2MiFowqEAwAA7OTGCYnMOQAAABZ0DgAAsJEbOweEAwAAbOTG\ncMCwAgAAsKBzAACAjTiUEQAAWLhxWIFwAACAnVwYDphzAAAALOgcAABgI4YVAACAhQuzgf3hoH37\nGLs3cUUOf7vP6RLK9f67q50uoWw1+Bv+5Zf/x+kSyhSxo5XTJZSrSZMWTpdQpm9r8O/mY7OWOl1C\nmTa/9obTJZTpwIFsp0uoEdx4tAJzDgAAgAXDCgAA2Ig5BwAAwIJwAAAALNwYDphzAAAALOgcAABg\nIzd2DggHAADYyI2HMhIOAACwkws7B8w5AAAAFnQOAACwkQsbB4QDAADsxIREAABg4cZwwJwDAABg\nQecAAAAbcSgjAACw+FkNK6xbt+6nrAMAgFrJGFPlW2XmzJmj+Ph4JSQkaPfu3ZbHVq9erfvuu08J\nCQmaMWNGQOsLqHOQnZ2tZcuWqaCgQJJ04cIF+Xw+DRkyJJCXAwAAm2RmZionJ0epqanav3+/UlJS\nlJqaKkn6/vvv9fbbb2vlypWqW7euRowYoY8//ljR0dEVrjOgzsGsWbM0fPhwnT17VklJSerWrZtS\nUlKq/o4AAKjl7O4cZGRkqF+/fpKkqKgonTx5UoWFhZKkBg0a6KWXXlLdunX1/fffq7CwUBEREZXW\nHFA4qF+/vnr06KGQkBB17NhREydO1MsvvxzISwEA+Hkzpuq3Cvh8PoWFhfmXw8PDlZ+fb3nO888/\nr/79+ys2NlatWrWqtOSAwkGDBg20ZcsWtWzZUosXL9aaNWuUm5sbyEsBAEA1KqvT8Lvf/U6bN2/W\nBx98oJ07d1a6joDCwcKFCxUVFaXp06crJCREe/fu1fz58y+/YgAAfmZMSdVvFYmMjJTP5/Mv5+Xl\n+YcOCgoKtGPHDkk/jAL06tVLu3btqrTmgMJBaGiorr/+eoWGhmr8+PF64okn1KlTp0BeCgDAz5rd\ncw5iYmKUnp4uSdqzZ48iIyMVGhoqSSoqKlJycrLOnDkj6YcDDFq3bl1pzZznAAAAG9l9noPo6Gh1\n6NBBCQkJ8ng88nq9SktLU+PGjdW/f3+NGzdOI0aMUHBwsNq2batf//rXla6TcAAAgMtNmTLFstyu\nXTv/z3FxcYqLi7us9REOAACwkRvPkEg4AADARoQDAABg4cYLL3HJZgAAYEHnAAAAOzGsAAAASjMi\nHAAAgFLcOCGROQcAAMCCzgEAADYylV0coQYiHAAAYCM3DisQDgAAsJEbwwFzDgAAgAWdAwAAbOTG\nzgHhAAAAG7lxQqLH2Bxp6tQJsnP1V6xmf1gepwsoU/PmUU6XUK4jR75yuoRy1MzPUpK6dr3b6RLK\ntHNnutMluE5U1K+cLqFMhw/vdbqEcp07d6batnXPb35f5XW8veG5n6CSwDHnAAAAWDCsAACAjTh9\nMgAAsHDjhESGFQAAgAWdAwAAbOTGzgHhAAAAG9Xso+PKRjgAAMBGbuwcMOcAAABY0DkAAMBGbuwc\nEA4AALAR4QAAAFi5MBww5wAAAFjQOQAAwEZGHMoIAABKceOcg4CGFfLy8uyuAwCAWskYU+VbdQso\nHEyaNMnuOgAAQA0R0LBCRESEEhIS1KlTJ9WtW9d/f1JSkm2FAQBQG7hxWCGgcNCrVy+76wAAoFaq\ntddWGDJkiN11AABQK7mxc8B5DgAAgAWHMgIAYKPq6BzMmTNHWVlZ8ng8SklJUefOnf2Pbdu2TYsX\nL1adOnXUunVrzZ49W3XqVNwboHMAAICdjKn6rQKZmZnKyclRamqqZs+erdmzZ1senz59upYsWaJX\nX31VZ86c0QcffFBpyXQOAACwkZG9nYOMjAz169dPkhQVFaWTJ0+qsLBQoaGhkqS0tDT/z+Hh4fru\nu+8qXSedAwAAXMzn8yksLMy/HB4ervz8fP/yxWCQl5enf/3rX+rdu3el66RzAACAjar7UMay5jgc\nP35cY8aMkdfrtQSJ8hAOAACwkd0TEiMjI+Xz+fzLeXl5ioiI8C8XFhbq4Ycf1qOPPqqePXsGtE6G\nFQAAsJHd11aIiYlRenq6JGnPnj2KjIz0DyVI0rx58/TQQw9d1gkN6RwAAOBi0dHR6tChgxISEuTx\neOT1epWWlqbGjRurZ8+eev3115WTk6O1a9dKku69917Fx8dXuE7CAQAANqqO8xxMmTLFstyuXTv/\nz59++ullr49wAACAjdx4bQXmHAAAAAs6BwAA2MiNF14iHAAAYCfCAQAAKM3u0yfbgTkHAADAgs4B\nAAA2Ys4BAACwcOOhjLaHg3r1Gtq9iSty7lyh0yW4zpEj+50uoVw333y70yWU6fDhvU6XUK7PPvvI\n6RLKtDYz0+kSynVfj5r5PcvPO+h0CWWKjLzO6RJqBDd2DphzAAAALBhWAADARm7sHBAOAACwEeEA\nAABYuDEcMOcAAABY0DkAAMBOHMoIAABKc+PpkwkHAADYiDkHAADA9egcAABgIzd2DggHAADYiGsr\nAAAACzd2DphzAAAALOgcAABgIzd2DggHAADYyI3hIKBhhb/97W+W5RMnTmjChAm2FAQAAJwVUDg4\ne/askpKSdP78ea1fv17Dhw9XbGys3bUBAOB+xlT9Vs0CGlaYNGmS3nnnHd1zzz268cYbtWrVKoWF\nhdldGwAArmdUyw5lnD9/vjwej3/5+uuvV05OjpYtWyZJSkpKsrc6AABczo1zDioMB23atLEs33TT\nTbYWAwAAnFdhOBgyZEh11QEAQK1U6zoHAACgaggHAADAwo3XVuD0yQAAwILOAQAANmJYAQAAWBAO\nAACAlQvDAXMOAABwuTlz5ig+Pl4JCQnavXu35bF///vfmjp1quLi4gJeH+EAAAAbmZ/gv4pkZmYq\nJydHqampmj17tmbPnm15fMGCBbr55psvq2bCAQAANjKmpMq3imRkZKhfv36SpKioKJ08eVKFhYX+\nxydOnOh/PFCEAwAAbGSMqfKtIj6fz3IxxPDwcOXn5/uXQ0NDL7tmwgEAALXIT3F0BEcrAABgI7sP\nZYyMjJTP5/Mv5+XlKSIiokrrpHMAAICN7B5WiImJUXp6uiRpz549ioyMvKKhhNLoHAAAYCO7OwfR\n0dHq0KGDEhIS5PF45PV6lZaWpsaNG6t///6aMGGCjh49qm+++UaJiYm67777NHDgwArXSTgAAMDl\npkyZYllu166d/+clS5Zc9voIBwAA2MiNV2W0PRyEhzezexNX5MiRr5wuoQLuO9Wm0z7/PMPpEspU\np06Q0yWUq0l4c6dLKNPQbt2cLqFcyXP/5nQJZcp45z2nSyjT3fff63QJNYMLT59M5wAAABtVdobD\nmoijFQAAgAWdAwAAbMQlmwEAgIUbJyQyrAAAACzoHAAAYCOGFQAAgAXhAAAAWLgxHDDnAAAAWNA5\nAADARm7sHBAOAACwkwsPZSQcAABgI06fDAAAXI/OAQAANmLOAQAAsCAcAAAAC66tAAAAXK/CcFBU\nVKR3333Xv/zRRx8pJSVFzz77rM6dO2d7cQAAuJ0xpsq36lZhOPB6vXr//fclSQcPHtTEiRPVrVs3\neTwe/fnPf66WAgEAcDM3hoMK5xx8+eWXWr16tSTpzTffVGxsrAYPHixJSkxMtL86AABczo0TEivs\nHNSrV8//80cffaTevXvbXhAAAHBWhZ2DBg0aKD09XadOndKBAwcUExMjSdq/f3+1FAcAgOu5sHNQ\nYTh48skn9dRTT+n06dP661//qnr16unf//63xo4dq0WLFlVXjQAAuJaR+w5lrDAcNG3aVHPnzrXc\nV69ePaWnp8vj8dhaGAAAtYEb5xxUehKk1157TS+++KIKCgrk8Xh0zTXXaOTIkRo4cGB11AcAAKpZ\nheFg1apVysjI0PPPP69rr71WkvTtt99q/vz5On78uP7rv/6rOmoEAMC13Ng5qPBohTVr1mjx4sX+\nYCBJLVq00KJFi7R+/XrbiwMAwO1q3XkOQkJCFBx86VPq1q2rkJAQ24oCAKC2qHWdA0k6evToJfcd\nOnTIlmIAAIDzKuwcPPLIIxo5cqRGjBih9u3bq7i4WNnZ2XrllVf03//939VVIwAAruXGqzJWGA46\ndeqkF154QatWrdKHH36oOnXq6IYbbtCLL74on89XXTUCAOBatW5YYfz48WrevLkmT56sZ555RmFh\nYZo4caKuvfZaOgcAANRSFXYOfpx2Dhw4UO5jAACgDC78e1lhOPjxWRBLBwLOkAgAQOWMalk4+DEC\nAQAAl6fWTUj89NNPNXToUEk/dA2++eYbDR06VMYYyxADAACoPSoMB2+++WZ11QEAQK3kxjl6FYaD\nFi1aVFcdAADUSm4MBx7jxqoBAIBtKj19MgAA+HkhHAAAAAvCAQAAsCAc1BJ5eXlq3769nn/+ecv9\nu3bt8l9F86uvvtKePXuueBtvvPGGJOnzzz/Xk08+eeXFVtHWrVv17LPPVvic5ORkrVmz5pL7v//+\ne23cuDHgbZXef4E4duyYMjIyJElPP/20/ud//ifg1/5cXPweVadAvjOlJSYm6qOPPrKxIqu0tDR1\n6dKlWrcJVIRwUEu8/vrrioqKUlpamuX+tLQ0/x+3TZs26bPPPrui9R87dkyvvvqqJOnmm2/WtGnT\nqlZwFfTq1Utjx469otd+9tlnlxUOSu+/QGzfvl3btm27ktJ+Fkp/j6pTVb4zdnv99df16aefql27\ndk6XAvhd1hkSUXO99tprmjFjhpKTk7Vr1y5FR0dr06ZNeuedd7R79279x3/8h15++WWFhoaqfv36\n6tWrl7xer06cOKHCwkKNHDlSAwcO1NNPP62CggIdPXpUOTk56t69u6ZNm6bJkydr3759SkpK0m9/\n+1s99dRTWrVqlb755ht5vV7PU9HRAAALEUlEQVQZY1RUVKTJkyfr1ltvVXJysiIjI7Vv3z7/ybMe\nfvhhf72HDh3ShAkTtG7dOhljFBMTo8cee0xDhgzR22+/rZ07dyo5OVkzZ85UTk6Ozpw5o3vvvVej\nRo1SWlqaPvroIy1cuFDvv/++Fi1apKuuukp33nmnXn75ZW3dulWStHfvXo0ZM0YHDhxQXFycRowY\noccff1ynTp3SggULNHjwYE2fPl1169bVuXPnNG7cON11113+Gkvvvz/96U9q1qxZme+19Ht66qmn\nZIzR1VdfLemHP4YTJkzQ119/rW7dumn69OmSpMWLF2vXrl06d+6cbrvtNiUlJVnOQHrs2DFNmTJF\nknTu3DnFx8dr6NChFe7vrl27atiwYZKktm3bas+ePXr22Wd1+PBhHTlyRFOnTlVoaKimTZumkpIS\n1atXT3PnzlXTpk21YsUK/eMf/1BxcbFuuOEGeb1e1a9f31/PmTNnNHnyZJ06dUpFRUXq06ePxo4d\nq5MnT17x92jBggVlbtfn82ns2LHq2bOndu/erTNnzui5555T06ZN9e6772rp0qWqV6+err/+es2c\nOVMlJSVlfk9KK/2d6du3r0aMGKGtW7fq8OHD+vOf/6zbb7+9zN+rkpISeb1eff311zp//rxuueUW\nPfHEE5o8ebJiYmIUFxcnSfJ6vWrTpo3uvffecvdH6c+hY8eO/m3069dPgwcPVmJiYoC/7UA1MHC9\nzMxM07dvX1NSUmIWL15sHn/8cf9jDz74oPnXv/5ljDFm6tSpZvXq1cYYY2bMmGHWrl1rjDHmzJkz\npl+/fub48eNmyZIlJiEhwRQVFZnvv//edOnSxRQUFJht27aZhIQEY4yx/Dxq1CizYcMGY4wxX3zx\nhenbt69/W48++qgxxpjDhw+b6OjoS+q+++67zenTp80XX3xhRo0aZZKTk40xxkybNs1s2bLFLFu2\nzPzlL38xxhhTVFRk4uLizOeff25ee+01M3nyZFNSUmJ69+5tPv/8c2OMMQsXLjR33nnnJdvPzc01\nXbp0McYY/2uNMebJJ580zz33nDHGGJ/PZ9atW3dJjaX3X3nvtbQlS5aYxYsX+39OSEgwFy5cMOfO\nnTNdunQxJ06cMBs2bDBJSUn+1/zhD38wW7Zssaxn+fLlZvr06cYYY86dO2dWrFhR6f6++NkaY0yb\nNm3MhQsXzJIlS8zw4cNNSUmJMcaYESNGmHfffdcYY8xbb71lli9fbrKyskxiYqL/ObNnzzb/+7//\na6ln48aNZvTo0cYYY4qLi82LL75oiouLq/Q9Km+7hw4dMjfffLPZt2+fMcaY5ORks3z5cnP27Flz\nxx13mOPHjxtjjFmwYIHZvn17ud+T0kp/7n369DGvvPKKMcaYtLQ0M2bMmEs+x4uf+4kTJ/z73hhj\nBgwYYPbu3WsyMzPNgw8+6N9mnz59zKlTpyrcH6U/h7KU/q4BTqNzUAusXbtWQ4YMkcfjUVxcnOLi\n4vT444+rQYMG5b5m+/btys7O1uuvvy5JCg4O1uHDhyVJXbt2VVBQkIKCghQWFqaTJ0+Wu56srCz/\nuHrbtm1VWFioEydOSJK6desm6YeTaRUWFqq4uFhBQUH+1/bo0UM7d+5UTk6OBg8erJUrV0r6YZx/\n6tSpWrVqlY4ePaodO3ZIks6fP6+DBw/6X//dd9/p7Nmz/nbsgAEDLOPZF7ffrFkznT17VsXFxZba\nBwwYoOTkZB05ckR9+vTRoEGDyn2fFb3X8PDwcl/TtWtXBQcHKzg4WGFhYTp9+rS2b9+uTz75xP8v\nxdOnT/v3/UV33nmnXnnlFSUnJ6t3796Kj4+vdH+X55ZbbvF3JXbv3u3fL/fcc48kadmyZTp48KBG\njBghSTp79qyCg63/a4iOjtaSJUv0xz/+Ub1799awYcNUp06dKn2Ptm/fXu52w8LCdNNNN0mSmjdv\nroKCAn311Vdq1qyZf38/9thj/vrL+p5U1Ka/uA+aN29e4ff7F7/4hXJzcxUfH6+QkBDl5+fru+++\nU/fu3XXixAkdOnRIhw8fVteuXdW4ceMK90fpzwGo6QgHLldYWKiNGzfq2muv1aZNmyT90ApNT0/X\n4MGDy31dSEiIvF6vOnXqZLn//ffft/wBlyo+u1dZ/7O7eN+P/8D8eD09e/bUjh079M0332j69Ona\ntGmTsrKyFBYWpkaNGikkJETjxo1TbGys5XUX51UYYyzb/3HdlW3/tttu01tvvaWMjAylpaVp/fr1\nWrRo0RW91/KUtS9DQkJ03333afTo0eW+LioqSm+//bZ27Nihd955Ry+99JJeffXVcmsoff/58+ct\nj9etW9eyXFJivQhMSEiI+vbt6x/yKEuTJk30xhtv6OOPP9aWLVv029/+VuvWravS96i87R4+fLjM\n13o8njK/i+V9TypS+rtR0ff77bffVnZ2tlauXKng4GD/MIIkDRs2TOvXr9exY8f8wzkV7Y8ffw5A\nTcaERJd76623dNttt2nDhg1644039MYbb2jmzJn+P6Aej0cXLly45OeuXbvqH//4h6QfxrRnzJih\noqKicrdTp06dMh+/5ZZb9OGHH0r6YbLf1VdfrbCwsIBq7969u3bt2qX8/Hw1bdpUt956q5599ln1\n7NnzkhpLSko0d+5cFRQU+F8fFhamOnXq6Ouvv5akgCYaln4fK1as0NGjR9W3b1/Nnj1bWVlZlzy/\n9D4L5L16PJ4K9+PF97Vp0yb/85YuXXrJhczefPNNZWdn64477pDX61Vubq6KiorKraFRo0bKzc2V\nJGVkZJQbWqKjo/XBBx9IkjZs2KDFixcrOjpaW7du1ZkzZyRJK1eu1Mcff2x53Ycffqj33ntPXbt2\nVVJSkho2bKjjx49X6XsUyHZLu+GGG3Ts2DEdPXpUkjR37lxt3ry50u9JVRw/flytW7dWcHCwPv30\nUx08eNAfvgYPHqwtW7boiy++8HciLnd/ADUVnQOXW7t2rcaNG2e5b8CAAZo3b54OHz6smJgYeb1e\npaSkqEePHlqwYIGMMRo/fryeeOIJ3X///Tp//rzi4+Mv+Zd2aTfeeKOOHz+ukSNHasyYMf77p02b\nJq/Xq1WrVqmoqEgLFiwIuPZf/OIXKikpUZs2bST90OqdM2eOxo8fL0l64IEH9OWXXyo+Pl7FxcW6\n6667/BP9pB/+0KSkpGjcuHFq3ry5br311grfgyR16tRJCxcu1J/+9Cfde++9mjx5sho1aqSSkhJN\nnjz5kueX3n+BvNdbb71VEydOVN26dS/51+9Fd999tz755BMlJCQoKChI7du3V6tWrSzPufHGG+X1\nehUSEiJjjB5++GEFBweXW8PQoUP1xz/+UTt27FDPnj3VuHHjMrc9bdo0TZs2Ta+88oqCg4M1Z84c\nXXvttXrggQeUmJioevXqKTIy0vIvZElq3bq1kpOT9fe//11BQUHq2bOnWrRoUaXv0fLly8vc7vHj\nx8t8bcOGDTV79mw98sgjCgkJUcuWLXXXXXepuLi4wu9JVcTGxmrMmDF68MEHFR0drVGjRmnWrFla\nvXq1rr76arVq1UodOnTwP/9y94f0Qzjcvn27Pv/8c82bN09XXXWV/vKXv1Q4XAXYjWsrwNU2b96s\ntm3bqlWrVtq4caNSU1P1wgsvOF0WfgZOnTqlhIQErVy5MuBuGeAWdA7gaiUlJXrkkUcUGhqq4uJi\nzZgxw+mS8DOwdu1avfTSS3r00UcJBqiV6BwAAAALJiQCAAALwgEAALAgHAAAAAvCAQAAsCAcAAAA\nC8IBAACw+L+yc6MEXFcEoQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x396 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgcAAAGHCAYAAAAk+fF+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x396 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgcAAAGHCAYAAAAk+fF+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x396 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgcAAAGHCAYAAAAk+fF+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi40LCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcv7US4rQAAIABJREFUeJzt3Xl0VHWa//FPkY2laA2agCyOEJpG\nE1zC2gZBOCDMoIdF6EQUZoDjGRC0UTDQoUkhTRBoZGwadWzGgw5ihMHgSsuSQW2bdUBCAEUaMQEJ\nkIABQowkqe/vD3/UyZUsRcJN1Q3vF6fOya3l3qdu3VBPnu9zv9dljDECAAD4/xoFOgAAABBcSA4A\nAIAFyQEAALAgOQAAABYkBwAAwILkAAAAWJAcAAAAC5IDAABg4YjkoKioSP/+7/+uMWPGaNSoUdq3\nb1+gQ5IkDR48WOXl5SorK9M999yj7OxsSdKECRP03XffBTS2YN1nl2VkZGjq1KkaPXq0Tp06Fehw\nJP0U06xZszRp0iQNHjxY//M//xPokCTxWdZGsP5uBvNnOWrUKOXm5kqSTp48qREjRgQ4IgSSI5KD\n/Px8jRo1SitXrtQzzzyj5cuXBzokSVJsbKwOHz6sgwcPKi4uTnv37pXX61VBQYHatGkT0NiCdZ9V\nlJeXp1WrVqlly5aBDsXn66+/1rJly/TSSy/pzTffDHQ4kvgsayNYfzeD+bMcOnSo1q9fL0nKzMzU\nkCFDAhwRAik00AH44+abb9bLL7+s1157TZcuXVLTpk0DHZIkqUePHtq7d69KSko0ZswYbdy4Ud27\nd9cdd9wR6NCCdp9V1KVLF7lcrkCHYXH33XcrJCRErVq10oULFwIdjiQ+y9oI1t/NYP4shwwZogkT\nJmjixIn65JNPNG/evECHhAByROXgjTfeUMuWLZWenq45c+YEOhyfHj16KCsrS1lZWbr33ntVVFSk\n3bt3q2fPnoEOLWj3WUVhYWGBDuEKoaHBly/zWV69YP3dDObPMjIyUq1atdK+ffvk9XqDpgqEwHBE\ncvD999/r1ltvlSRt3rxZpaWlAY7oJ+3bt1deXp4uXLggt9utm2++WZmZmerVq1egQwvafYarx2d5\n9YL1dzPYP8uhQ4dq7ty5Gjx4cKBDQYA5IjkYOnSoVqxYofHjx+vOO+9Ufn6+3nnnnUCHJUm66aab\n1Lp1a0nSXXfdpe+++06tWrUKcFTBvc9wdfgsaycYfzeD/bPs16+fcnNzNWjQoECHggBzcclmAIAk\nbd++XevWrdPChQsDHQoCLPgGWAEA9W7p0qX6/PPP9ec//znQoSAIUDkAAAAWjug5AAAA9YfkAAAA\nWJAcAAAAC5IDAABgQXIAAAAsSA4AAICF7fMcDHpgvN2bqJWNm1YEOgQAQIBwFn/1qBwAAAALZkgE\nAMBG16JKUd+XRCc5AADARt5rkByEkBwAANBwOLG/gZ4DAABgQeUAAAAbGTmvckByAACAjbzOyw0Y\nVgAAAFZUDgAAsJETGxJJDgAAsNG1OJWxvpEcAABgIydWDug5AAAAFlQOAACwkRMrByQHAADYiJ4D\nAABg4cTKQa17DtatW3ct4wAAAEHCr8pBdna2li9frsLCQklSaWmpCgoKNHz4cFuDAwDA6Zw4fbJf\nlYN58+Zp9OjRKi4uVnJysnr06KGUlBS7YwMAwPG8pu63+uZX5aBx48bq1auXwsPDFRcXp7i4OE2Y\nMEH9+vWzOz4AABzNiT0HfiUHTZo0UWZmptq2baslS5aoXbt2ysvLszs2AAAQAH4NKyxevFgxMTFK\nTU1VeHi4Dh06pIULF9odGwAAjuc1ps63+uZX5cDtdsvtdkuSpkyZYmtAAAA0JA12WAEAANSOE5MD\nrq0AAAAsqBwAAGAjpk8GAAAWThxWIDkAAMBGDXaGRAAAcP2gcgAAgI0CMf1xXZEcAABgIyf2HDCs\nAAAALKgcAABgIydWDkgOAACwEfMcAAAACydWDug5AAAAFlQOAACwEcMKAADAwonDCrYnB0e/zbZ7\nE7Xy3dmzgQ6hSinJfwp0CJVa/eYLgQ6hSiUlRYEOoVKNG7sDHUKVgnWfAQ0N0ycDAADHY1gBAAAb\nMX0yAACwoOcAAABYODE5oOcAAABYUDkAAMBGzHMAAAAsnDisQHIAAICNnJgc0HMAAAAsqBwAAGAj\neg4AAICFE6dPJjkAAMBGTpwhkZ4DAABgQeUAAAAbOfFsBZIDAABs5MTkoNbDCuvWrbuWcQAA0CB5\njanzrb75VTnIzs7W8uXLVVhYKEkqLS1VQUGBhg8fbmtwAACg/vlVOZg3b55Gjx6t4uJiJScnq0eP\nHkpJSbE7NgAAHM8YU+dbffOrctC4cWP16tVL4eHhiouLU1xcnCZMmKB+/frZHR8AAI7mxJ4Dv5KD\nJk2aKDMzU23bttWSJUvUrl075eXl2R0bAAAIAL+GFRYvXqyYmBilpqYqPDxchw4d0sKFC+2ODQAA\nx2uwDYlut1tut1uSNGXKFFsDAgCgIWH6ZAAAYMH0yQAAwPGoHAAAYKMGe7YCAACoHZIDAABgUR9n\nG8yfP19ZWVlyuVxKSUnRnXfe6Xts1apVev/999WoUSPFxcVp1qxZNa6PngMAABxs586dysnJ0erV\nq5WWlqa0tDTfY0VFRXrttde0atUqpaen68iRI9q7d2+N6yQ5AADARnZPn7xt2zYNGDBAkhQTE6Nz\n586pqKhIkhQWFqawsDAVFxerrKxMP/zwg2644YYaY2ZYAQAAG9ndc1BQUKDY2FjfcosWLZSfny+3\n262IiAhNnjxZAwYMUEREhIYMGaL27dvXuE4qBwAA2Ki+Z0ismIwUFRXp1Vdf1ccff6zMzExlZWXp\nq6++qnEdJAcAADhYdHS0CgoKfMunT59WVFSUJOnIkSNq166dWrRoofDwcHXr1k379++vcZ0kBwAA\n2Mhcg3/VSUhI0IYNGyRJBw4cUHR0tO+SB23atNGRI0dUUlIiSdq/f79uu+22GmOm5wAAABvZfSZj\nfHy8YmNjlZSUJJfLJY/Ho4yMDDVv3lwDBw7UhAkTNHbsWIWEhOiee+5Rt27dalwnyQEAADaqj3kO\npk+fblnu3Lmz7+ekpCQlJSVd1foYVgAAABZUDgAAsBHTJwMAAIv6GFa41mxPDnJzD9q9iVqJ7XB7\noEOo0g8/XAh0CJXq0+c3gQ6hSps2vR7oEBzH5QrOUUVjvIEOAbimnFg5CM7/HQAAQMAwrAAAgI2c\nWDkgOQAAwEb0HAAAAIuaZjgMRvQcAAAACyoHAADYyIGjCiQHAADYyYk9BwwrAAAACyoHAADYiFMZ\nAQCAhROHFUgOAACwkRMrB/QcAAAACyoHAADYyImVA5IDAADsRHIAAAAqMl7nJQd+9RycPn3a7jgA\nAECQ8Cs5eOaZZ+yOAwCABsmYut/qm1/DClFRUUpKSlKXLl0UFhbmuz85Odm2wAAAaAgabENinz59\n7I4DAIAGqcEmB8OHD7c7DgAAECQ4WwEAABs12MoBAACoHSeeykhyAACAjZxYOeDaCgAAwILKAQAA\nNnJi5YDkAAAAO5EcAACAihyYG9BzAAAArKgcAABgI05lBAAAFk5sSGRYAQAAWFA5AADARk6sHJAc\nAABgI5IDAABg4cTkgJ4DAABgQeUAAAA7cSojAACoyInDCrYnBzEd7rZ7E7Vy8MutgQ7BcTZtej3Q\nIVSpc+degQ6hUk2b/iLQIVRpz56NgQ4BuC44MDeg5wAAAFgxrAAAgI0YVgAAABYkBwAAwMKJF16i\n5wAAAFhQOQAAwEYMKwAAAAuSAwAAYOHE5ICeAwAAYEHlAAAAOzmwckByAACAjYw30BFcPZIDAABs\nRM8BAABwPCoHAADYyImVA5IDAABsRHIAAAAsGlxy0L9/f7lcrkofc7lc2rx5sy1BAQCAwKk2Ofjw\nww9ljNGrr76qzp07q2fPnvJ6vdq+fbtycnLqK0YAAByrwV2VsWnTpmrWrJn27Nmjf/mXf9FNN92k\nqKgoPfTQQ9q9e3d9xQgAgHMZU/dbDebPn6/ExEQlJSVp3759lsfy8vL0yCOPaOTIkUpNTfUrZL96\nDsLDw7VgwQLdc889atSokbKzs1VeXu7XBgAAgH127typnJwcrV69WkeOHFFKSopWr17te3zBggUa\nP368Bg4cqOeee04nTpxQ69atq12nX/McLF26VLfeeqt27typbdu2KSoqSi+99FLd3g0AANcBY0yd\nb9XZtm2bBgwYIEmKiYnRuXPnVFRUJEnyer3avXu3+vfvL0nyeDw1JgaSn5UDt9ut0aNH+/NUAABQ\ngd0nKxQUFCg2Nta33KJFC+Xn58vtduvs2bNq1qyZnn/+eR04cEDdunXTtGnTalwnMyQCAGAjuysH\nlW2v4s+nTp3S2LFj9eabb+rgwYP65JNPalwHyQEAAA4WHR2tgoIC3/Lp06cVFRUlSYqMjFTr1q11\n6623KiQkRL/+9a91+PDhGtdJcgAAgI2M19T5Vp2EhARt2LBBknTgwAFFR0fL7XZLkkJDQ9WuXTt9\n++23vsfbt29fY8zMkAgAgI3sniExPj5esbGxSkpKksvlksfjUUZGhpo3b66BAwcqJSVFM2fOlDFG\nnTp18jUnVofkAAAAG9XH9MnTp0+3LHfu3Nn38z/90z8pPT39qtbHsAIAALCgcgAAgI0a3IWXAABA\n3ZAcAAAAq4Z24SUAAHD9oXIAAICNHDiqQHIAAICd6DkAAAAWTkwO6DkAAAAWVA4AALBRTddGCEYk\nBwAA2MiJwwq2JwfN3DfavYkG59m5LwU6hEr9MXVyoEOo0qFDOwMdQqUaN24W6BBwDUWENwl0CJX6\n8dIPgQ4B1XBickDPAQAAsGBYAQAAOzmwckByAACAjRhWAAAAjkflAAAAGxlvoCO4eiQHAADYyInD\nCiQHAADYyInJAT0HAADAgsoBAAA2cmLlgOQAAAAbkRwAAAALJ154iZ4DAABgQeUAAAAbMawAAACs\nSA4AAEBFDswNau45GDFihP7yl78oJyenPuIBAAABVmNysGzZMjVp0kQej0cPP/ywXn75ZR05cqQ+\nYgMAwPGMMXW+1bcak4PWrVtrzJgxev311/XSSy8pJydHQ4cOrY/YAABwPOM1db7Vtxp7Dk6ePKn/\n/d//1ZYtW3T69Gn17dtX6enp9REbAACO1yDPVnjiiSc0cOBAzZgxQx07dqyPmAAAQADVmBxkZGTU\nRxwAADRIDbJyAAAAao/kAAAAWDkwOeDaCgAAwILKAQAANnLiVRlJDgAAsJEDRxVIDgAAsJMTGxLp\nOQAAABZUDgAAsJETKwckBwAA2MiJyQHDCgAAwILKAQAANuJURgAAYOHEYQWSAwAA7OTA5ICeAwAA\nYEHlAAAAGzGsAAAALByYG9ifHOzdm2n3JhqcP6ZODnQIjmOMN9AhVKp1646BDqFKR458EegQHOfH\nSz8EOgQ4kBPPVqDnAAAAWDCsAACAjeg5AAAAFiQHAADAwonJAT0HAADAgsoBAAA2cmLlgOQAAAAb\nOfFURpIDAADs5MDKAT0HAADAgsoBAAA2cmDhgOQAAAA7ObEhkWEFAABsZIyp860m8+fPV2JiopKS\nkrRv375Kn/PCCy9ozJgxfsVMcgAAgIPt3LlTOTk5Wr16tdLS0pSWlnbFc/7xj39o165dfq+T5AAA\nABsZr6nzrTrbtm3TgAEDJEkxMTE6d+6cioqKLM9ZsGCBnn76ab9jJjkAAMBGdg8rFBQUKDIy0rfc\nokUL5efn+5YzMjLUo0cPtWnTxu+Ya50crFu3rrYvBQDgulEfPQc/395lhYWFysjI0Lhx465qHX6d\nrZCdna3ly5ersLBQklRaWqqCggINHz78qjYGAACurejoaBUUFPiWT58+raioKEnS9u3bdfbsWT36\n6KO6dOmScnNzNX/+fKWkpFS7Tr8qB/PmzdPo0aNVXFys5ORk9ejRo8YVAwAA+ysHCQkJ2rBhgyTp\nwIEDio6OltvtliQNHjxY69ev15o1a7Rs2TLFxsb69f3tV+WgcePG6tWrl8LDwxUXF6e4uDhNmDBB\n/fr18+flAABcv2ye5yA+Pl6xsbFKSkqSy+WSx+NRRkaGmjdvroEDB9ZqnX4lB02aNFFmZqbatm2r\nJUuWqF27dsrLy6vVBgEAwLU1ffp0y3Lnzp2veE7btm21cuVKv9bn17DC4sWLFRMTo9TUVIWHh+vQ\noUNauHChXxsAAOB6Zrx1v9U3vyoHbrfbN34xZcoUWwMCAKAhceL0yVxbAQAAGzkxOWASJAAAYEHl\nAAAAGzmxckByAACAjUgOAACARU0XTgpG9BwAAAALKgcAANiJYQUAAFCREckBAACowIkNifQcAAAA\nCyoHAADYyATi4gh1RHIAAICNnDisQHIAAICNnJgc0HMAAAAsqBwAAGAjJ1YOSA4AALARDYmVKC39\n0e5NNECuQAdQqRfT1wU6hCpNfWRYoEOoVERE00CHUKUfS0sDHUKlIsLCAh2C4+w/dizQIVQqrl27\nQIcQHBxYOaDnAAAAWDCsAACAjZg+GQAAWDixIZFhBQAAYEHlAAAAGzmxckByAACAjTiVEQAAWDix\nckDPAQAAsKByAACAjZxYOSA5AADARiQHAADAyoHJAT0HAADAgsoBAAA2MuJURgAAUIETew78GlY4\nffq03XEAANAgGWPqfKtvfiUHzzzzjN1xAACAIOHXsEJUVJSSkpLUpUsXhYWF+e5PTk62LTAAABoC\nJw4r+JUc9OnTx+44AABokBrstRWGDx9udxwAADRITqwcMM8BAACw4FRGAABs5MTKAckBAAB2IjkA\nAAAVGTkvOaDnAAAAWFA5AADARg32VEYAAFA7NCQCAAALJyYH9BwAAAALKgcAANjIiZUDkgMAAGzk\nxIZEhhUAAIAFlQMAAGzEsAIAALAiOQAAABUxfTIAAHA8KgcAANiIngMAAGDhxFMZbU8OGjUKsXsT\nteL1lgc6hGoEZ5Y59ZFhgQ6hSpv37w90CJWa+8TcQIdQpYiwsECHUKlg/iurVav2gQ6hUv279g50\nCJW6VFYW6BCCQjAf01Wh5wAAAFgwrAAAgI2cWDkgOQAAwEYkBwAAwKI+koP58+crKytLLpdLKSkp\nuvPOO32Pbd++XUuWLFGjRo3Uvn17paWlqVGj6rsK6DkAAMDBdu7cqZycHK1evVppaWlKS0uzPJ6a\nmqqlS5fq7bff1sWLF/W3v/2txnVSOQAAwE42n8q4bds2DRgwQJIUExOjc+fOqaioSG63W5KUkZHh\n+7lFixb6/vvva1wnlQMAAGxkrsG/6hQUFCgyMtK33KJFC+Xn5/uWLycGp0+f1t///nf17du3xpip\nHAAAYKP6bkisbHtnzpzRxIkT5fF4LIlEVagcAADgYNHR0SooKPAtnz59WlFRUb7loqIiPf7445o6\ndap69/ZvwiySAwAAbGSMqfOtOgkJCdqwYYMk6cCBA4qOjvYNJUjSggUL9K//+q/q06eP3zEzrAAA\ngI3svrZCfHy8YmNjlZSUJJfLJY/Ho4yMDDVv3ly9e/fWu+++q5ycHK1du1aS9OCDDyoxMbHadZIc\nAABgo/roOZg+fbpluXPnzr6f99fi2jMMKwAAAAsqBwAA2IjpkwEAgIUTkwO/hhX+8z//07J89uxZ\nPfXUU7YEBAAAAsuv5KC4uFjJycm6dOmS3n//fY0ePVqDBw+2OzYAAJzPmLrf6plfwwrPPPOMPv74\nYw0ZMkQdO3ZUenq6XzMsAQBwvTOy91RGO1SbHCxcuFAul8u3fNtttyknJ0fLly+XJCUnJ9sbHQAA\nDufEnoNqk4NOnTpZln/5y1/aGgwAAAi8apOD4cOH11ccAAA0SA2ucgAAAOqG5AAAAFjYfW0FOzB9\nMgAAsKByAACAjRhWAAAAFiQHAADAyoHJAT0HAADAgsoBAAA2MnJe5YDkAAAAGznxVEaSAwAAbOTE\nhkR6DgAAgAWVAwAAbOTEygHJAQAANiI5AAAAFk5MDug5AAAAFlQOAACwkRNPZXQZm+sdLpfLztUD\nQS6Yj3/nlToDbffRo4EOoVLdYzoGOoRKBXM53estr7dttb4lps7rOJF35BpE4j8qBwAA2MiJMyTS\ncwAAACyoHAAAYKNgHl6pCskBAAA2cmJDIsMKAADAgsoBAAA2YlgBAABYkBwAAAALJyYH9BwAAAAL\nKgcAANjIiZUDkgMAAOzkwFMZSQ4AALAR0ycDAADHo3IAAICN6DkAAAAWJAcAAMCCaysAAADHqzY5\nKCsr05YtW3zLW7duVUpKil555RWVlJTYHhwAAE5njKnzrb5Vmxx4PB59+umnkqTc3Fw9/fTT6tGj\nh1wul5577rl6CRAAACdzYnJQbc/B4cOHtWbNGknSBx98oMGDB2vYsGGSpDFjxtgfHQAADufEhsRq\nKwcRERG+n7du3aq+ffvaHhAAAAisaisHTZo00YYNG3T+/Hl9++23SkhIkCQdOXKkXoIDAMDxHFg5\nqDY5+MMf/qAXX3xRFy5c0Msvv6yIiAj9+OOPmjRpkl544YX6ihEAAMcyct6pjC5Ti8EQY4xcLpd/\nG/DzeUDDFMzHv/P+mgm03UePBjqESnWP6RjoECoVzGPtXm95vW2radPmdV5HcfGFaxCJ/2qcBOmd\nd97R66+/rsLCQrlcLt18880aN26cHnroofqIDwAA1LNqk4P09HRt27ZNf/nLX3TLLbdIkr777jst\nXLhQZ86c0b/927/VR4wAADhWMFdQqlLtsMKIESO0Zs0ahYZac4jS0lIlJiYqIyOj5g0wrIDrWjAf\n/877DyvQGFa4OsH8pVifwwqNGzer8zpKSi5eg0j8V23lIDw8/IrEQJLCwsIUHh5uW1AAADQUwZwk\nVaXGayucPHnyivuOHTtmSzAAACDwqq0cPPnkkxo3bpzGjh2rO+64Q+Xl5crOztZbb72lP/7xj/UV\nIwAAjuXEqzJW23Nw/vx5FRUVKT09Xd98840aNWqkDh06KCkpSQUFBerSpUvNG6DnANe1YD7+nVfq\nDDR6Dq5OMJfT67PnICwsouYn1aC09MdrEIn/qh1WmDJlilq3bq1p06bppZdeUmRkpJ5++mndcsst\nVA4AAGigqh1W+HnW9+2331b5GAAAqIQDvy+rTQ5+PiRQMSFguAAAgJoZBw7h1ThDYkUkBAAAXJ36\naEicP3++srKy5HK5lJKSojvvvNP32NatW7VkyRKFhISoT58+mjx5co3rqzY52L9/v0aOHCnpp6rB\n0aNHNXLkSBljLEMMAAAgMHbu3KmcnBytXr1aR44cUUpKilavXu17fN68eXrttdfUsmVLPfbYYxo0\naJA6dqy+ibXa5OCDDz64NpEDAHCdsrtHb9u2bRowYIAkKSYmRufOnVNRUZHcbreOHTumG264wXcJ\nhL59+2rbtm11Sw7atGlzjUIHAOD6ZHdyUFBQoNjYWN9yixYtlJ+fL7fbrfz8fLVo0cLymD8TGV5V\nz0FtcFYDANirvLws0CGgGvX9PXgttlfj9MkAACB4RUdHq6CgwLd8+vRpRUVFVfrYqVOnFB0dXeM6\nSQ4AAHCwhIQEbdiwQZJ04MABRUdHy+12S5Latm2roqIiHT9+XGVlZdqyZYsSEhJqXGe10ycDAIDg\nt3jxYv3f//2fXC6XPB6PDh48qObNm2vgwIHatWuXFi9eLEl64IEHNGHChJpXaNAgnDp1ytx+++3m\n1Vdftdy/e/duk5uba4wx5vDhw2b//v213sa7775rjDHm4MGDZu7cubUPto4+/fRT8/LLL1f7nBkz\nZpg1a9ZccX9xcbHZsGGD39uquP/8cfLkSbN161ZjjDFLly41S5Ys8fu114vLx1F98ueYqeixxx4z\nf//7322M6EonTpww8fHxZvv27fW6XaAyDCs0EO+++65iYmKUkZFhuT8jI8PXmbpp0yYdPHiwVus/\ndeqU3n77bUnS7bffrtmzZ9ct4Dro06ePJk2aVKvXHjx4UBs3bvT7+RX3nz927Nih7du31ya060LF\n46g+1eWYqQ/GGKWmpqpDhw6BDgWQVA9nK6B+vPPOO5ozZ45mzpypPXv2KD4+Xps2bdLHH3+sffv2\n6Z//+Z/15ptvyu12q3HjxurTp488Ho/Onj2roqIijRs3Tg899JD+/Oc/q7CwUCdPnlROTo569uyp\n2bNna9q0afr666+VnJyshx9+WC+++KLS09N19OhReTweGWNUVlamadOmqVu3bpo5c6aio6P19ddf\n+ybPevzxx33xHjt2TE899ZTWrVsnY4wSEhL07LPPavjw4froo4+0e/duzZw5U3PnzlVOTo4uXryo\nBx98UOPHj1dGRoa2bt2qxYsX69NPP9ULL7ygG264Qffdd5/efPNNffbZZ5KkQ4cOaeLEifr22281\nYsQIjR07VrNmzdL58+e1aNEiDRs2TKmpqQoLC1NJSYkmT56s+++/3xdjxf33u9/9Tq1atar0vVZ8\nTy+++KKMMbrxxhsl/fRl+NRTT+mbb75Rjx49lJqaKklasmSJ9uzZo5KSEnXv3l3JycmWGUhPnTql\n6dOnS5JKSkqUmJiokSNHVru/u3btqlGjRkmSfvWrX+nAgQN65ZVXdPz4cZ04cUIzZsyQ2+3W7Nmz\n5fV6FRERoeeff14tW7bUypUr9de//lXl5eXq0KGDPB6PGjdu7Ivn4sWLmjZtms6fP6+ysjL169dP\nkyZN0rlz52p9HC1atKjS7RYUFGjSpEnq3bu39u3bp4sXL+rVV19Vy5YttWXLFi1btkwRERG67bbb\nNHfuXHm93kqPk4oqHjP9+/fX2LFj9dlnn+n48eN67rnn9Otf/7rS3yuv1yuPx6NvvvlGly5d0l13\n3aXf//73mjZtmhISEjRixAhJksfjUadOnfTggw9WuT8qfg5xcXGW7aSnp6tLly46ceKEH7/tQD0I\nZNkC18bOnTtN//79jdfrNUuWLDGzZs3yPVaxPFqx1D5nzhyzdu1aY4wxFy9eNAMGDDBnzpwxS5cu\nNUlJSaasrMz88MMP5u677zaFhYVm+/btJikpyRhjLD+PHz/erF+/3hhjzFdffWX69+/v29bUqVON\nMcYcP37cxMfHXxH3Aw88YC5OOyNMAAAIhElEQVRcuGC++uorM378eDNz5kxjjDGzZ882mZmZZvny\n5eZPf/qTMcaYsrIyM2LECPPll1+ad955x0ybNs14vV7Tt29f8+WXXxpjjFm8eLG57777rth+Xl6e\nufvuu40xxvdaY4z5wx/+4BuGKSgoMOvWrbsixor7r6r3WlHFoYTL+7K0tNSUlJSYu+++25w9e9as\nX7/eJCcn+17zxBNPmMzMTMt6VqxYYVJTU40xxpSUlJiVK1fWuL8rDqN06tTJlJaWmqVLl5rRo0cb\nr9drjDFm7NixZsuWLcYYYz788EOzYsUKk5WVZcaMGeN7Tlpamvnv//5vSzwbN240EyZMMMYYU15e\nbl5//XVTXl5ep+Ooqu0eO3bM3H777ebrr782xhgzc+ZMs2LFClNcXGzuvfdec+bMGWOMMYsWLTI7\nduyo8jipqOLn3q9fP/PWW28ZY4zJyMgwEydOvOJzvPy5nz171rfvjTFm0KBB5tChQ2bnzp3mscce\n822zX79+5vz589Xuj4qfQ0W5ubkmKSnJXLp0ycyYMYNhBQQFKgcNwNq1azV8+HC5XC6NGDFCI0aM\n0KxZs9SkSZMqX7Njxw5lZ2fr3XfflSSFhobq+PHjkqSuXbsqJCREISEhioyM1Llz56pcT1ZWlv7j\nP/5D0k9/rRYVFens2bOSpB49ekj6aTKtoqIilZeXKyQkxPfaXr16affu3crJydGwYcO0atUqSdKe\nPXs0Y8YMpaen6+TJk9q1a5ck6dKlS8rNzfW9/vvvv1dxcbE6d+4sSRo0aJDee+893+OXt9+qVSsV\nFxervNx6/fZBgwZp5syZOnHihPr166ehQ4dW+T6re68VJxj5ua5duyo0NFShoaGKjIzUhQsXtGPH\nDu3du1djxoyRJF24cMG37y+777779NZbb2nmzJnq27evEhMTa9zfVbnrrrt8VYl9+/b59suQIUMk\nScuXL1dubq7Gjh0rSSouLlZoqPW/hvj4eC1dulS//e1v1bdvX40aNUqNGjWq03G0Y8eOKrcbGRmp\nX/7yl5Kk1q1bq7CwUP/4xz/UqlUr3/5+9tlnffFXdpxcPi4qc3kftG7dutrj+xe/+IXy8vKUmJio\n8PBw5efn6/vvv1fPnj119uxZHTt2TMePH1fXrl3VvHnzavdHxc/hMq/Xq9mzZ/sqWECwIDlwuKKi\nIm3cuFG33HKLNm3aJOmn/3A2bNigYcOGVfm68PBweTwedenSxXL/p59+avkCl6qfUKOyi3Fdvu/n\nXzA/X0/v3r21a9cuHT16VKmpqdq0aZOysrIUGRmpZs2aKTw8XJMnT9bgwYMtr7vcV2GMsWz/53HX\ntP3u3bvrww8/1LZt25SRkaH3339fL7zwQq3ea1Uq25fh4eH6zW9+U23HcExMjD766CPt2rVLH3/8\nsd544w29/fbbVcZQ8f5Lly5ZHv/5l47Xa70ITHh4uPr37+8b8qjMTTfdpPfee09ffPGFMjMz9fDD\nD2vdunV1Oo6q2u7x48crfa3L5ar0WKzqOKlOxWOjuuP7o48+UnZ2tlatWqXQ0FDfMIIkjRo1Su+/\n/75OnTrlG86pbn9U9uV/9OhRHT9+XB6PR5KUm5urffv26bnnnlP37t39fj/AtUZDosN9+OGH6t69\nu9avX6/33ntP7733nubOnev7AnW5XCotLb3i565du+qvf/2rpJ/GtOfMmaOysqpnWWvUqFGlj991\n1136/PPPJf3U7HfjjTcqMjLSr9h79uypPXv2KD8/Xy1btlS3bt30yiuvqHfv3lfE6PV69fzzz6uw\nsND3+sjISDVq1EjffPONJPnVaFjxfaxcuVInT55U//79lZaWpqysrCueX3Gf+fNeXS5Xtfvx8vva\ntGmT73nLli274kJmH3zwgbKzs3XvvffK4/EoLy9PZWVlVcbQrFkz5eXlSfppnvWqkpb4+Hj97W9/\nkyStX79eS5YsUXx8vD777DNdvHhRkrRq1Sp98cUXltd9/vnn+uSTT9S1a1clJyeradOmOnPmTJ2O\nI3+2W1GHDh106tQpnTx5UpL0/PPPa/PmzTUeJ3Vx5swZtW/fXqGhodq/f79yc3N9ydewYcOUmZmp\nr776yleJuNr9ERMTo82bN2vNmjVas2aN7r//fnk8HhIDBByVA4dbu3btFZffHDRokBYsWKDjx48r\nISFBHo9HKSkp6tWrlxYtWiRjjKZMmaLf//73euSRR3Tp0iUlJiZe8Zd2RR07dtSZM2c0btw4TZw4\n0Xf/7Nmz5fF4lJ6errKyMi1atMjv2H/xi1/I6/WqU6dOkn4q9c6fP19TpkyRJD366KM6fPiwEhMT\nVV5ervvvv9/X6Cf99EWTkpKiyZMnq3Xr1urWrVu170GSunTposWLF+t3v/udHnzwQU2bNk3NmjWT\n1+vVtGnTrnh+xf3nz3vt1q2bnn76aYWFhV3x1+9lDzzwgPbu3aukpCSFhITojjvuULt27SzP6dix\nozwej8LDw2WM0eOPP67Q0NAqYxg5cqR++9vfateuXerdu7eaN29e6bZnz56t2bNn66233lJoaKjm\nz5+vW265RY8++qjGjBmjiIgIRUdHW/5ClqT27dtr5syZ+q//+i+FhISod+/eatOmTZ2OoxUrVlS6\n3TNnzlT62qZNmyotLU1PPvmkwsPD1bZtW91///0qLy+v9jipi8GDB2vixIl67LHHFB8fr/Hjx2ve\nvHlas2aNbrzxRrVr184yp/3V7g8gWDEJEhxt8+bN+tWvfqV27dpp48aNWr16tV577bVAh4XrwPnz\n55WUlKRVq1b5XS0DnIKUFo7m9Xr15JNPyu12q7y8XHPmzAl0SLgOrF27Vm+88YamTp1KYoAGicoB\nAACwoCERAABYkBwAAAALkgMAAGBBcgAAACxIDgAAgAXJAQAAsPh/jkafhIhGhjUAAAAASUVORK5C\nYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgcAAAGHCAYAAAAk+fF+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x396 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgcAAAGHCAYAAAAk+fF+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAFv8fcW9M8NUQbxcAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'awarnarway'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    }
  ]
}