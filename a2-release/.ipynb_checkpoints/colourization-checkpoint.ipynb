{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TjPTaRB4mpCd"
   },
   "source": [
    "# Colab FAQ\n",
    "\n",
    "For some basic overview and features offered in Colab notebooks, check out: [Overview of Colaboratory Features](https://colab.research.google.com/notebooks/basic_features_overview.ipynb)\n",
    "\n",
    "You need to use the colab GPU for this assignmentby selecting:\n",
    "\n",
    "> **Runtime**   →   **Change runtime type**   →   **Hardware Accelerator: GPU**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s9IS9B9-yUU5"
   },
   "source": [
    "# Download CIFAR and Colour dictionary\n",
    "It can take up to a couple of minutes to download everything the first time.\n",
    "\n",
    "All files are stored at /content/csc421/a2/data/ folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4BIpGwANoQOg"
   },
   "source": [
    "## Helper code\n",
    "You can ignore the restart warning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "piDmAsqFG0gU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (1.0.0)\n",
      "Requirement already satisfied: torchvision in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (0.2.1)\n",
      "Requirement already satisfied: six in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from torchvision) (1.11.0)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from torchvision) (1.16.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from torchvision) (5.4.1)\n",
      "\u001b[33mYou are using pip version 19.0.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting Pillow==4.0.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8d/80/eca7a2d1a3c2dafb960f32f844d570de988e609f5fd17de92e1cf6a01b0a/Pillow-4.0.0.tar.gz (11.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 11.1MB 1.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting olefile (from Pillow==4.0.0)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/81/e1ac43c6b45b4c5f8d9352396a14144bba52c8fec72a80f425f6a4d653ad/olefile-0.46.zip (112kB)\n",
      "\u001b[K    100% |████████████████████████████████| 112kB 11.3MB/s ta 0:00:01\n",
      "\u001b[31mtorchvision 0.2.1 has requirement pillow>=4.1.1, but you'll have pillow 4.0.0 which is incompatible.\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: olefile, Pillow\n",
      "  Running setup.py install for olefile ... \u001b[?25ldone\n",
      "\u001b[?25h  Found existing installation: Pillow 5.4.1\n",
      "    Uninstalling Pillow-5.4.1:\n",
      "      Successfully uninstalled Pillow-5.4.1\n",
      "  Running setup.py install for Pillow ... \u001b[?25lerror\n",
      "    Complete output from command /Library/Frameworks/Python.framework/Versions/3.7/bin/python3.7 -u -c \"import setuptools, tokenize;__file__='/private/var/folders/0d/h4dc98y57x7f01vttl9ktvfm0000gn/T/pip-install-4r54u4s1/Pillow/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" install --record /private/var/folders/0d/h4dc98y57x7f01vttl9ktvfm0000gn/T/pip-record-4w6by99y/install-record.txt --single-version-externally-managed --compile:\n",
      "    running install\n",
      "    running build\n",
      "    running build_py\n",
      "    creating build\n",
      "    creating build/lib.macosx-10.9-x86_64-3.7\n",
      "    creating build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/MpoImagePlugin.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/ImageMode.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/PngImagePlugin.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/XbmImagePlugin.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/PcxImagePlugin.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/SunImagePlugin.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/ImageFile.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/SpiderImagePlugin.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/TarIO.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/FitsStubImagePlugin.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/MpegImagePlugin.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/BdfFontFile.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/GribStubImagePlugin.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/ImageStat.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/PixarImagePlugin.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/GimpPaletteFile.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/ImageColor.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/ContainerIO.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/MspImagePlugin.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/MicImagePlugin.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/ImtImagePlugin.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/GifImagePlugin.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/PalmImagePlugin.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/ImageQt.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/ImageMath.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/PaletteFile.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/FontFile.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/ExifTags.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/ImageCms.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/FpxImagePlugin.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/ImageChops.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/BufrStubImagePlugin.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/PSDraw.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/PcdImagePlugin.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/ImageFilter.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/ImageDraw2.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/ImagePath.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/DcxImagePlugin.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/__init__.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/JpegPresets.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/Hdf5StubImagePlugin.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/features.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/ImageDraw.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/GimpGradientFile.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/ImageWin.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/IcoImagePlugin.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/_tkinter_finder.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/EpsImagePlugin.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/TgaImagePlugin.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/ImageMorph.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/Jpeg2KImagePlugin.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/WalImageFile.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/PcfFontFile.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/ImageTk.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/GbrImagePlugin.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/ImageOps.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/PdfImagePlugin.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/ImageShow.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/ImageEnhance.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/WmfImagePlugin.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/ImageGrab.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/WebPImagePlugin.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/FliImagePlugin.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/TiffTags.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/CurImagePlugin.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/_util.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/GdImageFile.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/TiffImagePlugin.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/IptcImagePlugin.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/ImagePalette.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/BmpImagePlugin.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/ImageTransform.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/IcnsImagePlugin.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/McIdasImagePlugin.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/XpmImagePlugin.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/OleFileIO.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/DdsImagePlugin.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/ImageSequence.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/PyAccess.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/_binary.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/Image.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/XVThumbImagePlugin.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/SgiImagePlugin.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/ImImagePlugin.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/PsdImagePlugin.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/JpegImagePlugin.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/ImageFont.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/PpmImagePlugin.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    copying PIL/FtexImagePlugin.py -> build/lib.macosx-10.9-x86_64-3.7/PIL\n",
      "    running egg_info\n",
      "    writing Pillow.egg-info/PKG-INFO\n",
      "    writing dependency_links to Pillow.egg-info/dependency_links.txt\n",
      "    writing requirements to Pillow.egg-info/requires.txt\n",
      "    writing top-level names to Pillow.egg-info/top_level.txt\n",
      "    reading manifest file 'Pillow.egg-info/SOURCES.txt'\n",
      "    reading manifest template 'MANIFEST.in'\n",
      "    warning: no files found matching '*.sh'\n",
      "    no previously-included directories found matching 'docs/_static'\n",
      "    warning: no previously-included files found matching '.coveragerc'\n",
      "    warning: no previously-included files found matching '.editorconfig'\n",
      "    warning: no previously-included files found matching '.landscape.yaml'\n",
      "    warning: no previously-included files found matching 'appveyor.yml'\n",
      "    warning: no previously-included files found matching 'build_children.sh'\n",
      "    warning: no previously-included files found matching 'tox.ini'\n",
      "    warning: no previously-included files matching '.git*' found anywhere in distribution\n",
      "    warning: no previously-included files matching '*.pyc' found anywhere in distribution\n",
      "    warning: no previously-included files matching '*.so' found anywhere in distribution\n",
      "    writing manifest file 'Pillow.egg-info/SOURCES.txt'\n",
      "    running build_ext\n",
      "    \n",
      "    \n",
      "    The headers or library files could not be found for zlib,\n",
      "    a required dependency when compiling Pillow from source.\n",
      "    \n",
      "    Please see the install instructions at:\n",
      "       http://pillow.readthedocs.io/en/latest/installation.html\n",
      "    \n",
      "    Traceback (most recent call last):\n",
      "      File \"/private/var/folders/0d/h4dc98y57x7f01vttl9ktvfm0000gn/T/pip-install-4r54u4s1/Pillow/setup.py\", line 779, in <module>\n",
      "        zip_safe=not debug_build(), )\n",
      "      File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/setuptools/__init__.py\", line 129, in setup\n",
      "        return distutils.core.setup(**attrs)\n",
      "      File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/distutils/core.py\", line 148, in setup\n",
      "        dist.run_commands()\n",
      "      File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/distutils/dist.py\", line 966, in run_commands\n",
      "        self.run_command(cmd)\n",
      "      File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/distutils/dist.py\", line 985, in run_command\n",
      "        cmd_obj.run()\n",
      "      File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/setuptools/command/install.py\", line 61, in run\n",
      "        return orig.install.run(self)\n",
      "      File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/distutils/command/install.py\", line 545, in run\n",
      "        self.run_command('build')\n",
      "      File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/distutils/cmd.py\", line 313, in run_command\n",
      "        self.distribution.run_command(command)\n",
      "      File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/distutils/dist.py\", line 985, in run_command\n",
      "        cmd_obj.run()\n",
      "      File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/distutils/command/build.py\", line 135, in run\n",
      "        self.run_command(cmd_name)\n",
      "      File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/distutils/cmd.py\", line 313, in run_command\n",
      "        self.distribution.run_command(command)\n",
      "      File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/distutils/dist.py\", line 985, in run_command\n",
      "        cmd_obj.run()\n",
      "      File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/distutils/command/build_ext.py\", line 339, in run\n",
      "        self.build_extensions()\n",
      "      File \"/private/var/folders/0d/h4dc98y57x7f01vttl9ktvfm0000gn/T/pip-install-4r54u4s1/Pillow/setup.py\", line 549, in build_extensions\n",
      "        raise RequiredDependencyException(f)\n",
      "    __main__.RequiredDependencyException: zlib\n",
      "    \n",
      "    During handling of the above exception, another exception occurred:\n",
      "    \n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"/private/var/folders/0d/h4dc98y57x7f01vttl9ktvfm0000gn/T/pip-install-4r54u4s1/Pillow/setup.py\", line 791, in <module>\n",
      "        raise RequiredDependencyException(msg)\n",
      "    __main__.RequiredDependencyException:\n",
      "    \n",
      "    The headers or library files could not be found for zlib,\n",
      "    a required dependency when compiling Pillow from source.\n",
      "    \n",
      "    Please see the install instructions at:\n",
      "       http://pillow.readthedocs.io/en/latest/installation.html\n",
      "    \n",
      "    \n",
      "    \n",
      "    ----------------------------------------\n",
      "\u001b[?25h  Rolling back uninstall of Pillow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mCould not install packages due to an EnvironmentError: [Errno 22] Invalid argument: '/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/-IL/.'\n",
      "\u001b[0m\n",
      "\u001b[33mYou are using pip version 19.0.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "mkdir: /content/csc421/a2/: Permission denied\n",
      "[Errno 2] No such file or directory: '/content/csc421/a2'\n",
      "/Users/mingrenchen/Desktop/csc421/a2-release\n"
     ]
    }
   ],
   "source": [
    "######################################################################\n",
    "# Setup python environment and change the current working directory\n",
    "######################################################################\n",
    "!pip install torch torchvision\n",
    "!pip install Pillow==4.0.0\n",
    "%mkdir -p /content/csc421/a2/\n",
    "%cd /content/csc421/a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wa5-onJhoSeM"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Image' from 'PIL' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-295b4a59823d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Image' from 'PIL' (unknown location)"
     ]
    }
   ],
   "source": [
    "# adapted from \n",
    "# https://github.com/fchollet/keras/blob/master/keras/datasets/cifar10.py\n",
    "\n",
    "import os\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "import tarfile\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sys\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def get_file(fname,\n",
    "             origin,\n",
    "             untar=False,\n",
    "             extract=False,\n",
    "             archive_format='auto',\n",
    "             cache_dir='data'):\n",
    "    datadir = os.path.join(cache_dir)\n",
    "    if not os.path.exists(datadir):\n",
    "        os.makedirs(datadir)\n",
    "\n",
    "    if untar:\n",
    "        untar_fpath = os.path.join(datadir, fname)\n",
    "        fpath = untar_fpath + '.tar.gz'\n",
    "    else:\n",
    "        fpath = os.path.join(datadir, fname)\n",
    "    \n",
    "    print(fpath)\n",
    "    if not os.path.exists(fpath):\n",
    "        print('Downloading data from', origin)\n",
    "\n",
    "        error_msg = 'URL fetch failure on {}: {} -- {}'\n",
    "        try:\n",
    "            try:\n",
    "                urlretrieve(origin, fpath)\n",
    "            except URLError as e:\n",
    "                raise Exception(error_msg.format(origin, e.errno, e.reason))\n",
    "            except HTTPError as e:\n",
    "                raise Exception(error_msg.format(origin, e.code, e.msg))\n",
    "        except (Exception, KeyboardInterrupt) as e:\n",
    "            if os.path.exists(fpath):\n",
    "                os.remove(fpath)\n",
    "            raise\n",
    "\n",
    "    if untar:\n",
    "        if not os.path.exists(untar_fpath):\n",
    "            print('Extracting file.')\n",
    "            with tarfile.open(fpath) as archive:\n",
    "                archive.extractall(datadir)\n",
    "        return untar_fpath\n",
    "\n",
    "    if extract:\n",
    "        _extract_archive(fpath, datadir, archive_format)\n",
    "\n",
    "    return fpath\n",
    "\n",
    "\n",
    "\n",
    "def load_batch(fpath, label_key='labels'):\n",
    "    \"\"\"Internal utility for parsing CIFAR data.\n",
    "    # Arguments\n",
    "        fpath: path the file to parse.\n",
    "        label_key: key for label data in the retrieve\n",
    "            dictionary.\n",
    "    # Returns\n",
    "        A tuple `(data, labels)`.\n",
    "    \"\"\"\n",
    "    f = open(fpath, 'rb')\n",
    "    if sys.version_info < (3,):\n",
    "        d = pickle.load(f)\n",
    "    else:\n",
    "        d = pickle.load(f, encoding='bytes')\n",
    "        # decode utf8\n",
    "        d_decoded = {}\n",
    "        for k, v in d.items():\n",
    "            d_decoded[k.decode('utf8')] = v\n",
    "        d = d_decoded\n",
    "    f.close()\n",
    "    data = d['data']\n",
    "    labels = d[label_key]\n",
    "\n",
    "    data = data.reshape(data.shape[0], 3, 32, 32)\n",
    "    return data, labels\n",
    "\n",
    "def load_cifar10(transpose=False):\n",
    "    \"\"\"Loads CIFAR10 dataset.\n",
    "    # Returns\n",
    "        Tuple of Numpy arrays: `(x_train, y_train), (x_test, y_test)`.\n",
    "    \"\"\"\n",
    "    dirname = 'cifar-10-batches-py'\n",
    "    origin = 'http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz'\n",
    "    path = get_file(dirname, origin=origin, untar=True)\n",
    "\n",
    "    num_train_samples = 50000\n",
    "\n",
    "    x_train = np.zeros((num_train_samples, 3, 32, 32), dtype='uint8')\n",
    "    y_train = np.zeros((num_train_samples,), dtype='uint8')\n",
    "\n",
    "    for i in range(1, 6):\n",
    "        fpath = os.path.join(path, 'data_batch_' + str(i))\n",
    "        data, labels = load_batch(fpath)\n",
    "        x_train[(i - 1) * 10000: i * 10000, :, :, :] = data\n",
    "        y_train[(i - 1) * 10000: i * 10000] = labels\n",
    "\n",
    "    fpath = os.path.join(path, 'test_batch')\n",
    "    x_test, y_test = load_batch(fpath)\n",
    "\n",
    "    y_train = np.reshape(y_train, (len(y_train), 1))\n",
    "    y_test = np.reshape(y_test, (len(y_test), 1))\n",
    "\n",
    "    if transpose:\n",
    "        x_train = x_train.transpose(0, 2, 3, 1)\n",
    "        x_test = x_test.transpose(0, 2, 3, 1)\n",
    "    return (x_train, y_train), (x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2jIKvJNtoVgU"
   },
   "source": [
    "## Download files\n",
    "\n",
    "This may take 1 or 2 mins for the first time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l7fti3cryStt"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-d905dcf9b435>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Download CIFAR datasets and other related files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m######################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m colours_fpath = get_file(fname='colours', \n\u001b[0m\u001b[1;32m      5\u001b[0m                          \u001b[0morigin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'http://www.cs.toronto.edu/~jba/kmeans_colour_a2.tar.gz'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                          untar=True)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_file' is not defined"
     ]
    }
   ],
   "source": [
    "######################################################################\n",
    "# Download CIFAR datasets and other related files\n",
    "######################################################################\n",
    "colours_fpath = get_file(fname='colours', \n",
    "                         origin='http://www.cs.toronto.edu/~jba/kmeans_colour_a2.tar.gz', \n",
    "                         untar=True)\n",
    "m = load_cifar10()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bXNsLNkOn38w"
   },
   "source": [
    "# Code for training and CNN models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oWyZwl9VKkxD"
   },
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bTF1TQObE6DG"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Colourization of CIFAR-10 Horses via classification.\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "import math\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import scipy.misc\n",
    "import time\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "\n",
    "#from load_data import load_cifar10\n",
    "\n",
    "HORSE_CATEGORY = 7\n",
    "\n",
    "######################################################################\n",
    "# Data related code\n",
    "######################################################################\n",
    "def get_rgb_cat(xs, colours):\n",
    "    \"\"\"\n",
    "    Get colour categories given RGB values. This function doesn't\n",
    "    actually do the work, instead it splits the work into smaller\n",
    "    chunks that can fit into memory, and calls helper function\n",
    "    _get_rgb_cat\n",
    "\n",
    "    Args:\n",
    "      xs: float numpy array of RGB images in [B, C, H, W] format\n",
    "      colours: numpy array of colour categories and their RGB values\n",
    "    Returns:\n",
    "      result: int numpy array of shape [B, 1, H, W]\n",
    "    \"\"\"\n",
    "    if np.shape(xs)[0] < 100:\n",
    "        return _get_rgb_cat(xs)\n",
    "    batch_size = 100\n",
    "    nexts = []\n",
    "    for i in range(0, np.shape(xs)[0], batch_size):\n",
    "        next = _get_rgb_cat(xs[i:i+batch_size,:,:,:], colours)\n",
    "        nexts.append(next)\n",
    "    result = np.concatenate(nexts, axis=0)\n",
    "    return result\n",
    "\n",
    "def _get_rgb_cat(xs, colours):\n",
    "    \"\"\"\n",
    "    Get colour categories given RGB values. This is done by choosing\n",
    "    the colour in `colours` that is the closest (in RGB space) to\n",
    "    each point in the image `xs`. This function is a little memory\n",
    "    intensive, and so the size of `xs` should not be too large.\n",
    "\n",
    "    Args:\n",
    "      xs: float numpy array of RGB images in [B, C, H, W] format\n",
    "      colours: numpy array of colour categories and their RGB values\n",
    "    Returns:\n",
    "      result: int numpy array of shape [B, 1, H, W]\n",
    "    \"\"\"\n",
    "    num_colours = np.shape(colours)[0]\n",
    "    xs = np.expand_dims(xs, 0)\n",
    "    cs = np.reshape(colours, [num_colours,1,3,1,1])\n",
    "    dists = np.linalg.norm(xs-cs, axis=2) # 2 = colour axis\n",
    "    cat = np.argmin(dists, axis=0)\n",
    "    cat = np.expand_dims(cat, axis=1)\n",
    "    return cat\n",
    "\n",
    "def get_cat_rgb(cats, colours):\n",
    "    \"\"\"\n",
    "    Get RGB colours given the colour categories\n",
    "\n",
    "    Args:\n",
    "      cats: integer numpy array of colour categories\n",
    "      colours: numpy array of colour categories and their RGB values\n",
    "    Returns:\n",
    "      numpy tensor of RGB colours\n",
    "    \"\"\"\n",
    "    return colours[cats]\n",
    "\n",
    "def process(xs, ys, max_pixel=256.0, downsize_input=False):\n",
    "    \"\"\"\n",
    "    Pre-process CIFAR10 images by taking only the horse category,\n",
    "    shuffling, and have colour values be bound between 0 and 1\n",
    "\n",
    "    Args:\n",
    "      xs: the colour RGB pixel values\n",
    "      ys: the category labels\n",
    "      max_pixel: maximum pixel value in the original data\n",
    "    Returns:\n",
    "      xs: value normalized and shuffled colour images\n",
    "      grey: greyscale images, also normalized so values are between 0 and 1\n",
    "    \"\"\"\n",
    "    xs = xs / max_pixel\n",
    "    xs = xs[np.where(ys == HORSE_CATEGORY)[0], :, :, :]\n",
    "    npr.shuffle(xs)\n",
    "    \n",
    "    grey = np.mean(xs, axis=1, keepdims=True)\n",
    "\n",
    "    if downsize_input:\n",
    "      downsize_module = nn.Sequential(nn.AvgPool2d(2),\n",
    "                               nn.AvgPool2d(2), \n",
    "                               nn.Upsample(scale_factor=2), \n",
    "                               nn.Upsample(scale_factor=2))\n",
    "      xs_downsized = downsize_module.forward(torch.from_numpy(xs).float())\n",
    "      xs_downsized = xs_downsized.data.numpy()\n",
    "      return (xs, xs_downsized)\n",
    "    else:\n",
    "      return (xs, grey)\n",
    "\n",
    "\n",
    "def get_batch(x, y, batch_size):\n",
    "    '''\n",
    "    Generated that yields batches of data\n",
    "\n",
    "    Args:\n",
    "      x: input values\n",
    "      y: output values\n",
    "      batch_size: size of each batch\n",
    "    Yields:\n",
    "      batch_x: a batch of inputs of size at most batch_size\n",
    "      batch_y: a batch of outputs of size at most batch_size\n",
    "    '''\n",
    "    N = np.shape(x)[0]\n",
    "    assert N == np.shape(y)[0]\n",
    "    for i in range(0, N, batch_size):\n",
    "        batch_x = x[i:i+batch_size, :,:,:]\n",
    "        batch_y = y[i:i+batch_size, :,:,:]\n",
    "        yield (batch_x, batch_y)\n",
    "\n",
    "######################################################################\n",
    "# Torch Helper\n",
    "######################################################################\n",
    "\n",
    "def get_torch_vars(xs, ys, gpu=False):\n",
    "    \"\"\"\n",
    "    Helper function to convert numpy arrays to pytorch tensors.\n",
    "    If GPU is used, move the tensors to GPU.\n",
    "\n",
    "    Args:\n",
    "      xs (float numpy tenosor): greyscale input\n",
    "      ys (int numpy tenosor): categorical labels \n",
    "      gpu (bool): whether to move pytorch tensor to GPU\n",
    "    Returns:\n",
    "      Variable(xs), Variable(ys)\n",
    "    \"\"\"\n",
    "    xs = torch.from_numpy(xs).float()\n",
    "    ys = torch.from_numpy(ys).long()\n",
    "    if gpu:\n",
    "        xs = xs.cuda()\n",
    "        ys = ys.cuda()\n",
    "    return Variable(xs), Variable(ys)\n",
    "\n",
    "def compute_loss(criterion, outputs, labels, batch_size, num_colours):\n",
    "    \"\"\"\n",
    "    Helper function to compute the loss. Since this is a pixelwise\n",
    "    prediction task we need to reshape the output and ground truth\n",
    "    tensors into a 2D tensor before passing it in to the loss criteron.\n",
    "\n",
    "    Args:\n",
    "      criterion: pytorch loss criterion\n",
    "      outputs (pytorch tensor): predicted labels from the model\n",
    "      labels (pytorch tensor): ground truth labels\n",
    "      batch_size (int): batch size used for training\n",
    "      num_colours (int): number of colour categories\n",
    "    Returns:\n",
    "      pytorch tensor for loss\n",
    "    \"\"\"\n",
    "\n",
    "    loss_out = outputs.transpose(1,3) \\\n",
    "                      .contiguous() \\\n",
    "                      .view([batch_size*32*32, num_colours])\n",
    "    loss_lab = labels.transpose(1,3) \\\n",
    "                      .contiguous() \\\n",
    "                      .view([batch_size*32*32])\n",
    "    return criterion(loss_out, loss_lab)\n",
    "\n",
    "def run_validation_step(cnn, criterion, test_grey, test_rgb_cat, batch_size,\n",
    "                        colours, plotpath=None, visualize=True, downsize_input=False):\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    losses = []\n",
    "    num_colours = np.shape(colours)[0]\n",
    "    for i, (xs, ys) in enumerate(get_batch(test_grey,\n",
    "                                           test_rgb_cat,\n",
    "                                           batch_size)):\n",
    "        images, labels = get_torch_vars(xs, ys, args.gpu)\n",
    "        outputs = cnn(images)\n",
    "\n",
    "        val_loss = compute_loss(criterion,\n",
    "                                outputs,\n",
    "                                labels,\n",
    "                                batch_size=args.batch_size,\n",
    "                                num_colours=num_colours)\n",
    "        losses.append(val_loss.data.item())\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1, keepdim=True)\n",
    "        total += labels.size(0) * 32 * 32\n",
    "        correct += (predicted == labels.data).sum()\n",
    "\n",
    "    if plotpath: # only plot if a path is provided\n",
    "        plot(xs, ys, predicted.cpu().numpy(), colours, \n",
    "             plotpath, visualize=visualize, compare_bilinear=downsize_input)\n",
    "\n",
    "    val_loss = np.mean(losses)\n",
    "    val_acc = 100 * correct / total\n",
    "    return val_loss, val_acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rp_wCpMjqt5w"
   },
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "syg8NjwMqw_F"
   },
   "outputs": [],
   "source": [
    "def plot(input, gtlabel, output, colours, path, visualize, compare_bilinear=False):\n",
    "    \"\"\"\n",
    "    Generate png plots of input, ground truth, and outputs\n",
    "\n",
    "    Args:\n",
    "      input: the greyscale input to the colourization CNN\n",
    "      gtlabel: the grouth truth categories for each pixel\n",
    "      output: the predicted categories for each pixel\n",
    "      colours: numpy array of colour categories and their RGB values\n",
    "      path: output path\n",
    "      visualize: display the figures inline or save the figures in path\n",
    "    \"\"\"\n",
    "    grey = np.transpose(input[:10,:,:,:], [0,2,3,1])\n",
    "    gtcolor = get_cat_rgb(gtlabel[:10,0,:,:], colours)\n",
    "    predcolor = get_cat_rgb(output[:10,0,:,:], colours)\n",
    "\n",
    "    img_stack = [\n",
    "      np.hstack(np.tile(grey, [1,1,1,3])),\n",
    "      np.hstack(gtcolor),\n",
    "      np.hstack(predcolor)]\n",
    "    \n",
    "    if compare_bilinear:\n",
    "      downsize_module = nn.Sequential(nn.AvgPool2d(2),\n",
    "                                 nn.AvgPool2d(2), \n",
    "                                 nn.Upsample(scale_factor=2, mode='bilinear'), \n",
    "                                 nn.Upsample(scale_factor=2, mode='bilinear'))\n",
    "      gt_input = np.transpose(gtcolor, [0, 3, 1, 2,])\n",
    "      color_bilinear = downsize_module.forward(torch.from_numpy(gt_input).float())\n",
    "      color_bilinear = np.transpose(color_bilinear.data.numpy(), [0, 2, 3, 1])\n",
    "      img_stack = [\n",
    "        np.hstack(np.transpose(input[:10,:,:,:], [0,2,3,1])),\n",
    "        np.hstack(gtcolor),\n",
    "        np.hstack(predcolor),\n",
    "        np.hstack(color_bilinear)]\n",
    "    img = np.vstack(img_stack)\n",
    "    \n",
    "    plt.grid('off')\n",
    "    plt.imshow(img, vmin=0., vmax=1.)\n",
    "    if visualize:\n",
    "      plt.show()\n",
    "    else:\n",
    "      plt.savefig(path)\n",
    "\n",
    "def toimage(img, cmin, cmax):\n",
    "    return Image.fromarray((img.clip(cmin, cmax)*255).astype(np.uint8))\n",
    "  \n",
    "def plot_activation(args, cnn):\n",
    "    # LOAD THE COLOURS CATEGORIES\n",
    "    colours = np.load(args.colours)[0]\n",
    "    num_colours = np.shape(colours)[0]\n",
    "    \n",
    "    (x_train, y_train), (x_test, y_test) = load_cifar10()\n",
    "    test_rgb, test_grey = process(x_test, y_test, downsize_input = args.downsize_input)\n",
    "    test_rgb_cat = get_rgb_cat(test_rgb, colours)\n",
    "    \n",
    "    # Take the idnex of the test image\n",
    "    id = args.index\n",
    "    outdir = \"outputs/\" + args.experiment_name + '/act' + str(id)\n",
    "    if not os.path.exists(outdir):\n",
    "      os.makedirs(outdir)\n",
    "    images, labels = get_torch_vars(np.expand_dims(test_grey[id], 0),\n",
    "                                    np.expand_dims(test_rgb_cat[id], 0))\n",
    "    cnn.cpu()\n",
    "    outputs = cnn(images)\n",
    "    _, predicted = torch.max(outputs.data, 1, keepdim=True)\n",
    "    predcolor = get_cat_rgb(predicted.cpu().numpy()[0,0,:,:], colours)\n",
    "    img = predcolor\n",
    "    toimage(predcolor, cmin=0, cmax=1) \\\n",
    "            .save(os.path.join(outdir, \"output_%d.png\" % id))\n",
    "\n",
    "    if not args.downsize_input:\n",
    "      img = np.tile(np.transpose(test_grey[id], [1,2,0]), [1,1,3])\n",
    "    else:\n",
    "      img = np.transpose(test_grey[id], [1,2,0])\n",
    "    toimage(img, cmin=0, cmax=1) \\\n",
    "            .save(os.path.join(outdir, \"input_%d.png\" % id))\n",
    "\n",
    "    img = np.transpose(test_rgb[id], [1,2,0])\n",
    "    toimage(img, cmin=0, cmax=1) \\\n",
    "            .save(os.path.join(outdir, \"input_%d_gt.png\" % id))\n",
    "\n",
    "    \n",
    "    def add_border(img):\n",
    "        return np.pad(img, 1, \"constant\", constant_values=1.0)\n",
    "\n",
    "    def draw_activations(path, activation, imgwidth=4):\n",
    "        img = np.vstack([\n",
    "            np.hstack([\n",
    "                add_border(filter) for filter in\n",
    "                activation[i*imgwidth:(i+1)*imgwidth,:,:]])\n",
    "            for i in range(activation.shape[0] // imgwidth)])\n",
    "        scipy.misc.imsave(path, img)\n",
    "\n",
    "\n",
    "    for i, tensor in enumerate([cnn.out1, cnn.out2, cnn.out3, cnn.out4, cnn.out5]):\n",
    "        draw_activations(\n",
    "            os.path.join(outdir, \"conv%d_out_%d.png\" % (i+1, id)),\n",
    "            tensor.data.cpu().numpy()[0])\n",
    "    print(\"visualization results are saved to %s\"%outdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xIa_fiZYnRy7"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LtAdbbzHnP-n"
   },
   "outputs": [],
   "source": [
    "class AttrDict(dict):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(AttrDict, self).__init__(*args, **kwargs)\n",
    "        self.__dict__ = self\n",
    "\n",
    "def train(args, cnn=None):\n",
    "    # Set the maximum number of threads to prevent crash in Teaching Labs\n",
    "    torch.set_num_threads(5)\n",
    "    # Numpy random seed\n",
    "    npr.seed(args.seed)\n",
    "    \n",
    "    # Save directory\n",
    "    save_dir = \"outputs/\" + args.experiment_name\n",
    "\n",
    "    # LOAD THE COLOURS CATEGORIES\n",
    "    colours = np.load(args.colours)[0]\n",
    "    num_colours = np.shape(colours)[0]\n",
    "    # INPUT CHANNEL\n",
    "    num_in_channels = 1 if not args.downsize_input else 3\n",
    "    # LOAD THE MODEL\n",
    "    if cnn is None:\n",
    "      if args.model == \"CNN\":\n",
    "          cnn = CNN(args.kernel, args.num_filters, num_colours, num_in_channels)\n",
    "      elif args.model == \"UNet\":\n",
    "          cnn = UNet(args.kernel, args.num_filters, num_colours, num_in_channels)\n",
    "\n",
    "    # LOSS FUNCTION\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(cnn.parameters(), lr=args.learn_rate)\n",
    "\n",
    "    # DATA\n",
    "    print(\"Loading data...\")\n",
    "    (x_train, y_train), (x_test, y_test) = load_cifar10()\n",
    "\n",
    "    print(\"Transforming data...\")\n",
    "    train_rgb, train_grey = process(x_train, y_train, downsize_input = args.downsize_input)\n",
    "    train_rgb_cat = get_rgb_cat(train_rgb, colours)\n",
    "    test_rgb, test_grey = process(x_test, y_test, downsize_input = args.downsize_input)\n",
    "    test_rgb_cat = get_rgb_cat(test_rgb, colours)\n",
    "\n",
    "    # Create the outputs folder if not created already\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    print(\"Beginning training ...\")\n",
    "    if args.gpu: cnn.cuda()\n",
    "    start = time.time()\n",
    "\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    valid_accs = []\n",
    "    for epoch in range(args.epochs):\n",
    "        # Train the Model\n",
    "        cnn.train() # Change model to 'train' mode\n",
    "        losses = []\n",
    "        for i, (xs, ys) in enumerate(get_batch(train_grey,\n",
    "                                               train_rgb_cat,\n",
    "                                               args.batch_size)):\n",
    "            images, labels = get_torch_vars(xs, ys, args.gpu)\n",
    "            # Forward + Backward + Optimize\n",
    "            optimizer.zero_grad()\n",
    "            outputs = cnn(images)\n",
    "\n",
    "            loss = compute_loss(criterion,\n",
    "                                outputs,\n",
    "                                labels,\n",
    "                                batch_size=args.batch_size,\n",
    "                                num_colours=num_colours)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.data.item())\n",
    "\n",
    "        # plot training images\n",
    "        if args.plot:\n",
    "            _, predicted = torch.max(outputs.data, 1, keepdim=True)\n",
    "            plot(xs, ys, predicted.cpu().numpy(), colours,\n",
    "                 save_dir+'/train_%d.png' % epoch, \n",
    "                 args.visualize, \n",
    "                 args.downsize_input)\n",
    "\n",
    "        # plot training images\n",
    "        avg_loss = np.mean(losses)\n",
    "        train_losses.append(avg_loss)\n",
    "        time_elapsed = time.time() - start\n",
    "        print('Epoch [%d/%d], Loss: %.4f, Time (s): %d' % (\n",
    "            epoch+1, args.epochs, avg_loss, time_elapsed))\n",
    "\n",
    "        # Evaluate the model\n",
    "        cnn.eval()  # Change model to 'eval' mode (BN uses moving mean/var).\n",
    "        val_loss, val_acc = run_validation_step(cnn,\n",
    "                                                criterion,\n",
    "                                                test_grey,\n",
    "                                                test_rgb_cat,\n",
    "                                                args.batch_size,\n",
    "                                                colours,\n",
    "                                                save_dir+'/test_%d.png' % epoch,\n",
    "                                                args.visualize,\n",
    "                                                args.downsize_input)\n",
    "\n",
    "        time_elapsed = time.time() - start\n",
    "        valid_losses.append(val_loss)\n",
    "        valid_accs.append(val_acc)\n",
    "        print('Epoch [%d/%d], Val Loss: %.4f, Val Acc: %.1f%%, Time(s): %d' % (\n",
    "            epoch+1, args.epochs, val_loss, val_acc, time_elapsed))\n",
    "    \n",
    "    # Plot training curve\n",
    "    plt.figure()\n",
    "    plt.plot(train_losses, \"ro-\", label=\"Train\")\n",
    "    plt.plot(valid_losses, \"go-\", label=\"Validation\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.savefig(save_dir+\"/training_curve.png\")\n",
    "\n",
    "    if args.checkpoint:\n",
    "        print('Saving model...')\n",
    "        torch.save(cnn.state_dict(), args.checkpoint)\n",
    "    \n",
    "    return cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LAqGXV0iK1G9"
   },
   "source": [
    "## Convolutional neural networks (your code goes here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XOG_sFloK9gs"
   },
   "outputs": [],
   "source": [
    "######################################################################\n",
    "# MODELS\n",
    "######################################################################\n",
    "\n",
    "class MyConv2d(nn.Module):\n",
    "    \"\"\"\n",
    "    Our simplified implemented of nn.Conv2d module for 2D convolution\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, padding=None):\n",
    "        super(MyConv2d, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        if padding is None:\n",
    "            self.padding = kernel_size // 2\n",
    "        else:\n",
    "            self.padding = padding\n",
    "        self.weight = nn.parameter.Parameter(torch.Tensor(\n",
    "            out_channels, in_channels, kernel_size, kernel_size))\n",
    "        self.bias = nn.parameter.Parameter(torch.Tensor(out_channels))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        n = self.in_channels * self.kernel_size * self.kernel_size\n",
    "        stdv = 1. / math.sqrt(n)\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        self.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return F.conv2d(input, self.weight, self.bias, padding=self.padding)\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, kernel, num_filters, num_colours, num_in_channels):\n",
    "        super(CNN, self).__init__()\n",
    "        padding = kernel // 2\n",
    "\n",
    "        ############### YOUR CODE GOES HERE ###############\n",
    "        #self.downconv1 = ...\n",
    "        ###################################################\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.out1 = self.downconv1(x)\n",
    "        self.out2 = self.downconv2(self.out1)\n",
    "        self.out3 = self.rfconv(self.out2)\n",
    "        self.out4 = self.upconv1(self.out3)\n",
    "        self.out5 = self.upconv2(self.out4)\n",
    "        self.out_final = self.finalconv(self.out5)\n",
    "        return self.out_final\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, kernel, num_filters, num_colours, num_in_channels):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        ############### YOUR CODE GOES HERE ############### \n",
    "\n",
    "        ###################################################\n",
    "\n",
    "    def forward(self, x):\n",
    "        ############### YOUR CODE GOES HERE ###############\n",
    "        #self.out1 = ...\n",
    "        #self.out2 = ...\n",
    "        #self.out3 = ...\n",
    "        #self.out4 = ...\n",
    "        #self.out5 = ...\n",
    "        #self.out_final = ...\n",
    "        #return self.out_final\n",
    "        ###################################################\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jCogvi3_nlfY"
   },
   "source": [
    "# CIFAR-10 colorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CTZWiuxMjQTB"
   },
   "source": [
    "## Main training loop for CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fZHc_eStGAQz"
   },
   "outputs": [],
   "source": [
    "args = AttrDict()\n",
    "args_dict = {\n",
    "              'gpu':True, \n",
    "              'valid':False, \n",
    "              'checkpoint':\"\", \n",
    "              'colours':'./data/colours/colour_kmeans24_cat7.npy', \n",
    "              'model':\"CNN\", \n",
    "              'kernel':3,\n",
    "              'num_filters':32, \n",
    "              'learn_rate':0.001, \n",
    "              'batch_size':100, \n",
    "              'epochs':25, \n",
    "              'seed':0,\n",
    "              'plot':True, \n",
    "              'experiment_name': 'colourization_cnn',\n",
    "              'visualize': False,\n",
    "              'downsize_input':False,\n",
    "}\n",
    "args.update(args_dict)\n",
    "cnn = train(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZXJzGP8inYF9"
   },
   "source": [
    "## Main training loop for UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2-vGs7qHndmY"
   },
   "outputs": [],
   "source": [
    "args = AttrDict()\n",
    "args_dict = {\n",
    "              'gpu':True, \n",
    "              'valid':False, \n",
    "              'checkpoint':\"\", \n",
    "              'colours':'./data/colours/colour_kmeans24_cat7.npy', \n",
    "              'model':\"UNet\", \n",
    "              'kernel':3,\n",
    "              'num_filters':32, \n",
    "              'learn_rate':0.001, \n",
    "              'batch_size':100, \n",
    "              'epochs':25, \n",
    "              'seed':0,\n",
    "              'plot':True, \n",
    "              'experiment_name': 'colourization_unet',\n",
    "              'visualize': False,\n",
    "              'downsize_input':False,\n",
    "}\n",
    "args.update(args_dict)\n",
    "unet_cnn = train(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iVRRksAUoLRX"
   },
   "source": [
    "# CIFAR-10 super-resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qylCy-EGofPq"
   },
   "source": [
    "## Main training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LOduh0wloOtr"
   },
   "outputs": [],
   "source": [
    "args = AttrDict()\n",
    "args_dict = {\n",
    "              'gpu':True, \n",
    "              'valid':False, \n",
    "              'checkpoint':\"\", \n",
    "              'colours':'./data/colours/colour_kmeans24_cat7.npy', \n",
    "              'model':\"CNN\", \n",
    "              'kernel':3,\n",
    "              'num_filters':32, \n",
    "              'learn_rate':0.001, \n",
    "              'batch_size':100, \n",
    "              'epochs':25, \n",
    "              'seed':0,\n",
    "              'plot':True, \n",
    "              'experiment_name': 'super_res_unet',\n",
    "              'visualize': False,\n",
    "              'downsize_input':True,\n",
    "}\n",
    "args.update(args_dict)\n",
    "sr_cnn = train(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0i-ys_cl-Kuh"
   },
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GaPJY4g6MLN8"
   },
   "source": [
    "You will run the following code to generate visualization results. The generated images are saved in the file system of this Colab notebook. You can find them by selecting  the \"Files\" tab on the left side of the screen. \n",
    "\n",
    ">  **Files**  →   **CSC421** →   **a2**  →   **outputs**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I56OMNq_NZIF"
   },
   "source": [
    "## Visualize CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aXvqoQYONMTA"
   },
   "outputs": [],
   "source": [
    "args = AttrDict()\n",
    "args_dict = {\n",
    "              'colours':'./data/colours/colour_kmeans24_cat7.npy', \n",
    "              'index':0,\n",
    "              'experiment_name': 'colourization_cnn',\n",
    "              'downsize_input':False,\n",
    "}\n",
    "args.update(args_dict)\n",
    "plot_activation(args, cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xuOvxfA1NMz3"
   },
   "source": [
    "## Visualize UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HSSB4wd8-M7g"
   },
   "outputs": [],
   "source": [
    "args = AttrDict()\n",
    "args_dict = {\n",
    "              'colours':'./data/colours/colour_kmeans24_cat7.npy', \n",
    "              'index':0,\n",
    "              'experiment_name': 'colourization_unet',\n",
    "              'downsize_input':False,\n",
    "}\n",
    "args.update(args_dict)\n",
    "plot_activation(args, unet_cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GUujoDHaPaui"
   },
   "source": [
    "## Visualize super-resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dsvPv4KgAZrx"
   },
   "outputs": [],
   "source": [
    "args = AttrDict()\n",
    "args_dict = {\n",
    "              'colours':'./data/colours/colour_kmeans24_cat7.npy', \n",
    "              'index':0,\n",
    "              'experiment_name': 'super_res_unet',\n",
    "              'downsize_input':True,\n",
    "}\n",
    "args.update(args_dict)\n",
    "plot_activation(args, sr_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VwYseLejNx7e"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "a2_colourization_devel.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
